<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US" xml:lang="en-US">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Yliess Hati" />
  <meta name="keywords" content="keyword" />
  <title>AI-Assisted Creative Expression: a Case for Automatic Lineart Colorization</title>
  <style>
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
    /* CSS for citations */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
    }
    .hanging-indent div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }  </style>
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  <script
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<header id="title-block-header">
<h1 class="title"><p>AI-Assisted Creative Expression: a Case for
Automatic Lineart Colorization</p></h1>
<p class="author">Yliess Hati</p>
</header>
<nav id="TOC" role="doc-toc">
<h2 id="toc-title">Contents</h2>
<ul>
<li><a href="#list-of-abbreviations" id="toc-list-of-abbreviations">List
of Abbreviations</a></li>
<li><a href="#acronym-list" id="toc-acronym-list">Acronyms</a></li>
<li><a href="#abstract" id="toc-abstract">Abstract</a></li>
<li><a href="#aknowledgements"
id="toc-aknowledgements">Aknowledgements</a></li>
<li><a href="#context" id="toc-context">Context</a>
<ul>
<li><a href="#ch:introduction" id="toc-ch:introduction">Introduction</a>
<ul>
<li><a href="#motivations" id="toc-motivations">Motivations</a></li>
<li><a href="#problem-statement" id="toc-problem-statement">Problem
Statement</a></li>
<li><a href="#contributions"
id="toc-contributions">Contributions</a></li>
<li><a href="#concerns" id="toc-concerns">Concerns</a></li>
<li><a href="#outline" id="toc-outline">Outline</a></li>
</ul></li>
<li><a href="#ch:background" id="toc-ch:background">Background</a>
<ul>
<li><a href="#sec:history" id="toc-sec:history">A Brief History of
Artificial Intelligence</a></li>
<li><a href="#sec:core" id="toc-sec:core">Deep Learning Core
Principles</a></li>
<li><a href="#sec:generative" id="toc-sec:generative">Generative
Architectures</a></li>
<li><a href="#sec:attention" id="toc-sec:attention">Attention
Machanism</a></li>
</ul></li>
<li><a href="#ch:methodology" id="toc-ch:methodology">Methodology</a>
<ul>
<li><a href="#implementation"
id="toc-implementation">Implementation</a></li>
<li><a href="#objective-evaluation"
id="toc-objective-evaluation">Objective Evaluation</a></li>
<li><a href="#subjective-evaluation"
id="toc-subjective-evaluation">Subjective Evaluation</a></li>
<li><a href="#reproducibility"
id="toc-reproducibility">Reproducibility</a></li>
</ul></li>
</ul></li>
<li><a href="#core" id="toc-core">Core</a>
<ul>
<li><a href="#ch:contrib-1" id="toc-ch:contrib-1">Contrib I (Find Catchy
Explicit Name)</a>
<ul>
<li><a href="#state-of-the-art" id="toc-state-of-the-art">State of the
Art</a></li>
<li><a href="#method" id="toc-method">Method</a></li>
<li><a href="#setup" id="toc-setup">Setup</a></li>
<li><a href="#results" id="toc-results">Results</a></li>
<li><a href="#summary" id="toc-summary">Summary</a></li>
</ul></li>
<li><a href="#ch:contrib-2" id="toc-ch:contrib-2">Contrib II (Find
Catchy Explicit Name)</a>
<ul>
<li><a href="#state-of-the-art-1" id="toc-state-of-the-art-1">State of
the Art</a></li>
<li><a href="#method-1" id="toc-method-1">Method</a></li>
<li><a href="#setup-1" id="toc-setup-1">Setup</a></li>
<li><a href="#results-1" id="toc-results-1">Results</a></li>
<li><a href="#summary-1" id="toc-summary-1">Summary</a></li>
</ul></li>
<li><a href="#ch:contrib-3" id="toc-ch:contrib-3">Contrib III (Find
Catchy Explicit Name)</a>
<ul>
<li><a href="#state-of-the-art-2" id="toc-state-of-the-art-2">State of
the Art</a></li>
<li><a href="#method-2" id="toc-method-2">Method</a></li>
<li><a href="#setup-2" id="toc-setup-2">Setup</a></li>
<li><a href="#results-2" id="toc-results-2">Results</a></li>
<li><a href="#summary-2" id="toc-summary-2">Summary</a></li>
</ul></li>
<li><a href="#ch:contrib-4" id="toc-ch:contrib-4">Contrib IV (Find
Catchy Explicit Name)</a>
<ul>
<li><a href="#state-of-the-art-3" id="toc-state-of-the-art-3">State of
the Art</a></li>
<li><a href="#method-3" id="toc-method-3">Method</a></li>
<li><a href="#setup-3" id="toc-setup-3">Setup</a></li>
<li><a href="#results-3" id="toc-results-3">Results</a></li>
<li><a href="#summary-3" id="toc-summary-3">Summary</a></li>
</ul></li>
</ul></li>
<li><a href="#reflection" id="toc-reflection">Reflection</a>
<ul>
<li><a href="#ch:ethical-and-societal-impact"
id="toc-ch:ethical-and-societal-impact">Ethical and Societal
Impact</a></li>
<li><a href="#ch:conclusion" id="toc-ch:conclusion">Conclusion</a></li>
<li><a href="#references" id="toc-references">References</a></li>
</ul></li>
</ul>
</nav>
<h2 class="unnumbered" id="list-of-abbreviations">List of
Abbreviations</h2>
<h1 id="acronym-list">Acronyms</h1>
<ul>
<li><strong>ACT-R</strong>: Adaptive Control of Thought—Rational</li>
<li><strong>AD</strong>: Automatic Differentiation</li>
<li><strong>AI</strong>: Artificial Intelligence</li>
<li><strong>ANN</strong>: Artificial Neural Network</li>
<li><strong>AST</strong>: Abstract Syntax Tree</li>
<li><strong>CNN</strong>: Convolutional Neural Network</li>
<li><strong>CV</strong>: Computer Vision</li>
<li><strong>DAG</strong>: Directed Acyclic Graph</li>
<li><strong>DDM</strong>: Denoising Diffusion Model</li>
<li><strong>DL</strong>: Deep Learning</li>
<li><strong>GAN</strong>: Generative Adversarial Network</li>
<li><strong>GD</strong>: Gradient Descent</li>
<li><strong>GPU</strong>: Graphical Processing Unit</li>
<li><strong>LLM</strong>: Large Language Model</li>
<li><strong>LSTM</strong>: Long Short-Term Memory</li>
<li><strong>ML</strong>: Machine Learning</li>
<li><strong>MLP</strong>: Multi-Layer Perceptron</li>
<li><strong>MSE</strong>: Mean Squared Error</li>
<li><strong>NN</strong>: Neural Network</li>
<li><strong>NPU</strong>: Neural Processing Unit</li>
<li><strong>RLHF</strong>: Reinforcement Learning from Human
Feedback</li>
<li><strong>RNN</strong>: Recurrent Neural Network</li>
<li><strong>SGD</strong>: Stochastic Gradient Descent</li>
<li><strong>SVM</strong>: Support Vector Machine</li>
<li><strong>TPU</strong>: Tensor Processing Unit</li>
<li><strong>VAE</strong>: Variational Autoencoder</li>
</ul>
<h2 class="unnumbered" id="abstract">Abstract</h2>

<h2 class="unnumbered" id="aknowledgements">Aknowledgements</h2>

<h1 id="context">Context</h1>
<h2 id="ch:introduction">Introduction</h2>
<p>Humans possess the ability to perceive and understand the world
allowing us to accomplish a wide range of complex tasks through the
combination of visual recognition, scene understanding, and
communication. The ability to quickly and accurately extract information
from a single image is a testament to the complexity and sophistication
of the human brain and is often taken for granted. One of the Artificial
Intelligence (AI) field’s ultimate goals is to empower computers with
such human-like abilities, one of them being creativity, being able to
produce something original and worthwhile <span class="citation"
data-cites="mumford_2012">[<a href="#ref-mumford_2012"
role="doc-biblioref">39</a>]</span>.</p>
<p>Computational creativity is the field at the intersection of AI,
cognitive psychology, philosophy, and art, which aims at understanding,
simulating, replicating, or in some cases enhancing human creativity.
One definition of computational creativity <span class="citation"
data-cites="newell_1959">[<a href="#ref-newell_1959"
role="doc-biblioref">40</a>]</span> is the ability to produce something
that is novel and useful, demands that we reject common beliefs, results
from intense motivation and persistence, or comes from clarifying a
vague problem. Top-down approaches to this definition use a mix of
explicit formulations of recipes and randomness such as procedural
generation. On the opposite, bottom-up approaches use Artificial Neural
Networks (ANN) to learn patterns and heuristics from large datasets to
enable non-linear generation.</p>
<p>We, as a species, are currently witnessing the beginning of a new era
where the gap between machines and humans is starting to blur. Current
breakthroughs in the field of AI, more specifically in Deep Learning
(DL), are giving computers the ability to perceive and understand our
world, but also to interact with our environment using natural
interactions such as speech and natural language. ANNs, once mocked by
the AI community <span class="citation" data-cites="lecun_2019">[<a
href="#ref-lecun_2019" role="doc-biblioref">30</a>]</span>, are now
trainable using Gradient Descent (GD) <span class="citation"
data-cites="rumelhart_1986">[<a href="#ref-rumelhart_1986"
role="doc-biblioref">48</a>]</span> thanks to the massive availability
of data and the processing power of modern hardware accelerators such as
Graphical Processing Units (GPU), Tensor Processing Units (TPU), and
Neural Processing Units (NPU).</p>
<p>Neural Networks (NN), those trainable general function approximators,
gave rise to the field of generative NNs. Specialized DL architectures
such as Variational Autoencoders (VAE) <span class="citation"
data-cites="kingma_2013">[<a href="#ref-kingma_2013"
role="doc-biblioref">27</a>]</span>, Generative Adversarial Networks
(GAN) <span class="citation" data-cites="goodfellow_2014">[<a
href="#ref-goodfellow_2014" role="doc-biblioref">14</a>]</span>,
Denoising Diffusion Models (DDM) <span class="citation"
data-cites="ho_2020">[<a href="#ref-ho_2020"
role="doc-biblioref">20</a>]</span>, and Large Language Models (LLM)
<span class="citation" data-cites="vaswani_2017 brown_2020">[<a
href="#ref-brown_2020" role="doc-biblioref">3</a>, <a
href="#ref-vaswani_2017" role="doc-biblioref">54</a>]</span> are used to
generate artifacts such as text, audio, images, and videos of
unprecedented quality and complexity.</p>
<p>This dissertation aims at exploring how one could train and use
generative NN to create AI-powered tools capable of enhancing human
creative expression. The task of automatic lineart colorization act as
the example case used to illustrate this process throughout the entire
thesis.</p>
<figure id="fig:steps">
<img src="./figures/motivations_steps.svg"
alt="Common illustration process. From left to right: sketching, inking, coloring, and pros-processing. Credits: Taira Akitsu" />
<figcaption>Figure 1: Common illustration process. From left to right:
sketching, inking, coloring, and pros-processing. Credits: Taira
Akitsu</figcaption>
</figure>
<h3 id="motivations">Motivations</h3>
<p>Lineart colorization is an essential aspect of the work of artists,
illustrators, and animators. The task of manually coloring lineart can
be time-consuming, repetitive, and exhausting, particularly in the
animation industry, where every frame of an animated product must be
colored and shaded. This process is typically done using image editing
software such as Photoshop <span class="citation"
data-cites="photoshop">[<a href="#ref-photoshop"
role="doc-biblioref">44</a>]</span>, Clip Studio PAINT <span
class="citation" data-cites="clipstudiopaint">[<a
href="#ref-clipstudiopaint" role="doc-biblioref">6</a>]</span>, and
PaintMan <span class="citation" data-cites="paintman">[<a
href="#ref-paintman" role="doc-biblioref">41</a>]</span>. Automating the
colorization process can greatly improve the workflow of these creative
professionals and has the potential to lower the barrier for newcomers
and amateurs. Such a system was integrated into Clip Studio PAINT <span
class="citation" data-cites="clipstudiopaint">[<a
href="#ref-clipstudiopaint" role="doc-biblioref">6</a>]</span>,
demonstrating the growing significance of automatic colorization in the
field.</p>
<p>The most common digital illustration process can be broken down into
four distinct stages: sketching, inking, coloring, and post-processing
(see <a href="#fig:steps">Fig 1</a>). As demonstrated by the work of
Kandinsky <span class="citation" data-cites="kandinsky_1977">[<a
href="#ref-kandinsky_1977" role="doc-biblioref">24</a>]</span>, the
colorization process can greatly impact the overall meaning of a piece
of art through the introduction of various color schemes, shading, and
textures. These elements of the coloring process present significant
challenges for the Computer Vision (CV) task of automatic lineart
colorization, particularly in comparison to its grayscale counterpart
<span class="citation"
data-cites="furusawa_2O17 hensman_2017 zhang_richard_2017">[<a
href="#ref-furusawa_2O17" role="doc-biblioref">12</a>, <a
href="#ref-hensman_2017" role="doc-biblioref">18</a>, <a
href="#ref-zhang_richard_2017" role="doc-biblioref">59</a>]</span>.
Without the added semantic information provided by textures and shadows,
inferring materials and 3D shapes from black and white linearts is
difficult. They can only be deduced from silhouettes.</p>
<h3 id="problem-statement">Problem Statement</h3>
<p>One major challenge of automatic lineart colorization is the
availability of qualitative public datasets. Illustrations do not always
come with their corresponding lineart. The few datasets available for
the task are lacking consistency in the quality of the illustrations,
gathering images from different types, mediums and styles. For those
reasons, online scrapping and synthetic lineart extraction is the method
of choice for many of the contributions in the field <span
class="citation" data-cites="ci_2018 zhang_richard_2017">[<a
href="#ref-ci_2018" role="doc-biblioref">5</a>, <a
href="#ref-zhang_richard_2017" role="doc-biblioref">59</a>]</span>.</p>
<p>Previous works in automatic lineart colorization are based on the GAN
<span class="citation" data-cites="goodfellow_2014">[<a
href="#ref-goodfellow_2014" role="doc-biblioref">14</a>]</span>
architecture. They can generate unperfect but high-quality illustrations
in a quasi realtime setting. They achieve user control and guidance via
different means, color hints <span class="citation"
data-cites="frans_2017 liu_2017 sangkloy_2016 paintschainer_2017 ci_2018">[<a
href="#ref-ci_2018" role="doc-biblioref">5</a>, <a
href="#ref-frans_2017" role="doc-biblioref">10</a>, <a
href="#ref-liu_2017" role="doc-biblioref">34</a>, <a
href="#ref-paintschainer_2017" role="doc-biblioref">43</a>, <a
href="#ref-sangkloy_2016" role="doc-biblioref">51</a>]</span>, style
transfer <span class="citation" data-cites="zhang_ji_2017">[<a
href="#ref-zhang_ji_2017" role="doc-biblioref">58</a>]</span>, tagging
<span class="citation" data-cites="kim_2019">[<a href="#ref-kim_2019"
role="doc-biblioref">25</a>]</span>, and more recently natural language
<span class="citation" data-cites="ho_2020">[<a href="#ref-ho_2020"
role="doc-biblioref">20</a>]</span>. One common pattern in these methods
is the use of a feature extractor such as Illustration2Vec <span
class="citation" data-cites="saito_2015">[<a href="#ref-saito_2015"
role="doc-biblioref">50</a>]</span> allowing to compensate for the lack
of semantic descriptors by injecting its feature vector into the
models.</p>
<h3 id="contributions">Contributions</h3>
<p>This work focuses on the use of color hints in the form of user
strokes as it fits the natural digital artist workflow and does not
involve learning and mastering a new skill. While previous works offers
improving quality compared to classical CV techniques, they are still
subject to noisy training data, artifacts, a lack of variety, and a lack
of fidelity in the user intent. In this dissertation we explore the
importance of a clean, qualitative and consistent dataset. We
investigate how to better capture the user intent via natural artistic
controls and how to reflect them into the generated model artifact while
preserving or improving its quality. We also look at how the creative
process can be transformed into a dynamic iterative workflow where the
user collaborates with the machine to refine and carry out variations of
his artwork.</p>
<p>Here is a brief enumeration of this thesis’s contributions:</p>
<ul>
<li>We present a recipe for curating datasets for the task of automatic
lineart colorization <span class="citation"
data-cites="hati_2019 hati_2023">[<a href="#ref-hati_2019"
role="doc-biblioref">15</a>, <a href="#ref-hati_2023"
role="doc-biblioref">16</a>]</span></li>
<li>We introduce three generative models:
<ul>
<li>PaintsTorch <span class="citation" data-cites="hati_2019">[<a
href="#ref-hati_2019" role="doc-biblioref">15</a>]</span>, a double GAN
generator that improved generation quality compared to previous work
while allowing realtime interaction with the user.</li>
<li>StencilTorch <span class="citation" data-cites="hati_2023">[<a
href="#ref-hati_2023" role="doc-biblioref">16</a>]</span>, an upgrade
upon PaintsTorch, shifting the colorization problem to in-painting
allowing for human collaboration to emerge as a natural workflow where
the input of a first pass becomes the potential input for a second.</li>
<li>StablePaint, an exploration of DDM for bringing more variety into
the generated outputs allowing for variation exploration and conserving
the iterative workflow introduced by StencilTorch for the cost of
inference speed.</li>
</ul></li>
<li>We offer an advised reflection on current generative AI ethical and
societal impact.</li>
</ul>
<h3 id="concerns">Concerns</h3>
<p>Recent advances in generative AI for text, image, audio, and video
synthesis are raising important ethical and societal concerns,
especially because of its availability and ease of use. Models such as
Stable Diffusion <span class="citation" data-cites="rombach_2021">[<a
href="#ref-rombach_2021" role="doc-biblioref">46</a>]</span> and more
recently Chat-GPT <span class="citation" data-cites="openai_2023">[<a
href="#ref-openai_2023" role="doc-biblioref">4</a>]</span> are
disturbing our common beliefs and relation with copyright, creativity,
the distribution of fake information and so on.</p>
<p>One of the main issues with generative AI is the potential for model
fabulation. Generative models can create entirely new, synthetic data
that is indistinguishable from real data. This can lead to the
dissemination of false information and the manipulation of public
opinion. Additionally, there are ambiguities surrounding the ownership
and copyright of the generated content, as it is unclear who holds the
rights to the generated images and videos. Training data is often
obtained via online scrapping and thus copyright ownership is not
propagated. This is especially true for commercial applications.</p>
<p>Another important concern is the potential for biases and
discrimination. These models are trained on large amounts of data, and
if the data is not diverse or representative enough, the model may
perpetuate or even amplify existing biases. The Microsoft Tay Twitter
bot <span class="citation" data-cites="wolf_2017">[<a
href="#ref-wolf_2017" role="doc-biblioref">56</a>]</span> scandal is an
outcome of such a phenomenon. This initially innocent chatbot has been
easily turned into a racist bot perpetuating hate speech. The task was
made easier because of the inherently biased dataset it was trained
on.</p>
<p>In this work, we are committed to addressing and raising awareness
for these concerns. The illustrations used for training our models and
for our experiments are only used for educational and research purposes.
We only provide recipes for reproducibility and do not distribute the
dataset nor the weights resulting from model training, only the code. We
hope this will not ensure that our work is used ethically and
responsibly but limit its potential misuse.</p>
<h3 id="outline">Outline</h3>
<p>The first part of this thesis (chapters <a
href="#ch:introduction">1</a>-<a href="#ch:methodology">3</a>) provides
context to the recent advances in generative AI and introduces the CV
task of user-guided automatic lineart colorization, its challenges, and
our contributions to the field. It then provides additional background,
from DL first principles to current architectures used in modern
generative NN, and introduces the methodology used throughout the entire
document. This part should be accessible to the majority, experts and
non-experts, and serve as an introduction to the field.</p>
<p>The second part (chapters <a href="#ch:contrib-1">4</a>-<a
href="#ch:contrib-4">7</a>) presents our contributions, some of which
have previously been presented in <span class="citation"
data-cites="hati_2019 hati_2023">[<a href="#ref-hati_2019"
role="doc-biblioref">15</a>, <a href="#ref-hati_2023"
role="doc-biblioref">16</a>]</span>. It introduces into detail our
recipe for sourcing and curating consistent and qualitative datasets for
automatic lineart colorization, PaintsTorch <span class="citation"
data-cites="hati_2019">[<a href="#ref-hati_2019"
role="doc-biblioref">15</a>]</span> our first double generator GAN
conditioned on user strokes, StencilTorch <span class="citation"
data-cites="hati_2023">[<a href="#ref-hati_2023"
role="doc-biblioref">16</a>]</span> our in-painting reformulation
introducing the use of masks to allow the emergence of iterative
workflow and collaboration with the machine, and finally StablePaint, an
exploration of the use of DDM models for variations qualitative
exploration.</p>
<p>The third and final part (chapters <a
href="#ch:ethdical-and-societal-impact">7</a>-<a
href="#ch:conclusion">8</a>) offers a detailed reflection on this
thesis’s contributions and more generally about the field of generative
AI ethical and societal impact, identifies the remaining challenges and
discusses future work.</p>
<p>The code base for the experiments and contributions is publicly
available on GitHub at <a
href="https://github.com/yliess86">https://github.com/yliess86</a>.</p>
<h2 id="ch:background">Background</h2>
<p>This chapter introduces the reader to the field of Deep Learning (DL)
from first principles to the current architectures used in modern
generative AI. The first section (section <a href="#sec:history">1</a>)
presents a brief history of AI to ground this technical dissertation
into its historical context. The following sections (sections <a
href="#sec:core">2</a>-<a href="#sec:attention">4</a>) are discussing
the first principles of modern DL from the early Perceptron to more
modern frameworks such as Large Language Models (LLM).</p>
<div class="sourceCode" id="lst:snippet"><pre
class="sourceCode python"><code class="sourceCode python"><span id="lst:snippet-1"><a href="#lst:snippet-1" aria-hidden="true" tabindex="-1"></a><span class="co"># This is a code snippet</span></span>
<span id="lst:snippet-2"><a href="#lst:snippet-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Hello World!&quot;</span>)</span></code></pre></div>
<p>Additional code snippets (see Lst <strong>¿lst:snippet?</strong>) are
included to make this chapter more insightful and valuable for
newcomers.</p>
<figure id="fig:timeline">
<img src="./figures/boai_timeline.svg"
alt="A brief timeline of the History of Artificial Intelligence (AI)." />
<figcaption>Figure 2: A brief timeline of the History of Artificial
Intelligence (AI).</figcaption>
</figure>
<h3 id="sec:history">A Brief History of Artificial Intelligence</h3>
<p>The history of the field of AI is not a simple linear and
straightforward story. The field had its success and failures. The term
Artificial Intelligence (AI) has first been introduced in 1956 by John
Mc Carthy and Marvin Lee Minsky at a workshop sponsored by Dartmouth
College <span class="citation" data-cites="dartmouth_2006">[<a
href="#ref-dartmouth_2006" role="doc-biblioref">37</a>]</span>,
gathering about twenty researchers and intellectuals such as the
renowned Claude Shannon (see <a href="#fig:dartmouth">Fig 3</a>). The
field’s main questions were supposed to be solved in a short period.</p>
<p>However, the reality has been far less rosy. Over the years, AI has
gone through several “winters”, periods of inactivity and disillusion
where funding was cut and research interest dropped (see <a
href="#fig:timeline">Fig 2</a>). But with the advent of Big Data and the
rise of Deep Learning (DL), AI is once again in the spotlight. The
following sections provide a brief overview of the history of AI, from
its early days to the current state of the field. For a more in-depth
look at the history of modern AI, DL, we recommend “Quand la machine
apprend” from Yann LeCun <span class="citation"
data-cites="lecun_2019">[<a href="#ref-lecun_2019"
role="doc-biblioref">30</a>]</span>.</p>
<figure id="fig:dartmouth">
<img src="./figures/boai_dartmouth.png"
alt="Photography of seven of the Dartmouth workshop participants. From left to right: John McCarthy, Marvin Lee Minsky, Nathaniel Rochester, Claude Elwood Shannon, Ray Solomonoff, Trenchard More, and Oliver Gordon Selfridge. Credit: Margaret Minksy" />
<figcaption>Figure 3: Photography of seven of the Dartmouth workshop
participants. From left to right: John McCarthy, Marvin Lee Minsky,
Nathaniel Rochester, Claude Elwood Shannon, Ray Solomonoff, Trenchard
More, and Oliver Gordon Selfridge. Credit: Margaret Minksy</figcaption>
</figure>
<h4 id="the-early-years">The Early Years</h4>
<p>The term Artificial Intelligence (AI) was first used at the 1956
Dartmouth Workshop <span class="citation"
data-cites="dartmouth_2006">[<a href="#ref-dartmouth_2006"
role="doc-biblioref">37</a>]</span>, where John McCarthy proposed the
idea of creating a machine that could learn from its mistakes and
improve its performance over time. The twenty researchers and
intellectuals present worked on topics such as the automatic computer,
the use of natural language by machines, neuron nets (Neural Network
(NN)), randomness and creativity, and many more. This was a
revolutionary idea at the time, and the work done at Dartmouth attracted
a great deal of attention and funding.</p>
<p>Much of the early research focused on symbolic AI, which uses symbols
and logical operations to represent and manipulate data. Logic
programming, production rules, semantic nets and frames, knowledge-based
systems, symbolic mathematics, automatons, automated provers, ontologies
and other paradigms were at the core of symbolic AI <span
class="citation" data-cites="russell_2016">[<a href="#ref-russell_2016"
role="doc-biblioref">49</a>]</span>. This approach was based on the
early work of Alan Turing and the development of functional languages
such as the LISP by McCarthy and al. at MIT <span class="citation"
data-cites="mccarthy_1978">[<a href="#ref-mccarthy_1978"
role="doc-biblioref">36</a>]</span>.</p>
<p>One significant contribution of this period was the Perceptron by
Frank Rosenblatt <span class="citation" data-cites="rosenblatt_1958">[<a
href="#ref-rosenblatt_1958" role="doc-biblioref">47</a>]</span>, a
simplified biomimical model of a single neuron. This artificial neuron
fires when the weighted sum of its input is above a predefined
threshold. The weights, scalars attributed to the connection edges of
the neuron’s inputs, are tuned iteratively and manually given supervised
data, inputs with corresponding labels, until good enough classification
accuracy is met.</p>
<h4 id="the-first-ai-winter">The First AI Winter</h4>
<p>The Perceptron was an early example of a connectionist approach,
which uses a network of artificial neurons to process data. The
Perceptron was met with much enthusiasm but was eventually criticized by
Marvin L. Minsky and Seymour Papert <span class="citation"
data-cites="minsky_1969">[<a href="#ref-minsky_1969"
role="doc-biblioref">38</a>]</span>, who argued that it could not solve
a simple XOR problem. The criticisms, as well as other issues, led to a
period of disillusion in the field of AI, known as the “First AI
Winter”. It was a time when AI research lost its momentum and funding
was not abundant anymore. This period lasted from 1973 to 1980.</p>
<h4 id="expert-systems-and-symbolic-ai">Expert Systems and Symbolic
AI</h4>
<p>The eighties saw a resurgence of interest in AI. Expert systems <span
class="citation" data-cites="jackson_1998">[<a href="#ref-jackson_1998"
role="doc-biblioref">22</a>]</span> were the new hot AI topic. They are
made of hierarchical and specialized ensembles of symbolic reasoning
models and are used to solve complex problems. Symbolic AI continued to
prosper as the dominant approach until the mid-nineties.</p>
<p>During this period, AI was developed as logic-based systems,
search-based systems using depth-first-search, and genetic algorithms,
requiring complex engineering and domain-specific knowledge from experts
to work. It was also the time of the first cognitive architectures <span
class="citation" data-cites="lieto_2021">[<a href="#ref-lieto_2021"
role="doc-biblioref">33</a>]</span> inspired by advances in the field of
neuroscience such as SOAR <span class="citation"
data-cites="larid_2019">[<a href="#ref-larid_2019"
role="doc-biblioref">29</a>]</span> and Adaptive Control of
Thought—Rational (ACT-R) <span class="citation"
data-cites="john_1992">[<a href="#ref-john_1992"
role="doc-biblioref">2</a>]</span> attempting at simulating the human
cognitive process for solving and task automation.</p>
<p>Although the connectionist approaches were not well received by the
community at the time, some individuals are known for significant
contributions that later would form the basis for modern NN
architectures. It was the case for Kunihiko Fukushima and his
NeoCognitron <span class="citation" data-cites="fukushima_1980">[<a
href="#ref-fukushima_1980" role="doc-biblioref">11</a>]</span>, or David
E. Rumelhart et al. who introduced the most used learning procedure for
training Multi-Layer Perceptrons (MLP), the backpropagation <span
class="citation" data-cites="rumelhart_1986">[<a
href="#ref-rumelhart_1986" role="doc-biblioref">48</a>]</span>.</p>
<h4 id="the-second-ai-winter">The Second AI Winter</h4>
<p>Unfortunately, this period was also marked by a lack of progress
because of the resource limitations of the time. Those algorithms
required too much power, data, and investments to work. They were not
sufficient to make AI truly successful. The lack of progress in the
eighties led to the “Second AI Winter”. AI research was largely
abandoned during this period. Funding and enthusiasm dwindled. This
winter lasted from 1988 to early 2000.</p>
<h5 id="the-indomitable-researchers">The Indomitable Researchers</h5>
<p>The second AI winter limited research for NN. However, some
indomitable individuals continued their work. During this period,
Vladimir Vapnik et al. developed the Support Vector Machine (SVM) <span
class="citation" data-cites="cortes_1995">[<a href="#ref-cortes_1995"
role="doc-biblioref">7</a>]</span>, a robust non-probabilistic binary
linear classifier. The method has the advantage to generalize well even
with small datasets. Sepp Hochreiter et al. introduced the Long
Short-Term Memory (LSTM) for Recurrent Neural Networks (RNN) <span
class="citation" data-cites="hochreiter_1997">[<a
href="#ref-hochreiter_1997" role="doc-biblioref">21</a>]</span>, a
complex recurrent cell using gates to route the information flow and
simulate long and short-term memory buffers. In 1989, Yann LeCun
provided the first practical and industrial demonstration of
backpropagation at Bell Labs with a Convolutional Neural Network (CNN)
to read handwritten digits <span class="citation"
data-cites="lecun_1989 lecun_1998">[<a href="#ref-lecun_1989"
role="doc-biblioref">31</a>, <a href="#ref-lecun_1998"
role="doc-biblioref">32</a>]</span> later used by the American postal
services to sort letters.</p>
<figure id="fig:revolution">
<img src="./figures/boai_revolution.svg"
alt="A brief timeline of the Deep Learning (DL) Revolution." />
<figcaption>Figure 4: A brief timeline of the Deep Learning (DL)
Revolution.</figcaption>
</figure>
<h4 id="the-deep-learning-revolution">The Deep Learning Revolution</h4>
<p>The next significant evolutionary step Deep Learning (DL), those deep
hierarchical NN, descendants of the connectionist movement, occurred in
the early twenty-first century (see <a
href="#fig:revolution">Fig 4</a>). Computers were now faster and GPUs
were developed for high compute parallelization. Data was starting to be
abundant thanks to the internet and the rapid rise of search engines and
social networks. It is the era of Big Data. NN were competing with SVM.
In 2009 Fei-Fei Li and her group launched ImageNet <span
class="citation" data-cites="deng_2009">[<a href="#ref-deng_2009"
role="doc-biblioref">8</a>]</span>, a dataset assembling billions of
labeled images.</p>
<p>By 2011, the speed of GPUs had increased significantly, making it
possible to train CNNs without layer-by-layer pre-training. The rest of
the story includes a succession of deep NN architectures including,
AlexNet <span class="citation" data-cites="krizhevsky_2012">[<a
href="#ref-krizhevsky_2012" role="doc-biblioref">28</a>]</span>, one of
the first award-winning deep CNN, ResNet <span class="citation"
data-cites="he_2016">[<a href="#ref-he_2016"
role="doc-biblioref">17</a>]</span>, introducing residual connections,
the Generative Adversarial Networks (GAN) <span class="citation"
data-cites="goodfellow_2014">[<a href="#ref-goodfellow_2014"
role="doc-biblioref">14</a>]</span>, a high fidelity and high-resolution
generative framework, attention mechanisms with the rise of the
Transformer “Attention is all you Need” architecture <span
class="citation" data-cites="vaswani_2017">[<a href="#ref-vaswani_2017"
role="doc-biblioref">54</a>]</span> present in almost all modern DL
contributions, and more recently the Denoising Diffusion Model (DDM)
<span class="citation" data-cites="ho_2020">[<a href="#ref-ho_2020"
role="doc-biblioref">20</a>]</span>, the spiritual autoregressive
successor of the GAN.</p>
<figure id="fig:milestones">
<img src="./figures/boai_milestones.svg"
alt="A brief timeline of the Deep Learning (DL) Milestones." />
<figcaption>Figure 5: A brief timeline of the Deep Learning (DL)
Milestones.</figcaption>
</figure>
<h4 id="deep-learning-milestones">Deep Learning Milestones</h4>
<p>DL is responsible for many AI milestones in the past decade (see <a
href="#fig:milestones">Fig 5</a>). These milestones have been essential
in advancing the field and enabling its applications within various
sectors. One of the first notable milestones was AlphaGo from DeepMind
in 2016 <span class="citation" data-cites="silver_2016">[<a
href="#ref-silver_2016" role="doc-biblioref">53</a>]</span>, where an AI
system was able to beat the Korean world champion Lee Se Dol in the game
of Go. AlphaGo is an illustration of the compression and pattern
recognition capabilities of deep NN in combination with efficient search
algorithms.</p>
<p>In 2019, AlphStar <span class="citation"
data-cites="vinyals_2019">[<a href="#ref-vinyals_2019"
role="doc-biblioref">55</a>]</span> from DeepMind also was able to
compete and defeat grandmasters in StarCraft the real-time strategy game
of Blizzard. This demonstrated the capability of Deep Learning
algorithms to achieve beyond human-level performance in real-time and
long-term plannification. In 2020, AlphaFold <span class="citation"
data-cites="senior_2020">[<a href="#ref-senior_2020"
role="doc-biblioref">52</a>]</span> improved the Protein Folding
competition by quite a margin, showing that DL could be used to help
solve complex problems that have implications for medical research and
drug discovery. In 2021 a follow-up model, AlphaFold 2 <span
class="citation" data-cites="jumper_2021">[<a href="#ref-jumper_2021"
role="doc-biblioref">23</a>]</span>, was presented as an impressive
successor of AlphaFold, showcasing further advances in this field.</p>
<p>In 2021, Stable Diffusion <span class="citation"
data-cites="rombach_2021">[<a href="#ref-rombach_2021"
role="doc-biblioref">46</a>]</span> from Stability AI was released. This
Latent DDM conditioned on text prompts allows to generate images of
unprecedented quality and met unprecedented public reach. Finally,
Chat-GPT <span class="citation" data-cites="openai_2023">[<a
href="#ref-openai_2023" role="doc-biblioref">4</a>]</span> was released
in 2023 as a chatbot based on GPT3 <span class="citation"
data-cites="brown_2020">[<a href="#ref-brown_2020"
role="doc-biblioref">3</a>]</span> and fine-tuned using Reinforcement
Learning from Human Feedback (RLHF) for natural question-answering
interaction publicly available as a web demo. However, these last two
milestones are also responsible for ethical and societal concerns about
copyright, creativity, and more. This highlights both the potential of
Deep Learning algorithms but also the need for further research around
their implications.</p>
<h3 id="sec:core">Deep Learning Core Principles</h3>
<p>This section introduces the technical background necessary to
understand this thesis dissertation. It introduces Neural Networks (NN)
from first principles. A more detailed and complete introduction to the
field can be found in “the Deep Learning book” by Ian Goodfellow et al
<span class="citation" data-cites="goodfellow_2016">[<a
href="#ref-goodfellow_2016" role="doc-biblioref">13</a>]</span> or in
“Dive into Deep Learning” by Aston Zhang et al. <span class="citation"
data-cites="aston_zhang_2021">[<a href="#ref-aston_zhang_2021"
role="doc-biblioref">57</a>]</span>.</p>
<h4 id="supervised-learning">Supervised Learning</h4>
<p>In Machine Learning (ML), problems are often formulated as
data-driven learning tasks, where a computer is used to find a mapping
<span class="math inline">\(f: X \rightarrow Y\)</span> from input space
<span class="math inline">\(X\)</span> to output space <span
class="math inline">\(Y\)</span>. For example, <span
class="math inline">\(X\)</span> could represent data about an e-mail
and <span class="math inline">\(Y\)</span> the probability of this
e-mail being spam. In practice, manually defining all the
characteristics of a function <span class="math inline">\(f\)</span>
that would satisfy this task is considered unpractical. It would require
one to manually describe all potential rules defining spam. In ML, the
supervised framework offers a practical solution consisting of acquiring
label data pairs, <span class="math inline">\((x, y) \in X \times
Y\)</span> for the current problem (see <a
href="#fig:dataflow">Fig 6</a>). In our case, this would require
gathering a dataset of e-mails and asking humans to label those as spam
or not.</p>
<p><strong>Objective Function</strong>: Let us consider such a training
dataset containing n independent pairs <span
class="math inline">\(\{(x_1, y_1), \dots, (x_n, y_n)\}\)</span> sampled
from the data distribution <span class="math inline">\(D\)</span>, <span
class="math inline">\((x_i, y_i) \sim D\)</span>. In ML, we seek for
learning a mapping <span class="math inline">\(f: X \rightarrow
Y\)</span> by searching the space of the candidates function class <span
class="math inline">\(\mathcal{F}\)</span>. Defining a scalar objective
function <span class="math inline">\(L(\hat{y}, y)\)</span> measuring
the distance from true label <span class="math inline">\(y\)</span> and
our prediction <span class="math inline">\(f(x_i) = \hat{y}_i\)</span>
given <span class="math inline">\(f \in \mathcal{F}\)</span>, the
ultimate objective is to find the function <span
class="math inline">\(f^* \in F\)</span> that best satisfy the following
minimization problem (see <a href="#eq:f_star_objective">Eq 1</a>):</p>
<p><span id="eq:f_star_objective"><span class="math display">\[
f^* = arg \; \underset{f \in \mathcal{F}}{min} \; E_{(x, y) \sim D}
L(\hat{y}, y)
\qquad{(1)}\]</span></span></p>
<p>The function <span class="math inline">\(f^*\)</span> must minimize
the expected loss <span class="math inline">\(L\)</span> over the entire
data distribution <span class="math inline">\(D\)</span>. Once such a
function is learned one can use it to perform inference and map any
element from the input space <span class="math inline">\(X\)</span> to
the output space <span class="math inline">\(Y\)</span>.</p>
<p>However, this minimization problem is intractable as it is impossible
to represent the entire distribution <span
class="math inline">\(D\)</span>. Fortunately, as every pair <span
class="math inline">\((x_i, y_i)\)</span> is independently sampled and
identically distributed, the objective can be approximated by sampling
and minimizing the loss over the training dataset (see <a
href="#eq:f_star_objective_approx">Eq 2</a>):</p>
<p><span id="eq:f_star_objective_approx"><span class="math display">\[
f^* \approx arg \; \underset{f \in \mathcal{F}}{min} \; \frac{1}{n}
\sum_{i=1}^{n} L(\hat{y}_i, y_i)
\qquad{(2)}\]</span></span></p>
<p><strong>Regularization</strong>: While simplifying the problem allows
us to perform loss minimization, this approximation comes at a cost.
This optimization problem can have multiple solutions, a set of
functions <span class="math inline">\(\{f_1, \dots, f_m\} \in F\)</span>
performing well on the given training set, but would behave differently
outside of the training data and outside of the data distribution. Those
functions would not necessarily be able to generalize. To mitigate those
concerns, we can introduce a regularization term <span
class="math inline">\(R\)</span> into the objective function (see <a
href="#eq:f_star_objective_regul">Eq 3</a>), a scalar function that is
independent of the data distribution and represent a preference on
certain function class.</p>
<p><span id="eq:f_star_objective_regul"><span class="math display">\[
f^* \approx arg \; \underset{f \in \mathcal{F}}{min} \; \frac{1}{n}
\sum_{i=1}^{n} L(\hat{y}_i, y_i) + R(f)
\qquad{(3)}\]</span></span></p>
<figure id="fig:dataflow">
<img src="./figures/core_nn_dataflow.svg"
alt="Supervised learning data flow. The dataset {(x_i, y_i)} \in D is used to train the model f \in \mathcal{F} to minimize an objective function with two terms, a data dependant loss L, and a regularization R measuring the system complexity." />
<figcaption>Figure 6: Supervised learning data flow. The dataset <span
class="math inline">\({(x_i, y_i)} \in D\)</span> is used to train the
model <span class="math inline">\(f \in \mathcal{F}\)</span> to minimize
an objective function with two terms, a data dependant loss <span
class="math inline">\(L\)</span>, and a regularization <span
class="math inline">\(R\)</span> measuring the system
complexity.</figcaption>
</figure>
<p>In the following, we investigate two examples where supervised
learning is first applied to a Neural Network (NN) regression problem,
and then a NN classification problem. The examples highlight the
objective functions composed by the loss and the regularization term for
regression and classification respectively.</p>
<p><strong>Regression Problem:</strong> Let us consider the distribution
<span class="math inline">\(D\)</span> represented by the <span
class="math inline">\(sin\)</span> function in the <span
class="math inline">\([-3 \pi; 3 \pi]\)</span> range (see <a
href="#fig:regression">Fig 7</a>). We sample <span
class="math inline">\(50\)</span> pairs <span
class="math inline">\((x_i, y_i)\)</span> with <span
class="math inline">\(X \in [-3 \pi; 3 \pi]\)</span> and <span
class="math inline">\(Y \in [-1; 1]\)</span>. Our objective is to learn
a regressor <span class="math inline">\(f_\theta\)</span>, a three
layers NN parametrized by its weights <span class="math inline">\(\{w_0,
W_1, w_2\} = \theta\)</span>. <span class="math inline">\(w_0\)</span>
contains <span class="math inline">\((1 \times 16) + 1\)</span> weights,
<span class="math inline">\(W_1\)</span>, <span
class="math inline">\((16 \times 16) + 1\)</span>, and <span
class="math inline">\(w_2\)</span>, <span class="math inline">\((16
\times 1) + 1\)</span>. In this case, the function space is limited to
the three layers NN family with <span class="math inline">\(291\)</span>
parameters <span class="math inline">\(\mathcal{F}\)</span>.</p>
<figure id="fig:regression">
<img src="./figures/core_nn_regression.svg"
alt="Neural Network (NN) regression example. The model f_\theta is fit on the training set (X, Y) \in D representing the sin function in the range [-3 \pi; 3 \pi]." />
<figcaption>Figure 7: Neural Network (NN) regression example. The model
<span class="math inline">\(f_\theta\)</span> is fit on the training set
<span class="math inline">\((X, Y) \in D\)</span> representing the <span
class="math inline">\(sin\)</span> function in the range <span
class="math inline">\([-3 \pi; 3 \pi]\)</span>.</figcaption>
</figure>
<p>To achieve this goal using supervised learning, we can optimize the
following objective function (see <a
href="#eq:reg_sin_objective">Eq 4</a>):</p>
<p><span id="eq:reg_sin_objective"><span class="math display">\[
f^* = arg \; \underset{\theta}{min} \; \frac{1}{n} \sum_{i=1}^{n}
(f_\theta(x_i) - y_i)^2 + \lambda ||\theta||_2^2
\qquad{(4)}\]</span></span></p>
<p>where the loss is the Mean Squared Error (MSE) <span
class="math inline">\(||.||_2^2\)</span> between the ground-truth <span
class="math inline">\(y_i\)</span> and the prediction <span
class="math inline">\(\hat{y_i} = f_\theta(x_i)\)</span>, and the
weighted regularization term <span class="math inline">\(\lambda
||\theta||_2^2\)</span> to penalize the model for having large weights
and converge to a simpler solution. A python code snippet for the
objective function and the model is provided below (see
Lst <strong>¿lst:regression?</strong>):</p>
<div class="sourceCode" id="lst:regression"><pre
class="sourceCode python"><code class="sourceCode python"><span id="lst:regression-1"><a href="#lst:regression-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.nn <span class="im">import</span> (Linear, Sequential, Tanh)</span>
<span id="lst:regression-2"><a href="#lst:regression-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="lst:regression-3"><a href="#lst:regression-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Loss and Regularization</span></span>
<span id="lst:regression-4"><a href="#lst:regression-4" aria-hidden="true" tabindex="-1"></a>L <span class="op">=</span> <span class="kw">lambda</span> y_, y <span class="op">=</span> (y_ <span class="op">-</span> y).<span class="bu">pow</span>(<span class="dv">2</span>)</span>
<span id="lst:regression-5"><a href="#lst:regression-5" aria-hidden="true" tabindex="-1"></a>R <span class="op">=</span> <span class="kw">lambda</span> f: <span class="bu">sum</span>(w.<span class="bu">pow</span>(<span class="dv">2</span>).<span class="bu">sum</span>() <span class="cf">for</span> w <span class="kw">in</span> f.parameters())</span>
<span id="lst:regression-6"><a href="#lst:regression-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="lst:regression-7"><a href="#lst:regression-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Neural Network model</span></span>
<span id="lst:regression-8"><a href="#lst:regression-8" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> Sequential(</span>
<span id="lst:regression-9"><a href="#lst:regression-9" aria-hidden="true" tabindex="-1"></a>    Linear(<span class="dv">1</span>, <span class="dv">16</span>), Tanh(),</span>
<span id="lst:regression-10"><a href="#lst:regression-10" aria-hidden="true" tabindex="-1"></a>    Linear(<span class="dv">16</span>, <span class="dv">16</span>), Tanh(),</span>
<span id="lst:regression-11"><a href="#lst:regression-11" aria-hidden="true" tabindex="-1"></a>    Linear(<span class="dv">16</span>, <span class="dv">1</span>),</span>
<span id="lst:regression-12"><a href="#lst:regression-12" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="lst:regression-13"><a href="#lst:regression-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="lst:regression-14"><a href="#lst:regression-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Objective function</span></span>
<span id="lst:regression-15"><a href="#lst:regression-15" aria-hidden="true" tabindex="-1"></a>C <span class="op">=</span> (<span class="dv">1</span> <span class="op">/</span> n) <span class="op">*</span> L(f(X), Y).<span class="bu">sum</span>() <span class="op">+</span> lam <span class="op">*</span>  R(f)</span></code></pre></div>
<p><strong>Classification Problem:</strong> Let us consider the
distribution <span class="math inline">\(D\)</span> representing the 2d
positions of two clusters <span class="math inline">\({0, 1} \in
K\)</span> of moons (see <a href="#fig:classification">Fig 8</a>). We
sample <span class="math inline">\(250\)</span> moon <span
class="math inline">\((x_i, y_i)\)</span> with <span
class="math inline">\(X \in [-1; 1]\)</span> and <span
class="math inline">\(Y \in [-1; 1]\)</span>. Our objective is to learn
a classifier <span class="math inline">\(f_\theta\)</span>, a three
layers NN parametrized by its weights <span class="math inline">\(\{w_0,
W_1, w_2\} = \theta\)</span>. <span class="math inline">\(w_0\)</span>
contains <span class="math inline">\((1 \times 32) + 1\)</span> weights,
<span class="math inline">\(W_1\)</span>, <span
class="math inline">\((32 \times 32) + 1\)</span>, and <span
class="math inline">\(w_2\)</span>, <span class="math inline">\((32
\times 1) + 1\)</span>. In this case, the function space is limited to
the three layers NN family with <span
class="math inline">\(1,091\)</span> parameters <span
class="math inline">\(\mathcal{F}\)</span>.</p>
<figure id="fig:classification">
<img src="./figures/core_nn_classification.svg"
alt="Neural Network (NN) classification example. The model f_\theta is trained to classify moons based on their positions. The decision boundary is shown." />
<figcaption>Figure 8: Neural Network (NN) classification example. The
model <span class="math inline">\(f_\theta\)</span> is trained to
classify moons based on their positions. The decision boundary is
shown.</figcaption>
</figure>
<p>To achieve this goal using supervised learning, we can optimize an
objective function similar to the regression problem (see <a
href="#eq:reg_sin_objective">Eq 4</a>) using the cross-entropy as the
loss function (see <a href="#eq:cross_entropy">Eq 5</a>), measuring the
classification discordance.</p>
<p><span id="eq:cross_entropy"><span class="math display">\[
\mathcal{L} (\hat{y}, y) = \sum_{k=1}^{K} y_k \; log \; \hat{y}_k
\qquad{(5)}\]</span></span></p>
<p>A python code snippet for the loss function and the model is provided
below (see Lst <strong>¿lst:classification?</strong>):</p>
<div class="sourceCode" id="lst:classification"><pre
class="sourceCode python"><code class="sourceCode python"><span id="lst:classification-1"><a href="#lst:classification-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.nn <span class="im">import</span> (Linear, Sequential, Tanh)</span>
<span id="lst:classification-2"><a href="#lst:classification-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.nn.functional <span class="im">import</span> cross_entropy</span>
<span id="lst:classification-3"><a href="#lst:classification-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="lst:classification-4"><a href="#lst:classification-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Loss</span></span>
<span id="lst:classification-5"><a href="#lst:classification-5" aria-hidden="true" tabindex="-1"></a>L <span class="op">=</span> <span class="kw">lambda</span> y_, y <span class="op">=</span> cross_entropy(y_, y, <span class="bu">reduce</span><span class="op">=</span><span class="va">False</span>)</span>
<span id="lst:classification-6"><a href="#lst:classification-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="lst:classification-7"><a href="#lst:classification-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Neural Network model</span></span>
<span id="lst:classification-8"><a href="#lst:classification-8" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> Sequential(</span>
<span id="lst:classification-9"><a href="#lst:classification-9" aria-hidden="true" tabindex="-1"></a>    Linear(<span class="dv">1</span>, <span class="dv">32</span>), Tanh(),</span>
<span id="lst:classification-10"><a href="#lst:classification-10" aria-hidden="true" tabindex="-1"></a>    Linear(<span class="dv">32</span>, <span class="dv">32</span>), Tanh(),</span>
<span id="lst:classification-11"><a href="#lst:classification-11" aria-hidden="true" tabindex="-1"></a>    Linear(<span class="dv">32</span>, <span class="dv">1</span>),</span>
<span id="lst:classification-12"><a href="#lst:classification-12" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<h4 id="sec:optimization">Optimization</h4>
<p>In ML, supervised problems can be reduced to an optimization problem
where the computer has to find a set of parameters, weights <span
class="math inline">\(\theta\)</span>, for a given function class <span
class="math inline">\(\mathcal{F}\)</span> by optimizing an objective
function <span class="math inline">\(\theta^* = arg \; min_\theta
\mathcal{C(\theta)}\)</span> made out of two components, a
data-dependant loss <span class="math inline">\(L\)</span> and a
regularization <span class="math inline">\(R\)</span>.</p>
<p><strong>Random Search:</strong> One way to find such a function <span
class="math inline">\(f_\theta\)</span> that satisfies this objective is
to estimate the objective function for a set of random parameter
initializations and take the one that minimizes <span
class="math inline">\(C\)</span> the most. This <span
class="math inline">\(\theta\)</span> setting can then be refined by
applying random perturbations to the parameters and repeating the
operation (see Lst <strong>¿lst:random_search?</strong>). This is
possible due to the fact that we can computer <span
class="math inline">\(C(\theta)\)</span> for any value of <span
class="math inline">\(\theta\)</span> taking the average loss for a
given dataset. However, such an approach to optimization is unpractical.
NN often comes with millions or billions of parameters <span
class="math inline">\(\theta\)</span> making random-search
intractable.</p>
<div class="sourceCode" id="lst:random_search"><pre
class="sourceCode python"><code class="sourceCode python"><span id="lst:random_search-1"><a href="#lst:random_search-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> copy</span>
<span id="lst:random_search-2"><a href="#lst:random_search-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="lst:random_search-3"><a href="#lst:random_search-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="lst:random_search-4"><a href="#lst:random_search-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="lst:random_search-5"><a href="#lst:random_search-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> step <span class="kw">in</span> <span class="bu">range</span>(steps):</span>
<span id="lst:random_search-6"><a href="#lst:random_search-6" aria-hidden="true" tabindex="-1"></a>    fs, os <span class="op">=</span> [f] <span class="op">+</span> [copy.deepcopy(f) <span class="cf">for</span> f <span class="kw">in</span> <span class="bu">range</span>(n_copy)], []</span>
<span id="lst:random_search-7"><a href="#lst:random_search-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> f_ <span class="kw">in</span> fs:</span>
<span id="lst:random_search-8"><a href="#lst:random_search-8" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Apply weight perturbation</span></span>
<span id="lst:random_search-9"><a href="#lst:random_search-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> w <span class="kw">in</span> f_.parameters():</span>
<span id="lst:random_search-10"><a href="#lst:random_search-10" aria-hidden="true" tabindex="-1"></a>            w.normal_(<span class="fl">0.0</span>, <span class="fl">1.0</span> <span class="op">/</span> step)</span>
<span id="lst:random_search-11"><a href="#lst:random_search-11" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Estimate the objective function</span></span>
<span id="lst:random_search-12"><a href="#lst:random_search-12" aria-hidden="true" tabindex="-1"></a>        os.append(C(f_(X), Y))</span>
<span id="lst:random_search-13"><a href="#lst:random_search-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="lst:random_search-14"><a href="#lst:random_search-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Retrieve the winner</span></span>
<span id="lst:random_search-15"><a href="#lst:random_search-15" aria-hidden="true" tabindex="-1"></a>    f <span class="op">=</span> fs[np.argmax(os)]</span></code></pre></div>
<p><strong>First Order Derivation:</strong> A more efficient approach is
to make the objective function <span class="math inline">\(C\)</span>
and the model <span class="math inline">\(f_\theta\)</span>
differentiable. This constraint allows us to compute the gradient of the
cost <span class="math inline">\(C\)</span> with respect to the model’s
parameters <span class="math inline">\(\theta\)</span>. The value <span
class="math inline">\(\nabla_\theta C\)</span> can be obtained using
backpropagation (discussed in the next sub-section <a
href="#sec:backpropagation">Sec 2.2.2.3</a>). This vector of first order
derivatives indicates the direction from which we need to move the
weights <span class="math inline">\(\theta\)</span> away. By taking
small iterative steps toward the negative direction of the gradients, we
can improve <span class="math inline">\(\theta\)</span>. This algorithm
is called GD. In practice, due to the very large size of the datasets
(<span class="math inline">\(14,197,122\)</span> images for ImageNet
<span class="citation" data-cites="deng_2009">[<a href="#ref-deng_2009"
role="doc-biblioref">8</a>]</span>), the objective gradient is
approximated using a small subset of the training data for each step
referred to as a minibatch. This approximation of the GD is called
Stochastic Gradient Descent (SGD) (see
Lst <strong>¿lst:sgd?</strong>).</p>
<div class="sourceCode" id="lst:sgd"><pre
class="sourceCode python"><code class="sourceCode python"><span id="lst:sgd-1"><a href="#lst:sgd-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> step <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1_000</span>):</span>
<span id="lst:sgd-2"><a href="#lst:sgd-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Retrieve the next minibatch</span></span>
<span id="lst:sgd-3"><a href="#lst:sgd-3" aria-hidden="true" tabindex="-1"></a>    x, y <span class="op">=</span> next_minibatch(X, Y)</span>
<span id="lst:sgd-4"><a href="#lst:sgd-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="lst:sgd-5"><a href="#lst:sgd-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute the objective function and the gradients</span></span>
<span id="lst:sgd-6"><a href="#lst:sgd-6" aria-hidden="true" tabindex="-1"></a>    C <span class="op">=</span> L(f(x), y) <span class="op">+</span> lam <span class="op">*</span> R(f)</span>
<span id="lst:sgd-7"><a href="#lst:sgd-7" aria-hidden="true" tabindex="-1"></a>    C.backward()</span>
<span id="lst:sgd-8"><a href="#lst:sgd-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="lst:sgd-9"><a href="#lst:sgd-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Update the weights and reset the gradients</span></span>
<span id="lst:sgd-10"><a href="#lst:sgd-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> w <span class="kw">in</span> f.parameters():</span>
<span id="lst:sgd-11"><a href="#lst:sgd-11" aria-hidden="true" tabindex="-1"></a>        w <span class="op">-=</span> eps <span class="op">*</span> w.grad</span>
<span id="lst:sgd-12"><a href="#lst:sgd-12" aria-hidden="true" tabindex="-1"></a>    f.zero_grad(set_to_none<span class="op">=</span><span class="va">True</span>)</span></code></pre></div>
<p>One critical aspect of the SGD algorithm is the hyperparameter <span
class="math inline">\(\epsilon\)</span>, the learning rate. It controls
the size of the step we take toward the negative gradients. If it is too
height or too low, the optimization may not converge toward an
acceptable local minimum. A toy example is provided in <a
href="#fig:toysgd">Fig 9</a> where different learning rates are used to
find the minimum of the square function <span class="math inline">\(y =
x^2\)</span>.</p>
<figure id="fig:toysgd">
<img src="./figures/core_nn_sgd.svg"
alt="Toy example where different learning rates \epsilon are used to find the minimum of the square function y = x^2 using the Gradient Descent (GD) algorithm starting from x = -1. Some learning rate setup result in situations where the optimization does not converge to the solution. A learning rate \epsilon = 2 diverges toward infinity, \epsilon = 1 is stuck and bounces between two positions -1 and 1. However, a small learning rate \epsilon = 0.1 &lt; 1 converges towards the minimum y = 0. This example illustrates the impact of the hyperparameter \epsilon on GD." />
<figcaption>Figure 9: Toy example where different learning rates <span
class="math inline">\(\epsilon\)</span> are used to find the minimum of
the square function <span class="math inline">\(y = x^2\)</span> using
the Gradient Descent (GD) algorithm starting from <span
class="math inline">\(x = -1\)</span>. Some learning rate setup result
in situations where the optimization does not converge to the solution.
A learning rate <span class="math inline">\(\epsilon = 2\)</span>
diverges toward infinity, <span class="math inline">\(\epsilon =
1\)</span> is stuck and bounces between two positions <span
class="math inline">\(-1\)</span> and <span
class="math inline">\(1\)</span>. However, a small learning rate <span
class="math inline">\(\epsilon = 0.1 &lt; 1\)</span> converges towards
the minimum <span class="math inline">\(y = 0\)</span>. This example
illustrates the impact of the hyperparameter <span
class="math inline">\(\epsilon\)</span> on GD.</figcaption>
</figure>
<p><strong>First Order Derivation with Momentum:</strong> The DL
literature contains abundant work on first order optimizer variants
aiming for faster convergence such as SGD with Momentum <span
class="citation" data-cites="qian_1999">[<a href="#ref-qian_1999"
role="doc-biblioref">45</a>]</span>, Adagrad <span class="citation"
data-cites="duchi_2011">[<a href="#ref-duchi_2011"
role="doc-biblioref">9</a>]</span>, RMSProp <span class="citation"
data-cites="hinton_lecture6a">[<a href="#ref-hinton_lecture6a"
role="doc-biblioref">19</a>]</span>, Adam <span class="citation"
data-cites="kingma_2014">[<a href="#ref-kingma_2014"
role="doc-biblioref">26</a>]</span>, and its correction AdamW <span
class="citation" data-cites="loshchilov_2017">[<a
href="#ref-loshchilov_2017" role="doc-biblioref">35</a>]</span>. A toy
example is shown <a href="#fig:sgd_moments">Fig 10</a>.</p>
<p>The Momentum update <span class="citation" data-cites="qian_1999">[<a
href="#ref-qian_1999" role="doc-biblioref">45</a>]</span> introduces the
use of a momentum inspired by physics’ first principles to favor small
and consistent gradient directions. In this particular case, the
momentum is represented by a variable <span
class="math inline">\(v\)</span> updated to store an exponential
decaying sum of the previous gradients <span class="math inline">\(v :=
\alpha v + \nabla_\theta C(\theta)\)</span>. The weights are then
updated using negative <span class="math inline">\(v\)</span> as the
gradient direction instead of <span class="math inline">\(\nabla_\theta
C(\theta)\)</span>.</p>
<p>Other optimizers also make use of the second moment of the gradients.
Adagrad <span class="citation" data-cites="duchi_2011">[<a
href="#ref-duchi_2011" role="doc-biblioref">9</a>]</span> uses another
variable <span class="math inline">\(r\)</span> to store the second
moment <span class="math inline">\(r := r + \nabla_\theta C(\theta)
\odot \nabla_\theta C(\theta)\)</span> and modulate the update rule
toward the negative direction <span
class="math inline">\(\frac{1}{\delta + \sqrt{r}} \odot \nabla_\theta
C(\theta)\)</span> where <span class="math inline">\(\delta\)</span> is
a small value to avoid division by zero. Similarly, RMSProp <span
class="citation" data-cites="hinton_lecture6a">[<a
href="#ref-hinton_lecture6a" role="doc-biblioref">19</a>]</span>
maintains a running mean of the second moment <span
class="math inline">\(r := \rho r + (1 - \rho) \nabla_\theta C(\theta)
\odot \nabla_\theta C(\theta)\)</span>.</p>
<p>Finally Adam <span class="citation" data-cites="kingma_2014">[<a
href="#ref-kingma_2014" role="doc-biblioref">26</a>]</span>, and its
correction AdamW <span class="citation" data-cites="loshchilov_2017">[<a
href="#ref-loshchilov_2017" role="doc-biblioref">35</a>]</span>, are
applying both Momentum and RMSProp estimating the first and second
moment to make parameters with large gradients take small steps and
parameters with low gradients take larger ones. This has the advantage
to allow for bigger learning rates and faster convergence at the cost of
triple the amount of parameters to store during training. A simple
implementation of Adam is shown below (see
Lst <strong>¿lst:adam?</strong>):</p>
<!-- - Adagrad, RMSProp, AdamW
- Adam: Big Gradient = Small Steps, Small Gradient == Big Steps -->
<div class="sourceCode" id="lst:adam"><pre
class="sourceCode python"><code class="sourceCode python"><span id="lst:adam-1"><a href="#lst:adam-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Adam state (parameters, gradients first and second moments)</span></span>
<span id="lst:adam-2"><a href="#lst:adam-2" aria-hidden="true" tabindex="-1"></a>params <span class="op">=</span> <span class="bu">list</span>(f.parameters())</span>
<span id="lst:adam-3"><a href="#lst:adam-3" aria-hidden="true" tabindex="-1"></a>d_means <span class="op">=</span> [w.clone().zeros_() <span class="cf">for</span> w <span class="kw">in</span> params]</span>
<span id="lst:adam-4"><a href="#lst:adam-4" aria-hidden="true" tabindex="-1"></a>d_vars  <span class="op">=</span> [w.clone().zeros_() <span class="cf">for</span> w <span class="kw">in</span> params]</span>
<span id="lst:adam-5"><a href="#lst:adam-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="lst:adam-6"><a href="#lst:adam-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> step <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1_000</span>):</span>
<span id="lst:adam-7"><a href="#lst:adam-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Retrieve the next minibatch</span></span>
<span id="lst:adam-8"><a href="#lst:adam-8" aria-hidden="true" tabindex="-1"></a>    x, y <span class="op">=</span> next_minibatch(X, Y)</span>
<span id="lst:adam-9"><a href="#lst:adam-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="lst:adam-10"><a href="#lst:adam-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute the objective function and the gradients</span></span>
<span id="lst:adam-11"><a href="#lst:adam-11" aria-hidden="true" tabindex="-1"></a>    C <span class="op">=</span> L(f(x), y) <span class="op">+</span> lam <span class="op">*</span> R(f)</span>
<span id="lst:adam-12"><a href="#lst:adam-12" aria-hidden="true" tabindex="-1"></a>    C.backward()</span>
<span id="lst:adam-13"><a href="#lst:adam-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="lst:adam-14"><a href="#lst:adam-14" aria-hidden="true" tabindex="-1"></a>    data <span class="op">=</span> <span class="bu">zip</span>(params, d_means, d_vars)</span>
<span id="lst:adam-15"><a href="#lst:adam-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> w_idx, (w, d_m, d_v) <span class="kw">in</span> <span class="bu">enumerate</span>(data):</span>
<span id="lst:adam-16"><a href="#lst:adam-16" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Update the moments (mean and uncentered variance)</span></span>
<span id="lst:adam-17"><a href="#lst:adam-17" aria-hidden="true" tabindex="-1"></a>        d_m <span class="op">=</span> beta1 <span class="op">*</span> d_m <span class="op">+</span> (<span class="dv">1</span> <span class="op">-</span> beta1) <span class="op">*</span> w.grad</span>
<span id="lst:adam-18"><a href="#lst:adam-18" aria-hidden="true" tabindex="-1"></a>        d_v <span class="op">=</span> beta2 <span class="op">*</span> d_v <span class="op">+</span> (<span class="dv">1</span> <span class="op">-</span> beta2) <span class="op">*</span> (w.grad <span class="op">**</span> <span class="dv">2</span>)</span>
<span id="lst:adam-19"><a href="#lst:adam-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="lst:adam-20"><a href="#lst:adam-20" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Compute bias correction</span></span>
<span id="lst:adam-21"><a href="#lst:adam-21" aria-hidden="true" tabindex="-1"></a>        corr_m <span class="op">=</span> d_m <span class="op">/</span> (<span class="fl">1.0</span> <span class="op">-</span> beta1 <span class="op">**</span> step)</span>
<span id="lst:adam-22"><a href="#lst:adam-22" aria-hidden="true" tabindex="-1"></a>        corr_v <span class="op">=</span> d_v <span class="op">/</span> (<span class="fl">1.0</span> <span class="op">-</span> beta2 <span class="op">**</span> step)</span>
<span id="lst:adam-23"><a href="#lst:adam-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="lst:adam-24"><a href="#lst:adam-24" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Update weight and reset the gradient</span></span>
<span id="lst:adam-25"><a href="#lst:adam-25" aria-hidden="true" tabindex="-1"></a>        w <span class="op">-=</span> eps <span class="op">*</span> (corr_m <span class="op">/</span> (corr_v.sqrt() <span class="op">+</span> <span class="fl">1e-8</span>))</span>
<span id="lst:adam-26"><a href="#lst:adam-26" aria-hidden="true" tabindex="-1"></a>        w.grad <span class="op">=</span> <span class="va">None</span></span></code></pre></div>
<figure id="fig:sgd_moments">
<img src="./figures/core_nn_sgd_moments.svg"
alt="This toy example illustrates the impact of the optimizer choice during objective minimization with first order methods. SGD, Momentum, Adagrad, RMSProp and Adam are tasked to find the minimum of a 1-dimensional mixture of Gaussians given the same starting point x = 1 and the same learning rate \epsilon = 0.5. In this particular setup, Moments and Adagrad find the solution, RMSProp explodes, and SGD and Adam are stuck into a local minimum." />
<figcaption>Figure 10: This toy example illustrates the impact of the
optimizer choice during objective minimization with first order methods.
SGD, Momentum, Adagrad, RMSProp and Adam are tasked to find the minimum
of a 1-dimensional mixture of Gaussians given the same starting point
<span class="math inline">\(x = 1\)</span> and the same learning rate
<span class="math inline">\(\epsilon = 0.5\)</span>. In this particular
setup, Moments and Adagrad find the solution, RMSProp explodes, and SGD
and Adam are stuck into a local minimum.</figcaption>
</figure>
<p><strong>Cross-Validation and HyperParameter Search:</strong> As
illustrated by the toy examples (see Figs <a href="#fig:toysgd">9</a>,
<a href="#fig:sgd_moments">10</a>), the training of NN using SGD is
highly dependent on the initial setting of hyperparameters. One could
ask if there is a rule for choosing such parameters. Unfortunately, this
is not the case. The field is highly empirical and driven by exploration
using the scientific method.</p>
<p>One common approach is to set up metrics to evaluate the performance
of the model during the optimization process. It is a good practice to
divide the dataset into validation folds that are different from the
training data to evaluate the generalization capabilities of the model.
This practice is referred to as <span
class="math inline">\(k\)</span>-fold cross-validation and is most of
the time in DL, because of the large datasets, reduced to a single fold,
called the validation set. By defining such a process, NN can be
compared in a controlled manner and the hyperparameter space can be
searched. Hyperparameter search is so important that it is a subfield of
its own. The broad DL literature however contains many examples of
initial parameters and architectures that can be used to bootstrap this
search.</p>
<h4 id="sec:backpropagation">Backpropagation</h4>
<p>In the previous sub-section (see <a
href="#sec:optimization">Sec 2.2.2.2</a>), we saw how to learn
parametrized functions <span class="math inline">\(f_\theta\)</span>
given a training dataset. By evaluating the gradients of the objective
function with respect to the model’s parameters, it is possible to
obtain a good enough mapping <span class="math inline">\(f_\theta: X
\rightarrow Y\)</span>. In this sub-section, we discuss backpropagation,
the recursive algorithm used to efficiently compute those gradients
exploiting the chain rule <span class="math inline">\(\frac{\partial
z}{\partial x} = \frac{\partial z}{\partial y} \cdot \frac{\partial
y}{\partial x}\)</span> with <span class="math inline">\(z\)</span>
dependant on <span class="math inline">\(y\)</span> and <span
class="math inline">\(y\)</span> on <span
class="math inline">\(x\)</span>.</p>
<p><strong>Automatic Differentiation:</strong> In mathematics, Automatic
Differentiation (AD) describes the set of techniques used to evaluate
the derivative of a function and exploits the fact that any complex
computation can be transformed into a sequence of elementary operations
and functions with known symbolic derivatives. By applying the chain
rule recursively to this sequence of operations, one can automatically
compute the derivatives with precision at the cost of storage.</p>
<p>We distinguish two modes of operation for AD, forward mode
differentiation, and reverse mode differentiation. In forward mode, the
derivatives are computed after applying each elementary operation and
function in order using the chain rule. It requires storing the
gradients along the way and carrying them until the last computation.
This mode is preferred when the size of the outputs exceeds the size of
the inputs. This is generally not the case for NN where the input, an
image for example, is larger than the output, a scalar for the objective
function. On the opposite, reverse mode differentiation traverses the
sequence of operations from end to start using the chain rule and
requires storing the output of the operations instead. This method is
preferred when the size of the inputs exceeds the outputs. This mode
thus has to happen in two passes, a forward pass where one computes the
output of every operation in the order, and a backward pass, where the
sequence of operations is traversed in backward order to compute the
derivatives.</p>
<p><strong>Computation Graph:</strong> A NN can be defined as a
succession of linear transformations followed by non-linear activations
(discussed in the next sub-section <a href="#sec:nn">Sec 2.2.2.4</a>).
Those elementary operations are differentiable and when thinking of the
data flow can be viewed as a computation Directed Acyclic Graph (DAG) to
which backpropagation, reverse mode differentiation, can be applied.</p>
<p>In modern DL frameworks <span class="citation"
data-cites="pytorch tensorflow">[<a href="#ref-tensorflow"
role="doc-biblioref">1</a>, <a href="#ref-pytorch"
role="doc-biblioref">42</a>]</span>, the AD is centered on the
implementation of a Graph object with Nodes. Both entities possess a
<code>forward()</code> and a <code>backward()</code> function. The
forward pass calls the <code>forward()</code> function of each node of
the graph by traversing it in order while saving the node output for
differentiation. The backward pass traverses the graph recursively in
backward order calling the <code>backward()</code> function responsible
for computing the local gradient of the node operation and multiplying
it by its output gradient following the chain rule. Nodes are in most
frameworks referred to as Layers, the elementary building block of the
NN operation chain.</p>
<p><strong>Eager or Graph Execution:</strong> Modern DL frameworks such
as PyTorch <span class="citation" data-cites="pytorch">[<a
href="#ref-pytorch" role="doc-biblioref">42</a>]</span> and Tensorflow
<span class="citation" data-cites="tensorflow">[<a
href="#ref-tensorflow" role="doc-biblioref">1</a>]</span> now propose
two execution modes. An eager mode, where the graph is built dynamically
and operations are applied immediately, and a graph mode where the
computational graph has to be defined beforehand. Both modes come with
advantages and inconveniences. Eager mode is useful for iterative
development and provides an intuitive interface similar to imperative
programming, it is easier to debug and offers natural control flows as
well as hardware acceleration support. On the other side, graph mode
allows for more efficient execution. The graph can be optimized by
applying operations similar to the ones used in programming language
Abstract Syntax Trees (AST). Graph edges can be merged into a single
fused operation, and execution can be optimized for parallelization. It
is often the preferred way for deployment where the execution time and
memory are at stake.</p>
<h4 id="sec:nn">Neural Network</h4>
<h4 id="convolutional-neural-network">Convolutional Neural Network</h4>
<h3 id="sec:generative">Generative Architectures</h3>
<h4 id="autoencoders">Autoencoders</h4>
<h4 id="variational-autoencoders">Variational Autoencoders</h4>
<h4 id="generative-adversarial-networks">Generative Adversarial
Networks</h4>
<h4 id="denoising-diffusion-models">Denoising Diffusion Models</h4>
<h3 id="sec:attention">Attention Machanism</h3>
<h4 id="multihead-self-attention">Multihead Self-Attention</h4>
<h4 id="large-language-models">Large Language Models</h4>

<h2 id="ch:methodology">Methodology</h2>
<h3 id="implementation">Implementation</h3>
<h3 id="objective-evaluation">Objective Evaluation</h3>
<h3 id="subjective-evaluation">Subjective Evaluation</h3>
<h3 id="reproducibility">Reproducibility</h3>

<h1 id="core">Core</h1>
<h2 id="ch:contrib-1">Contrib I (Find Catchy Explicit Name)</h2>
<h3 id="state-of-the-art">State of the Art</h3>
<h3 id="method">Method</h3>
<h3 id="setup">Setup</h3>
<h3 id="results">Results</h3>
<h3 id="summary">Summary</h3>

<h2 id="ch:contrib-2">Contrib II (Find Catchy Explicit Name)</h2>
<h3 id="state-of-the-art-1">State of the Art</h3>
<h3 id="method-1">Method</h3>
<h3 id="setup-1">Setup</h3>
<h3 id="results-1">Results</h3>
<h3 id="summary-1">Summary</h3>

<h2 id="ch:contrib-3">Contrib III (Find Catchy Explicit Name)</h2>
<h3 id="state-of-the-art-2">State of the Art</h3>
<h3 id="method-2">Method</h3>
<h3 id="setup-2">Setup</h3>
<h3 id="results-2">Results</h3>
<h3 id="summary-2">Summary</h3>

<h2 id="ch:contrib-4">Contrib IV (Find Catchy Explicit Name)</h2>
<h3 id="state-of-the-art-3">State of the Art</h3>
<h3 id="method-3">Method</h3>
<h3 id="setup-3">Setup</h3>
<h3 id="results-3">Results</h3>
<h3 id="summary-3">Summary</h3>

<h1 id="reflection">Reflection</h1>
<h2 id="ch:ethical-and-societal-impact">Ethical and Societal Impact</h2>

<h2 id="ch:conclusion">Conclusion</h2>

<h2 class="unnumbered" id="references">References</h2>
<div id="refs" class="references csl-bib-body" role="list">
<div id="ref-tensorflow" class="csl-entry" role="listitem">
<div class="csl-left-margin">[1] </div><div
class="csl-right-inline">Abadi, M., Barham, P., Chen, J., Chen, Z.,
Davis, A., Dean, J., Devin, M., Ghemawat, S., Irving, G., Isard, M., et
al. 2016. Tensorflow: A system for large-scale machine learning.
<em>Osdi</em> (2016), 265–283.</div>
</div>
<div id="ref-john_1992" class="csl-entry" role="listitem">
<div class="csl-left-margin">[2] </div><div
class="csl-right-inline">Anderson, J.R. 1992. Automaticity and the ACT
theory. <em>The American Journal of Psychology</em>. 105, 2 (1992),
165–180. DOI:https://doi.org/<a
href="https://doi.org/10.2307/1423026">10.2307/1423026</a>.</div>
</div>
<div id="ref-brown_2020" class="csl-entry" role="listitem">
<div class="csl-left-margin">[3] </div><div
class="csl-right-inline">Brown, T., Mann, B., Ryder, N., Subbiah, M.,
Kaplan, J.D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G.,
Askell, A., et al. 2020. Language models are few-shot learners.
<em>Advances in neural information processing systems</em>. 33, (2020),
1877–1901.</div>
</div>
<div id="ref-openai_2023" class="csl-entry" role="listitem">
<div class="csl-left-margin">[4] </div><div
class="csl-right-inline">CHATGPT: Optimizing language models for
dialogue: 2023. <a
href="https://openai.com/blog/chatgpt/"><em>https://openai.com/blog/chatgpt/</em></a>.
Accessed: 2023-01-26.</div>
</div>
<div id="ref-ci_2018" class="csl-entry" role="listitem">
<div class="csl-left-margin">[5] </div><div class="csl-right-inline">Ci,
Y., Ma, X., Wang, Z., Li, H. and Luo, Z. 2018. <a
href="https://doi.org/10.1145/3240508.3240661">User-guided deep anime
line art colorization with conditional adversarial networks</a>.
<em>Proceedings of the 26th ACM international conference on
multimedia</em> (New York, NY, USA, 2018), 1536–1544.</div>
</div>
<div id="ref-clipstudiopaint" class="csl-entry" role="listitem">
<div class="csl-left-margin">[6] </div><div
class="csl-right-inline">Clip studio PAINT: <a
href="https://www.clipstudio.net/"><em>https://www.clipstudio.net/</em></a>.
Accessed: 2023-01-26.</div>
</div>
<div id="ref-cortes_1995" class="csl-entry" role="listitem">
<div class="csl-left-margin">[7] </div><div
class="csl-right-inline">Cortes, C. and Vapnik, V. 1995. Support-vector
networks. <em>Machine Learning</em>. 20, 3 (Sep. 1995), 273–297.
DOI:https://doi.org/<a
href="https://doi.org/10.1007/BF00994018">10.1007/BF00994018</a>.</div>
</div>
<div id="ref-deng_2009" class="csl-entry" role="listitem">
<div class="csl-left-margin">[8] </div><div
class="csl-right-inline">Deng, J., Dong, W., Socher, R., Li, L.-J., Li,
K. and Fei-Fei, L. 2009. <a
href="https://doi.org/10.1109/CVPR.2009.5206848">ImageNet: A large-scale
hierarchical image database</a>. <em>2009 IEEE conference on computer
vision and pattern recognition</em> (2009), 248–255.</div>
</div>
<div id="ref-duchi_2011" class="csl-entry" role="listitem">
<div class="csl-left-margin">[9] </div><div
class="csl-right-inline">Duchi, J., Hazan, E. and Singer, Y. 2011. <a
href="http://jmlr.org/papers/v12/duchi11a.html">Adaptive subgradient
methods for online learning and stochastic optimization</a>. <em>Journal
of Machine Learning Research</em>. 12, 61 (2011), 2121–2159.</div>
</div>
<div id="ref-frans_2017" class="csl-entry" role="listitem">
<div class="csl-left-margin">[10] </div><div
class="csl-right-inline">Frans, K. 2017. <a
href="http://arxiv.org/abs/1704.08834">Outline colorization through
tandem adversarial networks</a>. <em>CoRR</em>. abs/1704.08834,
(2017).</div>
</div>
<div id="ref-fukushima_1980" class="csl-entry" role="listitem">
<div class="csl-left-margin">[11] </div><div
class="csl-right-inline">Fukushima, K. 1980. Neocognitron: A
self-organizing neural network model for a mechanism of pattern
recognition unaffected by shift in position. <em>Biological
Cybernetics</em>. 36, 4 (Apr. 1980), 193–202. DOI:https://doi.org/<a
href="https://doi.org/10.1007/BF00344251">10.1007/BF00344251</a>.</div>
</div>
<div id="ref-furusawa_2O17" class="csl-entry" role="listitem">
<div class="csl-left-margin">[12] </div><div
class="csl-right-inline">Furusawa, C., Hiroshiba, K., Ogaki, K. and
Odagiri, Y. 2017. <a
href="https://doi.org/10.1145/3145749.3149430">Comicolorization:
Semi-automatic manga colorization</a>. <em>SIGGRAPH asia 2017 technical
briefs</em> (New York, NY, USA, 2017).</div>
</div>
<div id="ref-goodfellow_2016" class="csl-entry" role="listitem">
<div class="csl-left-margin">[13] </div><div
class="csl-right-inline">Goodfellow, I.J., Bengio, Y. and Courville, A.
2016. <em>Deep learning</em>. MIT Press.</div>
</div>
<div id="ref-goodfellow_2014" class="csl-entry" role="listitem">
<div class="csl-left-margin">[14] </div><div
class="csl-right-inline">Goodfellow, I., Pouget-Abadie, J., Mirza, M.,
Xu, B., Warde-Farley, D., Ozair, S., Courville, A. and Bengio, Y. 2014.
<a
href="https://proceedings.neurips.cc/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf">Generative
adversarial nets</a>. <em>Advances in neural information processing
systems</em> (2014).</div>
</div>
<div id="ref-hati_2019" class="csl-entry" role="listitem">
<div class="csl-left-margin">[15] </div><div
class="csl-right-inline">Hati, Y., Jouet, G., Rousseaux, F. and Duhart,
C. 2019. <a href="https://doi.org/10.1145/3359998.3369401">PaintsTorch:
A user-guided anime line art colorization tool with double generator
conditional adversarial network</a>. <em>European conference on visual
media production</em> (New York, NY, USA, 2019).</div>
</div>
<div id="ref-hati_2023" class="csl-entry" role="listitem">
<div class="csl-left-margin">[16] </div><div
class="csl-right-inline">Hati, Y., Thevenin, V., Nolot, F., Rousseaux,
F. and Duhart, C. 2023. StencilTorch: An iterative and user-guided
framework for anime lineart colorization. <em>Image and vision
computing</em> (Cham, 2023), 1–17.</div>
</div>
<div id="ref-he_2016" class="csl-entry" role="listitem">
<div class="csl-left-margin">[17] </div><div
class="csl-right-inline">He, K., Zhang, X., Ren, S. and Sun, J. 2016.
Deep residual learning for image recognition. <em>Proceedings of the
IEEE conference on computer vision and pattern recognition</em> (2016),
770–778.</div>
</div>
<div id="ref-hensman_2017" class="csl-entry" role="listitem">
<div class="csl-left-margin">[18] </div><div
class="csl-right-inline">Hensman, P. and Aizawa, K. 2017. <a
href="https://doi.org/10.1109/ICDAR.2017.295">cGAN-based manga
colorization using a single training image</a>. <em>2017 14th IAPR
international conference on document analysis and recognition
(ICDAR)</em> (Los Alamitos, CA, USA, Nov. 2017), 72–77.</div>
</div>
<div id="ref-hinton_lecture6a" class="csl-entry" role="listitem">
<div class="csl-left-margin">[19] </div><div
class="csl-right-inline">Hinton, G., Srivastava, N. and Swersky, K.
Neural networks for machine learning: Overview of mini-batch gradient
descent.</div>
</div>
<div id="ref-ho_2020" class="csl-entry" role="listitem">
<div class="csl-left-margin">[20] </div><div
class="csl-right-inline">Ho, J., Jain, A. and Abbeel, P. 2020. Denoising
diffusion probabilistic models. <em>Advances in Neural Information
Processing Systems</em>. 33, (2020), 6840–6851.</div>
</div>
<div id="ref-hochreiter_1997" class="csl-entry" role="listitem">
<div class="csl-left-margin">[21] </div><div
class="csl-right-inline">Hochreiter, S. and Schmidhuber, J. 1997.
<span>Long Short-Term Memory</span>. <em>Neural Computation</em>. 9, 8
(Nov. 1997), 1735–1780. DOI:https://doi.org/<a
href="https://doi.org/10.1162/neco.1997.9.8.1735">10.1162/neco.1997.9.8.1735</a>.</div>
</div>
<div id="ref-jackson_1998" class="csl-entry" role="listitem">
<div class="csl-left-margin">[22] </div><div
class="csl-right-inline">Jackson, P. 1998. <em>Introduction to expert
systems</em>. Addison-Wesley Longman Publishing Co., Inc.</div>
</div>
<div id="ref-jumper_2021" class="csl-entry" role="listitem">
<div class="csl-left-margin">[23] </div><div
class="csl-right-inline">Jumper, J. et al. 2021. Highly accurate protein
structure prediction with AlphaFold. <em>Nature</em>. 596, 7873 (Aug.
2021), 583–589. DOI:https://doi.org/<a
href="https://doi.org/10.1038/s41586-021-03819-2">10.1038/s41586-021-03819-2</a>.</div>
</div>
<div id="ref-kandinsky_1977" class="csl-entry" role="listitem">
<div class="csl-left-margin">[24] </div><div
class="csl-right-inline">Kandinsky, W. and Sadleir, M. 1977.
<em>Concerning the spiritual in art</em>. Dover Publications.</div>
</div>
<div id="ref-kim_2019" class="csl-entry" role="listitem">
<div class="csl-left-margin">[25] </div><div
class="csl-right-inline">Kim, H., Jhoo, H.Y., Park, E. and Yoo, S. 2019.
<a href="https://doi.org/10.1109/ICCV.2019.00915">Tag2Pix: Line art
colorization using text tag with SECat and changing loss</a>. <em>2019
IEEE/CVF international conference on computer vision (ICCV)</em> (2019),
9055–9064.</div>
</div>
<div id="ref-kingma_2014" class="csl-entry" role="listitem">
<div class="csl-left-margin">[26] </div><div
class="csl-right-inline">Kingma, D.P. and Ba, J. 2014. Adam: A method
for stochastic optimization. <em>arXiv preprint arXiv:1412.6980</em>.
(2014).</div>
</div>
<div id="ref-kingma_2013" class="csl-entry" role="listitem">
<div class="csl-left-margin">[27] </div><div
class="csl-right-inline">Kingma, D.P. and Welling, M. 2013.
Auto-encoding variational bayes. <em>arXiv preprint
arXiv:1312.6114</em>. (2013).</div>
</div>
<div id="ref-krizhevsky_2012" class="csl-entry" role="listitem">
<div class="csl-left-margin">[28] </div><div
class="csl-right-inline">Krizhevsky, A., Sutskever, I. and Hinton, G.E.
2012. <a
href="https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf">ImageNet
classification with deep convolutional neural networks</a>. <em>Advances
in neural information processing systems</em> (2012).</div>
</div>
<div id="ref-larid_2019" class="csl-entry" role="listitem">
<div class="csl-left-margin">[29] </div><div
class="csl-right-inline">Laird, J.E. 2019. <em>The soar cognitive
architecture</em>. The MIT Press.</div>
</div>
<div id="ref-lecun_2019" class="csl-entry" role="listitem">
<div class="csl-left-margin">[30] </div><div class="csl-right-inline">Le
Cun, Y. 2019. <em><a
href="https://www.odilejacob.fr/catalogue/sciences-humaines/questions-de-societe/quand-la-machine-apprend_9782738149312.php">Quand
la machine apprend: La r<span>é</span>volution des neurones artificiels
et de l’apprentissage profond</a></em>. Odile Jacob.</div>
</div>
<div id="ref-lecun_1989" class="csl-entry" role="listitem">
<div class="csl-left-margin">[31] </div><div
class="csl-right-inline">LeCun, Y., Boser, B., Denker, J.S., Henderson,
D., Howard, R.E., Hubbard, W. and Jackel, L.D. 1989. <span
class="nocase">Backpropagation Applied to Handwritten Zip Code
Recognition</span>. <em>Neural Computation</em>. 1, 4 (Dec. 1989),
541–551. DOI:https://doi.org/<a
href="https://doi.org/10.1162/neco.1989.1.4.541">10.1162/neco.1989.1.4.541</a>.</div>
</div>
<div id="ref-lecun_1998" class="csl-entry" role="listitem">
<div class="csl-left-margin">[32] </div><div
class="csl-right-inline">Lecun, Y., Bottou, L., Bengio, Y. and Haffner,
P. 1998. Gradient-based learning applied to document recognition.
<em>Proceedings of the IEEE</em>. 86, 11 (1998), 2278–2324.
DOI:https://doi.org/<a
href="https://doi.org/10.1109/5.726791">10.1109/5.726791</a>.</div>
</div>
<div id="ref-lieto_2021" class="csl-entry" role="listitem">
<div class="csl-left-margin">[33] </div><div
class="csl-right-inline">Lieto, A. 2021. <em><a
href="https://doi.org/10.4324/9781315460536">Cognitive design for
artificial minds (1st ed.)</a></em>. Routledge.</div>
</div>
<div id="ref-liu_2017" class="csl-entry" role="listitem">
<div class="csl-left-margin">[34] </div><div
class="csl-right-inline">Liu, Y., Qin, Z., Wan, T. and Luo, Z. 2018.
Auto-painter: Cartoon image generation from sketch by using conditional
wasserstein generative adversarial networks. <em>Neurocomputing</em>.
311, (2018), 78–87. DOI:https://doi.org/<a
href="https://doi.org/10.1016/j.neucom.2018.05.045">10.1016/j.neucom.2018.05.045</a>.</div>
</div>
<div id="ref-loshchilov_2017" class="csl-entry" role="listitem">
<div class="csl-left-margin">[35] </div><div
class="csl-right-inline">Loshchilov, I. and Hutter, F. 2017. Decoupled
weight decay regularization. <em>arXiv preprint arXiv:1711.05101</em>.
(2017).</div>
</div>
<div id="ref-mccarthy_1978" class="csl-entry" role="listitem">
<div class="csl-left-margin">[36] </div><div
class="csl-right-inline">McCarthy, J. 1978. <a
href="https://doi.org/10.1145/800025.1198360">History of LISP</a>.
<em>History of programming languages</em>. Association for Computing
Machinery. 173–185.</div>
</div>
<div id="ref-dartmouth_2006" class="csl-entry" role="listitem">
<div class="csl-left-margin">[37] </div><div
class="csl-right-inline">McCarthy, J., Minsky, M.L., Rochester, N. and
Shannon, C.E. 2006. A proposal for the dartmouth summer research project
on artificial intelligence, august 31, 1955. <em>AI Magazine</em>. 27, 4
(2006), 12. DOI:https://doi.org/<a
href="https://doi.org/10.1609/aimag.v27i4.1904">10.1609/aimag.v27i4.1904</a>.</div>
</div>
<div id="ref-minsky_1969" class="csl-entry" role="listitem">
<div class="csl-left-margin">[38] </div><div
class="csl-right-inline">Minsky, M. and Papert, S. 1969.
<em>Perceptrons: An introduction to computational geometry</em>. MIT
Press.</div>
</div>
<div id="ref-mumford_2012" class="csl-entry" role="listitem">
<div class="csl-left-margin">[39] </div><div
class="csl-right-inline">Mumford, M., Medeiros, K. and Partlow, P. 2012.
Creative thinking: Processes, strategies, and knowledge. <em>The Journal
of Creative Behavior</em>. 46, (Mar. 2012). DOI:https://doi.org/<a
href="https://doi.org/10.1002/jocb.003">10.1002/jocb.003</a>.</div>
</div>
<div id="ref-newell_1959" class="csl-entry" role="listitem">
<div class="csl-left-margin">[40] </div><div
class="csl-right-inline">Newell, A., Shaw, J.C. and Simon, H.A. 1959.
<em><a href="https://doi.org/10.1037/13117-003">The processes of
creative thinking</a></em>. RAND Corporation.</div>
</div>
<div id="ref-paintman" class="csl-entry" role="listitem">
<div class="csl-left-margin">[41] </div><div
class="csl-right-inline">Paintman: <a
href="http://www.retasstudio.net/products/paintman/"><em>http://www.retasstudio.net/products/paintman/</em></a>.
Accessed: 2023-01-26.</div>
</div>
<div id="ref-pytorch" class="csl-entry" role="listitem">
<div class="csl-left-margin">[42] </div><div
class="csl-right-inline">Paszke, A. et al. 2019. PyTorch: An imperative
style, high-performance deep learning library. <em>Proceedings of the
33rd international conference on neural information processing
systems</em>. Curran Associates Inc.</div>
</div>
<div id="ref-paintschainer_2017" class="csl-entry" role="listitem">
<div class="csl-left-margin">[43] </div><div
class="csl-right-inline">Pelica paint: 2017. <a
href="https://petalica-paint.pixiv.dev/index_en.html"><em>https://petalica-paint.pixiv.dev/index_en.html</em></a>.
Accessed: 2023-01-26.</div>
</div>
<div id="ref-photoshop" class="csl-entry" role="listitem">
<div class="csl-left-margin">[44] </div><div
class="csl-right-inline">Photoshop: <a
href="https://www.adobe.com/products/photoshop.html"><em>https://www.adobe.com/products/photoshop.html</em></a>.
Accessed: 2023-01-26.</div>
</div>
<div id="ref-qian_1999" class="csl-entry" role="listitem">
<div class="csl-left-margin">[45] </div><div
class="csl-right-inline">Qian, N. 1999. On the momentum term in gradient
descent learning algorithms. <em>Neural Networks</em>. 12, 1 (1999),
145–151. DOI:https://doi.org/<a
href="https://doi.org/10.1016/S0893-6080(98)00116-6">10.1016/S0893-6080(98)00116-6</a>.</div>
</div>
<div id="ref-rombach_2021" class="csl-entry" role="listitem">
<div class="csl-left-margin">[46] </div><div
class="csl-right-inline">Rombach, R., Blattmann, A., Lorenz, D., Esser,
P. and Ommer, B. 2021. <a
href="https://arxiv.org/abs/2112.10752">High-resolution image synthesis
with latent diffusion models</a>.</div>
</div>
<div id="ref-rosenblatt_1958" class="csl-entry" role="listitem">
<div class="csl-left-margin">[47] </div><div
class="csl-right-inline">Rosenblatt, F. 1958. <span class="nocase">The
perceptron: A probabilistic model for information storage and
organization in the brain.</span> <em>Psychological Review</em>. 65, 6
(1958), 386–408. DOI:https://doi.org/<a
href="https://doi.org/10.1037/h0042519">10.1037/h0042519</a>.</div>
</div>
<div id="ref-rumelhart_1986" class="csl-entry" role="listitem">
<div class="csl-left-margin">[48] </div><div
class="csl-right-inline">Rumelhart, D.E., Hinton, G.E. and Williams,
R.J. 1986. Learning representations by back-propagating errors.
<em>Nature</em>. 323, 6088 (Oct. 1986), 533–536. DOI:https://doi.org/<a
href="https://doi.org/10.1038/323533a0">10.1038/323533a0</a>.</div>
</div>
<div id="ref-russell_2016" class="csl-entry" role="listitem">
<div class="csl-left-margin">[49] </div><div
class="csl-right-inline">Russell, S.J. and Norvig, P. 2009.
<em>Artificial intelligence: A modern approach</em>. Pearson.</div>
</div>
<div id="ref-saito_2015" class="csl-entry" role="listitem">
<div class="csl-left-margin">[50] </div><div
class="csl-right-inline">Saito, M. and Matsui, Y. 2015. <a
href="https://doi.org/10.1145/2820903.2820907">Illustration2Vec: A
semantic vector representation of illustrations</a>. <em>SIGGRAPH asia
2015 technical briefs</em> (New York, NY, USA, 2015), 5:1–5:4.</div>
</div>
<div id="ref-sangkloy_2016" class="csl-entry" role="listitem">
<div class="csl-left-margin">[51] </div><div
class="csl-right-inline">Sangkloy, P., Lu, J., Fang, C., Yu, F. and
Hays, J. 2017. <a
href="https://doi.org/10.1109/CVPR.2017.723">Scribbler: Controlling deep
image synthesis with sketch and color</a>. <em>2017 <span>IEEE</span>
conference on computer vision and pattern recognition, <span>CVPR</span>
2017, honolulu, HI, USA, july 21-26, 2017</em> (2017), 6836–6845.</div>
</div>
<div id="ref-senior_2020" class="csl-entry" role="listitem">
<div class="csl-left-margin">[52] </div><div
class="csl-right-inline">Senior, A.W. et al. 2020. Improved protein
structure prediction using potentials from deep learning.
<em>Nature</em>. 577, 7792 (Jan. 2020), 706–710. DOI:https://doi.org/<a
href="https://doi.org/10.1038/s41586-019-1923-7">10.1038/s41586-019-1923-7</a>.</div>
</div>
<div id="ref-silver_2016" class="csl-entry" role="listitem">
<div class="csl-left-margin">[53] </div><div
class="csl-right-inline">Silver, D. et al. 2016. Mastering the game of
go with deep neural networks and tree search. <em>Nature</em>. 529, 7587
(Jan. 2016), 484–489. DOI:https://doi.org/<a
href="https://doi.org/10.1038/nature16961">10.1038/nature16961</a>.</div>
</div>
<div id="ref-vaswani_2017" class="csl-entry" role="listitem">
<div class="csl-left-margin">[54] </div><div
class="csl-right-inline">Vaswani, A., Shazeer, N., Parmar, N.,
Uszkoreit, J., Jones, L., Gomez, A.N., Kaiser, Ł. and Polosukhin, I.
2017. Attention is all you need. <em>Advances in neural information
processing systems</em>. 30, (2017).</div>
</div>
<div id="ref-vinyals_2019" class="csl-entry" role="listitem">
<div class="csl-left-margin">[55] </div><div
class="csl-right-inline">Vinyals, O. et al. 2019. Grandmaster level in
StarCraft II using multi-agent reinforcement learning. <em>Nature</em>.
575, 7782 (Nov. 2019), 350–354. DOI:https://doi.org/<a
href="https://doi.org/10.1038/s41586-019-1724-z">10.1038/s41586-019-1724-z</a>.</div>
</div>
<div id="ref-wolf_2017" class="csl-entry" role="listitem">
<div class="csl-left-margin">[56] </div><div
class="csl-right-inline">Wolf, M.J., Miller, K. and Grodzinsky, F.S.
2017. Why we should have seen that coming: Comments on microsoft’s tay
"experiment," and wider implications. <em>SIGCAS Comput. Soc.</em> 47, 3
(Sep. 2017), 54–64. DOI:https://doi.org/<a
href="https://doi.org/10.1145/3144592.3144598">10.1145/3144592.3144598</a>.</div>
</div>
<div id="ref-aston_zhang_2021" class="csl-entry" role="listitem">
<div class="csl-left-margin">[57] </div><div
class="csl-right-inline">Zhang, A., Lipton, Z.C., Li, M. and Smola, A.J.
2021. Dive into deep learning. <em>arXiv preprint arXiv:2106.11342</em>.
(2021).</div>
</div>
<div id="ref-zhang_ji_2017" class="csl-entry" role="listitem">
<div class="csl-left-margin">[58] </div><div
class="csl-right-inline">Zhang, L., Ji, Y., Lin, X. and Liu, C. 2017. <a
href="https://doi.org/10.1109/ACPR.2017.61">Style transfer for anime
sketches with enhanced residual u-net and auxiliary classifier GAN</a>.
<em>2017 4th IAPR asian conference on pattern recognition (ACPR)</em>
(2017), 506–511.</div>
</div>
<div id="ref-zhang_richard_2017" class="csl-entry" role="listitem">
<div class="csl-left-margin">[59] </div><div
class="csl-right-inline">Zhang, R., Zhu, J.-Y., Isola, P., Geng, X.,
Lin, A.S., Yu, T. and Efros, A.A. 2017. Real-time user-guided image
colorization with learned deep priors. <em>ACM Trans. Graph.</em> 36, 4
(Jul. 2017). DOI:https://doi.org/<a
href="https://doi.org/10.1145/3072959.3073703">10.1145/3072959.3073703</a>.</div>
</div>
</div>
</body>
</html>
