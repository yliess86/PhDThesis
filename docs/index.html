<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US" xml:lang="en-US">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Yliess Hati" />
  <meta name="keywords" content="keyword" />
  <title>AI-Assisted Creative Expression: a Case for Automatic Lineart Colorization</title>
  <style>
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
    /* CSS for citations */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
    }
    .hanging-indent div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }  </style>
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  <script
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<header id="title-block-header">
<h1 class="title"><p>AI-Assisted Creative Expression: a Case for
Automatic Lineart Colorization</p></h1>
<p class="author">Yliess Hati</p>
</header>
<nav id="TOC" role="doc-toc">
<h2 id="toc-title">Contents</h2>
<ul>
<li><a href="#list-of-abbreviations" id="toc-list-of-abbreviations">List
of Abbreviations</a></li>
<li><a href="#acronym-list" id="toc-acronym-list">Acronyms</a></li>
<li><a href="#abstract" id="toc-abstract">Abstract</a></li>
<li><a href="#aknowledgements"
id="toc-aknowledgements">Aknowledgements</a></li>
<li><a href="#context" id="toc-context">Context</a>
<ul>
<li><a href="#ch:introduction" id="toc-ch:introduction">Introduction</a>
<ul>
<li><a href="#motivations" id="toc-motivations">Motivations</a></li>
<li><a href="#problem-statement" id="toc-problem-statement">Problem
Statement</a></li>
<li><a href="#contributions"
id="toc-contributions">Contributions</a></li>
<li><a href="#concerns" id="toc-concerns">Concerns</a></li>
<li><a href="#outline" id="toc-outline">Outline</a></li>
</ul></li>
<li><a href="#ch:background" id="toc-ch:background">Background</a>
<ul>
<li><a href="#sec:history" id="toc-sec:history">A Brief History of
Artificial Intelligence</a></li>
<li><a href="#sec:core" id="toc-sec:core">Core Principles</a></li>
<li><a href="#sec:nn" id="toc-sec:nn">Neural Networks</a></li>
<li><a href="#sec:generative" id="toc-sec:generative">Generative
Architectures</a></li>
<li><a href="#sec:attention" id="toc-sec:attention">Attention
Machanism</a></li>
</ul></li>
<li><a href="#ch:methodology" id="toc-ch:methodology">Methodology</a>
<ul>
<li><a href="#implementation"
id="toc-implementation">Implementation</a></li>
<li><a href="#objective-evaluation"
id="toc-objective-evaluation">Objective Evaluation</a></li>
<li><a href="#subjective-evaluation"
id="toc-subjective-evaluation">Subjective Evaluation</a></li>
<li><a href="#reproducibility"
id="toc-reproducibility">Reproducibility</a></li>
</ul></li>
</ul></li>
<li><a href="#core" id="toc-core">Core</a>
<ul>
<li><a href="#ch:contrib-1" id="toc-ch:contrib-1">Contrib I (Find Catchy
Explicit Name)</a>
<ul>
<li><a href="#state-of-the-art" id="toc-state-of-the-art">State of the
Art</a></li>
<li><a href="#method" id="toc-method">Method</a></li>
<li><a href="#setup" id="toc-setup">Setup</a></li>
<li><a href="#results" id="toc-results">Results</a></li>
<li><a href="#summary" id="toc-summary">Summary</a></li>
</ul></li>
<li><a href="#ch:contrib-2" id="toc-ch:contrib-2">Contrib II (Find
Catchy Explicit Name)</a>
<ul>
<li><a href="#state-of-the-art-1" id="toc-state-of-the-art-1">State of
the Art</a></li>
<li><a href="#method-1" id="toc-method-1">Method</a></li>
<li><a href="#setup-1" id="toc-setup-1">Setup</a></li>
<li><a href="#results-1" id="toc-results-1">Results</a></li>
<li><a href="#summary-1" id="toc-summary-1">Summary</a></li>
</ul></li>
<li><a href="#ch:contrib-3" id="toc-ch:contrib-3">Contrib III (Find
Catchy Explicit Name)</a>
<ul>
<li><a href="#state-of-the-art-2" id="toc-state-of-the-art-2">State of
the Art</a></li>
<li><a href="#method-2" id="toc-method-2">Method</a></li>
<li><a href="#setup-2" id="toc-setup-2">Setup</a></li>
<li><a href="#results-2" id="toc-results-2">Results</a></li>
<li><a href="#summary-2" id="toc-summary-2">Summary</a></li>
</ul></li>
<li><a href="#ch:contrib-4" id="toc-ch:contrib-4">Contrib IV (Find
Catchy Explicit Name)</a>
<ul>
<li><a href="#state-of-the-art-3" id="toc-state-of-the-art-3">State of
the Art</a></li>
<li><a href="#method-3" id="toc-method-3">Method</a></li>
<li><a href="#setup-3" id="toc-setup-3">Setup</a></li>
<li><a href="#results-3" id="toc-results-3">Results</a></li>
<li><a href="#summary-3" id="toc-summary-3">Summary</a></li>
</ul></li>
</ul></li>
<li><a href="#reflection" id="toc-reflection">Reflection</a>
<ul>
<li><a href="#ch:ethical-and-societal-impact"
id="toc-ch:ethical-and-societal-impact">Ethical and Societal
Impact</a></li>
<li><a href="#ch:conclusion" id="toc-ch:conclusion">Conclusion</a></li>
<li><a href="#references" id="toc-references">References</a></li>
</ul></li>
</ul>
</nav>
<h2 class="unnumbered" id="list-of-abbreviations">List of
Abbreviations</h2>
<h1 id="acronym-list">Acronyms</h1>
<ul>
<li><strong>ACT-R</strong>: Adaptive Control of Thought—Rational</li>
<li><strong>AD</strong>: Automatic Differentiation</li>
<li><strong>AI</strong>: Artificial Intelligence</li>
<li><strong>ANN</strong>: Artificial Neural Network</li>
<li><strong>AST</strong>: Abstract Syntax Tree</li>
<li><strong>CNN</strong>: Convolutional Neural Network</li>
<li><strong>CV</strong>: Computer Vision</li>
<li><strong>DAG</strong>: Directed Acyclic Graph</li>
<li><strong>DDM</strong>: Denoising Diffusion Model</li>
<li><strong>DL</strong>: Deep Learning</li>
<li><strong>GAN</strong>: Generative Adversarial Network</li>
<li><strong>GD</strong>: Gradient Descent</li>
<li><strong>GPU</strong>: Graphical Processing Unit</li>
<li><strong>LLM</strong>: Large Language Model</li>
<li><strong>LSTM</strong>: Long Short-Term Memory</li>
<li><strong>ML</strong>: Machine Learning</li>
<li><strong>MLP</strong>: Multi-Layer Perceptron</li>
<li><strong>MNIST</strong>: Modified National Institute of Standards and
Technology</li>
<li><strong>MSE</strong>: Mean Squared Error</li>
<li><strong>NN</strong>: Neural Network</li>
<li><strong>NPU</strong>: Neural Processing Unit</li>
<li><strong>RLHF</strong>: Reinforcement Learning from Human
Feedback</li>
<li><strong>RNN</strong>: Recurrent Neural Network</li>
<li><strong>ReLU</strong>: Rectified Linear Unit</li>
<li><strong>SGD</strong>: Stochastic Gradient Descent</li>
<li><strong>SVM</strong>: Support Vector Machine</li>
<li><strong>TPU</strong>: Tensor Processing Unit</li>
<li><strong>VAE</strong>: Variational Autoencoder</li>
</ul>
<h2 class="unnumbered" id="abstract">Abstract</h2>

<h2 class="unnumbered" id="aknowledgements">Aknowledgements</h2>

<h1 id="context">Context</h1>
<h2 id="ch:introduction">Introduction</h2>
<p>Humans possess the ability to perceive and understand the world
allowing us to accomplish a wide range of complex tasks through the
combination of visual recognition, scene understanding, and
communication. The ability to quickly and accurately extract information
from a single image is a testament to the complexity and sophistication
of the human brain and is often taken for granted. One of the Artificial
Intelligence (AI) field’s ultimate goals is to empower computers with
such human-like abilities, one of them being creativity, being able to
produce something original and worthwhile <span class="citation"
data-cites="mumford_2012">[<a href="#ref-mumford_2012"
role="doc-biblioref">41</a>]</span>.</p>
<p>Computational creativity is the field at the intersection of AI,
cognitive psychology, philosophy, and art, which aims at understanding,
simulating, replicating, or in some cases enhancing human creativity.
One definition of computational creativity <span class="citation"
data-cites="newell_1959">[<a href="#ref-newell_1959"
role="doc-biblioref">42</a>]</span> is the ability to produce something
that is novel and useful, demands that we reject common beliefs, results
from intense motivation and persistence, or comes from clarifying a
vague problem. Top-down approaches to this definition use a mix of
explicit formulations of recipes and randomness such as procedural
generation. On the opposite, bottom-up approaches use Artificial Neural
Networks (ANN) to learn patterns and heuristics from large datasets to
enable non-linear generation.</p>
<p>We, as a species, are currently witnessing the beginning of a new era
where the gap between machines and humans is starting to blur. Current
breakthroughs in the field of AI, more specifically in Deep Learning
(DL), are giving computers the ability to perceive and understand our
world, but also to interact with our environment using natural
interactions such as speech and natural language. ANNs, once mocked by
the AI community <span class="citation" data-cites="lecun_2019">[<a
href="#ref-lecun_2019" role="doc-biblioref">32</a>]</span>, are now
trainable using Gradient Descent (GD) <span class="citation"
data-cites="rumelhart_1986">[<a href="#ref-rumelhart_1986"
role="doc-biblioref">50</a>]</span> thanks to the massive availability
of data and the processing power of modern hardware accelerators such as
Graphical Processing Units (GPU), Tensor Processing Units (TPU), and
Neural Processing Units (NPU).</p>
<p>Neural Networks (NN), those trainable general function approximators,
gave rise to the field of generative NNs. Specialized DL architectures
such as Variational Autoencoders (VAE) <span class="citation"
data-cites="kingma_2013">[<a href="#ref-kingma_2013"
role="doc-biblioref">29</a>]</span>, Generative Adversarial Networks
(GAN) <span class="citation" data-cites="goodfellow_2014">[<a
href="#ref-goodfellow_2014" role="doc-biblioref">14</a>]</span>,
Denoising Diffusion Models (DDM) <span class="citation"
data-cites="ho_2020">[<a href="#ref-ho_2020"
role="doc-biblioref">20</a>]</span>, and Large Language Models (LLM)
<span class="citation" data-cites="vaswani_2017 brown_2020">[<a
href="#ref-brown_2020" role="doc-biblioref">3</a>, <a
href="#ref-vaswani_2017" role="doc-biblioref">57</a>]</span> are used to
generate artifacts such as text, audio, images, and videos of
unprecedented quality and complexity.</p>
<p>This dissertation aims at exploring how one could train and use
generative NN to create AI-powered tools capable of enhancing human
creative expression. The task of automatic lineart colorization act as
the example case used to illustrate this process throughout the entire
thesis.</p>
<figure id="fig:steps">
<img src="./figures/motivations_steps.svg"
alt="Common illustration process. From left to right: sketching, inking, coloring, and pros-processing. Credits: Taira Akitsu" />
<figcaption>Figure 1: Common illustration process. From left to right:
sketching, inking, coloring, and pros-processing. Credits: Taira
Akitsu</figcaption>
</figure>
<h3 id="motivations">Motivations</h3>
<p>Lineart colorization is an essential aspect of the work of artists,
illustrators, and animators. The task of manually coloring lineart can
be time-consuming, repetitive, and exhausting, particularly in the
animation industry, where every frame of an animated product must be
colored and shaded. This process is typically done using image editing
software such as Photoshop <span class="citation"
data-cites="photoshop">[<a href="#ref-photoshop"
role="doc-biblioref">46</a>]</span>, Clip Studio PAINT <span
class="citation" data-cites="clipstudiopaint">[<a
href="#ref-clipstudiopaint" role="doc-biblioref">6</a>]</span>, and
PaintMan <span class="citation" data-cites="paintman">[<a
href="#ref-paintman" role="doc-biblioref">43</a>]</span>. Automating the
colorization process can greatly improve the workflow of these creative
professionals and has the potential to lower the barrier for newcomers
and amateurs. Such a system was integrated into Clip Studio PAINT <span
class="citation" data-cites="clipstudiopaint">[<a
href="#ref-clipstudiopaint" role="doc-biblioref">6</a>]</span>,
demonstrating the growing significance of automatic colorization in the
field.</p>
<p>The most common digital illustration process can be broken down into
four distinct stages: sketching, inking, coloring, and post-processing
(see <a href="#fig:steps">Fig 1</a>). As demonstrated by the work of
Kandinsky <span class="citation" data-cites="kandinsky_1977">[<a
href="#ref-kandinsky_1977" role="doc-biblioref">25</a>]</span>, the
colorization process can greatly impact the overall meaning of a piece
of art through the introduction of various color schemes, shading, and
textures. These elements of the coloring process present significant
challenges for the Computer Vision (CV) task of automatic lineart
colorization, particularly in comparison to its grayscale counterpart
<span class="citation"
data-cites="furusawa_2O17 hensman_2017 zhang_richard_2017">[<a
href="#ref-furusawa_2O17" role="doc-biblioref">12</a>, <a
href="#ref-hensman_2017" role="doc-biblioref">18</a>, <a
href="#ref-zhang_richard_2017" role="doc-biblioref">62</a>]</span>.
Without the added semantic information provided by textures and shadows,
inferring materials and 3D shapes from black and white linearts is
difficult. They can only be deduced from silhouettes.</p>
<h3 id="problem-statement">Problem Statement</h3>
<p>One major challenge of automatic lineart colorization is the
availability of qualitative public datasets. Illustrations do not always
come with their corresponding lineart. The few datasets available for
the task are lacking consistency in the quality of the illustrations,
gathering images from different types, mediums and styles. For those
reasons, online scrapping and synthetic lineart extraction is the method
of choice for many of the contributions in the field <span
class="citation" data-cites="ci_2018 zhang_richard_2017">[<a
href="#ref-ci_2018" role="doc-biblioref">5</a>, <a
href="#ref-zhang_richard_2017" role="doc-biblioref">62</a>]</span>.</p>
<p>Previous works in automatic lineart colorization are based on the GAN
<span class="citation" data-cites="goodfellow_2014">[<a
href="#ref-goodfellow_2014" role="doc-biblioref">14</a>]</span>
architecture. They can generate unperfect but high-quality illustrations
in a quasi realtime setting. They achieve user control and guidance via
different means, color hints <span class="citation"
data-cites="frans_2017 liu_2017 sangkloy_2016 paintschainer_2017 ci_2018">[<a
href="#ref-ci_2018" role="doc-biblioref">5</a>, <a
href="#ref-frans_2017" role="doc-biblioref">10</a>, <a
href="#ref-liu_2017" role="doc-biblioref">36</a>, <a
href="#ref-paintschainer_2017" role="doc-biblioref">45</a>, <a
href="#ref-sangkloy_2016" role="doc-biblioref">53</a>]</span>, style
transfer <span class="citation" data-cites="zhang_ji_2017">[<a
href="#ref-zhang_ji_2017" role="doc-biblioref">61</a>]</span>, tagging
<span class="citation" data-cites="kim_2019">[<a href="#ref-kim_2019"
role="doc-biblioref">27</a>]</span>, and more recently natural language
<span class="citation" data-cites="ho_2020">[<a href="#ref-ho_2020"
role="doc-biblioref">20</a>]</span>. One common pattern in these methods
is the use of a feature extractor such as Illustration2Vec <span
class="citation" data-cites="saito_2015">[<a href="#ref-saito_2015"
role="doc-biblioref">52</a>]</span> allowing to compensate for the lack
of semantic descriptors by injecting its feature vector into the
models.</p>
<h3 id="contributions">Contributions</h3>
<p>This work focuses on the use of color hints in the form of user
strokes as it fits the natural digital artist workflow and does not
involve learning and mastering a new skill. While previous works offers
improving quality compared to classical CV techniques, they are still
subject to noisy training data, artifacts, a lack of variety, and a lack
of fidelity in the user intent. In this dissertation we explore the
importance of a clean, qualitative and consistent dataset. We
investigate how to better capture the user intent via natural artistic
controls and how to reflect them into the generated model artifact while
preserving or improving its quality. We also look at how the creative
process can be transformed into a dynamic iterative workflow where the
user collaborates with the machine to refine and carry out variations of
his artwork.</p>
<p>Here is a brief enumeration of this thesis’s contributions:</p>
<ul>
<li>We present a recipe for curating datasets for the task of automatic
lineart colorization <span class="citation"
data-cites="hati_2019 hati_2023">[<a href="#ref-hati_2019"
role="doc-biblioref">15</a>, <a href="#ref-hati_2023"
role="doc-biblioref">16</a>]</span></li>
<li>We introduce three generative models:
<ul>
<li>PaintsTorch <span class="citation" data-cites="hati_2019">[<a
href="#ref-hati_2019" role="doc-biblioref">15</a>]</span>, a double GAN
generator that improved generation quality compared to previous work
while allowing realtime interaction with the user.</li>
<li>StencilTorch <span class="citation" data-cites="hati_2023">[<a
href="#ref-hati_2023" role="doc-biblioref">16</a>]</span>, an upgrade
upon PaintsTorch, shifting the colorization problem to in-painting
allowing for human collaboration to emerge as a natural workflow where
the input of a first pass becomes the potential input for a second.</li>
<li>StablePaint, an exploration of DDM for bringing more variety into
the generated outputs allowing for variation exploration and conserving
the iterative workflow introduced by StencilTorch for the cost of
inference speed.</li>
</ul></li>
<li>We offer an advised reflection on current generative AI ethical and
societal impact.</li>
</ul>
<h3 id="concerns">Concerns</h3>
<p>Recent advances in generative AI for text, image, audio, and video
synthesis are raising important ethical and societal concerns,
especially because of its availability and ease of use. Models such as
Stable Diffusion <span class="citation" data-cites="rombach_2021">[<a
href="#ref-rombach_2021" role="doc-biblioref">48</a>]</span> and more
recently Chat-GPT <span class="citation" data-cites="openai_2023">[<a
href="#ref-openai_2023" role="doc-biblioref">4</a>]</span> are
disturbing our common beliefs and relation with copyright, creativity,
the distribution of fake information and so on.</p>
<p>One of the main issues with generative AI is the potential for model
fabulation. Generative models can create entirely new, synthetic data
that is indistinguishable from real data. This can lead to the
dissemination of false information and the manipulation of public
opinion. Additionally, there are ambiguities surrounding the ownership
and copyright of the generated content, as it is unclear who holds the
rights to the generated images and videos. Training data is often
obtained via online scrapping and thus copyright ownership is not
propagated. This is especially true for commercial applications.</p>
<p>Another important concern is the potential for biases and
discrimination. These models are trained on large amounts of data, and
if the data is not diverse or representative enough, the model may
perpetuate or even amplify existing biases. The Microsoft Tay Twitter
bot <span class="citation" data-cites="wolf_2017">[<a
href="#ref-wolf_2017" role="doc-biblioref">59</a>]</span> scandal is an
outcome of such a phenomenon. This initially innocent chatbot has been
easily turned into a racist bot perpetuating hate speech. The task was
made easier because of the inherently biased dataset it was trained
on.</p>
<p>In this work, we are committed to addressing and raising awareness
for these concerns. The illustrations used for training our models and
for our experiments are only used for educational and research purposes.
We only provide recipes for reproducibility and do not distribute the
dataset nor the weights resulting from model training, only the code. We
hope this will not ensure that our work is used ethically and
responsibly but limit its potential misuse.</p>
<h3 id="outline">Outline</h3>
<p>The first part of this thesis (chapters <a
href="#ch:introduction">1</a>-<a href="#ch:methodology">3</a>) provides
context to the recent advances in generative AI and introduces the CV
task of user-guided automatic lineart colorization, its challenges, and
our contributions to the field. It then provides additional background,
from DL first principles to current architectures used in modern
generative NN, and introduces the methodology used throughout the entire
document. This part should be accessible to the majority, experts and
non-experts, and serve as an introduction to the field.</p>
<p>The second part (chapters <a href="#ch:contrib-1">4</a>-<a
href="#ch:contrib-4">7</a>) presents our contributions, some of which
have previously been presented in <span class="citation"
data-cites="hati_2019 hati_2023">[<a href="#ref-hati_2019"
role="doc-biblioref">15</a>, <a href="#ref-hati_2023"
role="doc-biblioref">16</a>]</span>. It introduces into detail our
recipe for sourcing and curating consistent and qualitative datasets for
automatic lineart colorization, PaintsTorch <span class="citation"
data-cites="hati_2019">[<a href="#ref-hati_2019"
role="doc-biblioref">15</a>]</span> our first double generator GAN
conditioned on user strokes, StencilTorch <span class="citation"
data-cites="hati_2023">[<a href="#ref-hati_2023"
role="doc-biblioref">16</a>]</span> our in-painting reformulation
introducing the use of masks to allow the emergence of iterative
workflow and collaboration with the machine, and finally StablePaint, an
exploration of the use of DDM models for variations qualitative
exploration.</p>
<p>The third and final part (chapters <a
href="#ch:ethdical-and-societal-impact">7</a>-<a
href="#ch:conclusion">8</a>) offers a detailed reflection on this
thesis’s contributions and more generally about the field of generative
AI ethical and societal impact, identifies the remaining challenges and
discusses future work.</p>
<p>The code base for the experiments and contributions is publicly
available on GitHub at <a
href="https://github.com/yliess86">https://github.com/yliess86</a>.</p>
<h2 id="ch:background">Background</h2>
<p>This chapter introduces the reader to the field of Deep Learning (DL)
from first principles to the current architectures used in modern
generative AI. The first section (section <a href="#sec:history">1</a>)
presents a brief history of AI to ground this technical dissertation
into its historical context. The following sections (sections <a
href="#sec:core">2</a>-<a href="#sec:attention">4</a>) are discussing
the first principles of modern DL from the early Perceptron to more
modern frameworks such as Large Language Models (LLM).</p>
<div class="sourceCode" id="lst:snippet"><pre
class="sourceCode python"><code class="sourceCode python"><span id="lst:snippet-1"><a href="#lst:snippet-1" aria-hidden="true" tabindex="-1"></a><span class="co"># This is a code snippet</span></span>
<span id="lst:snippet-2"><a href="#lst:snippet-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Hello World!&quot;</span>)</span></code></pre></div>
<p>Additional code snippets (see Lst <strong>¿lst:snippet?</strong>) are
included to make this chapter more insightful and valuable for
newcomers.</p>
<figure id="fig:timeline">
<img src="./figures/boai_timeline.svg"
alt="A brief timeline of the History of Artificial Intelligence (AI)." />
<figcaption>Figure 2: A brief timeline of the History of Artificial
Intelligence (AI).</figcaption>
</figure>
<h3 id="sec:history">A Brief History of Artificial Intelligence</h3>
<p>The history of the field of AI is not a simple linear and
straightforward story. The field had its success and failures. The term
Artificial Intelligence (AI) has first been introduced in 1956 by John
Mc Carthy and Marvin Lee Minsky at a workshop sponsored by Dartmouth
College <span class="citation" data-cites="dartmouth_2006">[<a
href="#ref-dartmouth_2006" role="doc-biblioref">39</a>]</span>,
gathering about twenty researchers and intellectuals such as the
renowned Claude Shannon (see <a href="#fig:dartmouth">Fig 3</a>). The
field’s main questions were supposed to be solved in a short period.</p>
<p>However, the reality has been far less rosy. Over the years, AI has
gone through several “winters”, periods of inactivity and disillusion
where funding was cut and research interest dropped (see <a
href="#fig:timeline">Fig 2</a>). But with the advent of Big Data and the
rise of Deep Learning (DL), AI is once again in the spotlight. The
following sections provide a brief overview of the history of AI, from
its early days to the current state of the field. For a more in-depth
look at the history of modern AI, DL, we recommend “Quand la machine
apprend” from Yann LeCun <span class="citation"
data-cites="lecun_2019">[<a href="#ref-lecun_2019"
role="doc-biblioref">32</a>]</span>.</p>
<figure id="fig:dartmouth">
<img src="./figures/boai_dartmouth.png"
alt="Photography of seven of the Dartmouth workshop participants. From left to right: John McCarthy, Marvin Lee Minsky, Nathaniel Rochester, Claude Elwood Shannon, Ray Solomonoff, Trenchard More, and Oliver Gordon Selfridge. Credit: Margaret Minksy" />
<figcaption>Figure 3: Photography of seven of the Dartmouth workshop
participants. From left to right: John McCarthy, Marvin Lee Minsky,
Nathaniel Rochester, Claude Elwood Shannon, Ray Solomonoff, Trenchard
More, and Oliver Gordon Selfridge. Credit: Margaret Minksy</figcaption>
</figure>
<h4 id="the-early-years">The Early Years</h4>
<p>The term Artificial Intelligence (AI) was first used at the 1956
Dartmouth Workshop <span class="citation"
data-cites="dartmouth_2006">[<a href="#ref-dartmouth_2006"
role="doc-biblioref">39</a>]</span>, where John McCarthy proposed the
idea of creating a machine that could learn from its mistakes and
improve its performance over time. The twenty researchers and
intellectuals present worked on topics such as the automatic computer,
the use of natural language by machines, neuron nets (Neural Network
(NN)), randomness and creativity, and many more. This was a
revolutionary idea at the time, and the work done at Dartmouth attracted
a great deal of attention and funding.</p>
<p>Much of the early research focused on symbolic AI, which uses symbols
and logical operations to represent and manipulate data. Logic
programming, production rules, semantic nets and frames, knowledge-based
systems, symbolic mathematics, automatons, automated provers, ontologies
and other paradigms were at the core of symbolic AI <span
class="citation" data-cites="russell_2016">[<a href="#ref-russell_2016"
role="doc-biblioref">51</a>]</span>. This approach was based on the
early work of Alan Turing and the development of functional languages
such as the LISP by McCarthy and al. at MIT <span class="citation"
data-cites="mccarthy_1978">[<a href="#ref-mccarthy_1978"
role="doc-biblioref">38</a>]</span>.</p>
<p>One significant contribution of this period was the Perceptron by
Frank Rosenblatt <span class="citation" data-cites="rosenblatt_1958">[<a
href="#ref-rosenblatt_1958" role="doc-biblioref">49</a>]</span>, a
simplified biomimical model of a single neuron. This artificial neuron
fires when the weighted sum of its input is above a predefined
threshold. The weights, scalars attributed to the connection edges of
the neuron’s inputs, are tuned iteratively and manually given supervised
data, inputs with corresponding labels, until good enough classification
accuracy is met.</p>
<h4 id="the-first-ai-winter">The First AI Winter</h4>
<p>The Perceptron was an early example of a connectionist approach,
which uses a network of artificial neurons to process data. The
Perceptron was met with much enthusiasm but was eventually criticized by
Marvin L. Minsky and Seymour Papert <span class="citation"
data-cites="minsky_1969">[<a href="#ref-minsky_1969"
role="doc-biblioref">40</a>]</span>, who argued that it could not solve
a simple XOR problem. The criticisms, as well as other issues, led to a
period of disillusion in the field of AI, known as the “First AI
Winter”. It was a time when AI research lost its momentum and funding
was not abundant anymore. This period lasted from 1973 to 1980.</p>
<h4 id="expert-systems-and-symbolic-ai">Expert Systems and Symbolic
AI</h4>
<p>The eighties saw a resurgence of interest in AI. Expert systems <span
class="citation" data-cites="jackson_1998">[<a href="#ref-jackson_1998"
role="doc-biblioref">23</a>]</span> were the new hot AI topic. They are
made of hierarchical and specialized ensembles of symbolic reasoning
models and are used to solve complex problems. Symbolic AI continued to
prosper as the dominant approach until the mid-nineties.</p>
<p>During this period, AI was developed as logic-based systems,
search-based systems using depth-first-search, and genetic algorithms,
requiring complex engineering and domain-specific knowledge from experts
to work. It was also the time of the first cognitive architectures <span
class="citation" data-cites="lieto_2021">[<a href="#ref-lieto_2021"
role="doc-biblioref">35</a>]</span> inspired by advances in the field of
neuroscience such as SOAR <span class="citation"
data-cites="larid_2019">[<a href="#ref-larid_2019"
role="doc-biblioref">31</a>]</span> and Adaptive Control of
Thought—Rational (ACT-R) <span class="citation"
data-cites="john_1992">[<a href="#ref-john_1992"
role="doc-biblioref">2</a>]</span> attempting at simulating the human
cognitive process for solving and task automation.</p>
<p>Although the connectionist approaches were not well received by the
community at the time, some individuals are known for significant
contributions that later would form the basis for modern NN
architectures. It was the case for Kunihiko Fukushima and his
NeoCognitron <span class="citation" data-cites="fukushima_1980">[<a
href="#ref-fukushima_1980" role="doc-biblioref">11</a>]</span>, or David
E. Rumelhart et al. who introduced the most used learning procedure for
training Multi-Layer Perceptrons (MLP), the backpropagation <span
class="citation" data-cites="rumelhart_1986">[<a
href="#ref-rumelhart_1986" role="doc-biblioref">50</a>]</span>.</p>
<h4 id="the-second-ai-winter">The Second AI Winter</h4>
<p>Unfortunately, this period was also marked by a lack of progress
because of the resource limitations of the time. Those algorithms
required too much power, data, and investments to work. They were not
sufficient to make AI truly successful. The lack of progress in the
eighties led to the “Second AI Winter”. AI research was largely
abandoned during this period. Funding and enthusiasm dwindled. This
winter lasted from 1988 to early 2000.</p>
<h5 id="the-indomitable-researchers">The Indomitable Researchers</h5>
<p>The second AI winter limited research for NN. However, some
indomitable individuals continued their work. During this period,
Vladimir Vapnik et al. developed the Support Vector Machine (SVM) <span
class="citation" data-cites="cortes_1995">[<a href="#ref-cortes_1995"
role="doc-biblioref">7</a>]</span>, a robust non-probabilistic binary
linear classifier. The method has the advantage to generalize well even
with small datasets. Sepp Hochreiter et al. introduced the Long
Short-Term Memory (LSTM) for Recurrent Neural Networks (RNN) <span
class="citation" data-cites="hochreiter_1997">[<a
href="#ref-hochreiter_1997" role="doc-biblioref">21</a>]</span>, a
complex recurrent cell using gates to route the information flow and
simulate long and short-term memory buffers. In 1989, Yann LeCun
provided the first practical and industrial demonstration of
backpropagation at Bell Labs with a Convolutional Neural Network (CNN)
to read handwritten digits <span class="citation"
data-cites="lecun_1989 lecun_1998">[<a href="#ref-lecun_1989"
role="doc-biblioref">33</a>, <a href="#ref-lecun_1998"
role="doc-biblioref">34</a>]</span> later used by the American postal
services to sort letters.</p>
<figure id="fig:revolution">
<img src="./figures/boai_revolution.svg"
alt="A brief timeline of the Deep Learning (DL) Revolution." />
<figcaption>Figure 4: A brief timeline of the Deep Learning (DL)
Revolution.</figcaption>
</figure>
<h4 id="the-deep-learning-revolution">The Deep Learning Revolution</h4>
<p>The next significant evolutionary step Deep Learning (DL), those deep
hierarchical NN, descendants of the connectionist movement, occurred in
the early twenty-first century (see <a
href="#fig:revolution">Fig 4</a>). Computers were now faster and GPUs
were developed for high compute parallelization. Data was starting to be
abundant thanks to the internet and the rapid rise of search engines and
social networks. It is the era of Big Data. NN were competing with SVM.
In 2009 Fei-Fei Li and her group launched ImageNet <span
class="citation" data-cites="deng_2009">[<a href="#ref-deng_2009"
role="doc-biblioref">8</a>]</span>, a dataset assembling billions of
labeled images.</p>
<p>By 2011, the speed of GPUs had increased significantly, making it
possible to train CNNs without layer-by-layer pre-training. The rest of
the story includes a succession of deep NN architectures including,
AlexNet <span class="citation" data-cites="krizhevsky_2012">[<a
href="#ref-krizhevsky_2012" role="doc-biblioref">30</a>]</span>, one of
the first award-winning deep CNN, ResNet <span class="citation"
data-cites="he_2016">[<a href="#ref-he_2016"
role="doc-biblioref">17</a>]</span>, introducing residual connections,
the Generative Adversarial Networks (GAN) <span class="citation"
data-cites="goodfellow_2014">[<a href="#ref-goodfellow_2014"
role="doc-biblioref">14</a>]</span>, a high fidelity and high-resolution
generative framework, attention mechanisms with the rise of the
Transformer “Attention is all you Need” architecture <span
class="citation" data-cites="vaswani_2017">[<a href="#ref-vaswani_2017"
role="doc-biblioref">57</a>]</span> present in almost all modern DL
contributions, and more recently the Denoising Diffusion Model (DDM)
<span class="citation" data-cites="ho_2020">[<a href="#ref-ho_2020"
role="doc-biblioref">20</a>]</span>, the spiritual autoregressive
successor of the GAN.</p>
<figure id="fig:milestones">
<img src="./figures/boai_milestones.svg"
alt="A brief timeline of the Deep Learning (DL) Milestones." />
<figcaption>Figure 5: A brief timeline of the Deep Learning (DL)
Milestones.</figcaption>
</figure>
<h4 id="deep-learning-milestones">Deep Learning Milestones</h4>
<p>DL is responsible for many AI milestones in the past decade (see <a
href="#fig:milestones">Fig 5</a>). These milestones have been essential
in advancing the field and enabling its applications within various
sectors. One of the first notable milestones was AlphaGo from DeepMind
in 2016 <span class="citation" data-cites="silver_2016">[<a
href="#ref-silver_2016" role="doc-biblioref">55</a>]</span>, where an AI
system was able to beat the Korean world champion Lee Se Dol in the game
of Go. AlphaGo is an illustration of the compression and pattern
recognition capabilities of deep NN in combination with efficient search
algorithms.</p>
<p>In 2019, AlphStar <span class="citation"
data-cites="vinyals_2019">[<a href="#ref-vinyals_2019"
role="doc-biblioref">58</a>]</span> from DeepMind also was able to
compete and defeat grandmasters in StarCraft the real-time strategy game
of Blizzard. This demonstrated the capability of Deep Learning
algorithms to achieve beyond human-level performance in real-time and
long-term plannification. In 2020, AlphaFold <span class="citation"
data-cites="senior_2020">[<a href="#ref-senior_2020"
role="doc-biblioref">54</a>]</span> improved the Protein Folding
competition by quite a margin, showing that DL could be used to help
solve complex problems that have implications for medical research and
drug discovery. In 2021 a follow-up model, AlphaFold 2 <span
class="citation" data-cites="jumper_2021">[<a href="#ref-jumper_2021"
role="doc-biblioref">24</a>]</span>, was presented as an impressive
successor of AlphaFold, showcasing further advances in this field.</p>
<p>In 2021, Stable Diffusion <span class="citation"
data-cites="rombach_2021">[<a href="#ref-rombach_2021"
role="doc-biblioref">48</a>]</span> from Stability AI was released. This
Latent DDM conditioned on text prompts allows to generate images of
unprecedented quality and met unprecedented public reach. Finally,
Chat-GPT <span class="citation" data-cites="openai_2023">[<a
href="#ref-openai_2023" role="doc-biblioref">4</a>]</span> was released
in 2023 as a chatbot based on GPT3 <span class="citation"
data-cites="brown_2020">[<a href="#ref-brown_2020"
role="doc-biblioref">3</a>]</span> and fine-tuned using Reinforcement
Learning from Human Feedback (RLHF) for natural question-answering
interaction publicly available as a web demo. However, these last two
milestones are also responsible for ethical and societal concerns about
copyright, creativity, and more. This highlights both the potential of
Deep Learning algorithms but also the need for further research around
their implications.</p>
<h3 id="sec:core">Core Principles</h3>
<p>This section introduces the technical background necessary to
understand this thesis dissertation. It introduces Neural Networks (NN)
from first principles. A more detailed and complete introduction to the
field can be found in “the Deep Learning book” by Ian Goodfellow et al
<span class="citation" data-cites="goodfellow_2016">[<a
href="#ref-goodfellow_2016" role="doc-biblioref">13</a>]</span> or in
“Dive into Deep Learning” by Aston Zhang et al. <span class="citation"
data-cites="aston_zhang_2021">[<a href="#ref-aston_zhang_2021"
role="doc-biblioref">60</a>]</span>.</p>
<h4 id="supervised-learning">Supervised Learning</h4>
<p>In Machine Learning (ML), problems are often formulated as
data-driven learning tasks, where a computer is used to find a mapping
<span class="math inline">\(f: X \rightarrow Y\)</span> from input space
<span class="math inline">\(X\)</span> to output space <span
class="math inline">\(Y\)</span>. For example, <span
class="math inline">\(X\)</span> could represent data about an e-mail
and <span class="math inline">\(Y\)</span> the probability of this
e-mail being spam. In practice, manually defining all the
characteristics of a function <span class="math inline">\(f\)</span>
that would satisfy this task is considered unpractical. It would require
one to manually describe all potential rules defining spam. In ML, the
supervised framework offers a practical solution consisting of acquiring
label data pairs, <span class="math inline">\((x, y) \in X \times
Y\)</span> for the current problem (see <a
href="#fig:dataflow">Fig 6</a>). In our case, this would require
gathering a dataset of e-mails and asking humans to label those as spam
or not.</p>
<p><strong>Objective Function</strong>: Let us consider such a training
dataset containing n independent pairs <span
class="math inline">\(\{(x_1, y_1), \dots, (x_n, y_n)\}\)</span> sampled
from the data distribution <span class="math inline">\(D\)</span>, <span
class="math inline">\((x_i, y_i) \sim D\)</span>. In ML, we seek for
learning a mapping <span class="math inline">\(f: X \rightarrow
Y\)</span> by searching the space of the candidates function class <span
class="math inline">\(\mathcal{F}\)</span>. Defining a scalar objective
function <span class="math inline">\(L(\hat{y}, y)\)</span> measuring
the distance from true label <span class="math inline">\(y\)</span> and
our prediction <span class="math inline">\(f(x_i) = \hat{y}_i\)</span>
given <span class="math inline">\(f \in \mathcal{F}\)</span>, the
ultimate objective is to find the function <span
class="math inline">\(f^* \in F\)</span> that best satisfy the following
minimization problem (see <a href="#eq:f_star_objective">Eq 1</a>):</p>
<p><span id="eq:f_star_objective"><span class="math display">\[
f^* = arg \; \underset{f \in \mathcal{F}}{min} \; E_{(x, y) \sim D}
L(\hat{y}, y)
\qquad{(1)}\]</span></span></p>
<p>The function <span class="math inline">\(f^*\)</span> must minimize
the expected loss <span class="math inline">\(L\)</span> over the entire
data distribution <span class="math inline">\(D\)</span>. Once such a
function is learned one can use it to perform inference and map any
element from the input space <span class="math inline">\(X\)</span> to
the output space <span class="math inline">\(Y\)</span>.</p>
<p>However, this minimization problem is intractable as it is impossible
to represent the entire distribution <span
class="math inline">\(D\)</span>. Fortunately, as every pair <span
class="math inline">\((x_i, y_i)\)</span> is independently sampled and
identically distributed, the objective can be approximated by sampling
and minimizing the loss over the training dataset (see <a
href="#eq:f_star_objective_approx">Eq 2</a>):</p>
<p><span id="eq:f_star_objective_approx"><span class="math display">\[
f^* \approx arg \; \underset{f \in \mathcal{F}}{min} \; \frac{1}{n}
\sum_{i=1}^{n} L(\hat{y}_i, y_i)
\qquad{(2)}\]</span></span></p>
<p><strong>Regularization</strong>: While simplifying the problem allows
us to perform loss minimization, this approximation comes at a cost.
This optimization problem can have multiple solutions, a set of
functions <span class="math inline">\(\{f_1, \dots, f_m\} \in F\)</span>
performing well on the given training set, but would behave differently
outside of the training data and outside of the data distribution. Those
functions would not necessarily be able to generalize. To mitigate those
concerns, we can introduce a regularization term <span
class="math inline">\(R\)</span> into the objective function (see <a
href="#eq:f_star_objective_regul">Eq 3</a>), a scalar function that is
independent of the data distribution and represent a preference on
certain function class.</p>
<p><span id="eq:f_star_objective_regul"><span class="math display">\[
f^* \approx arg \; \underset{f \in \mathcal{F}}{min} \; \frac{1}{n}
\sum_{i=1}^{n} L(\hat{y}_i, y_i) + R(f)
\qquad{(3)}\]</span></span></p>
<figure id="fig:dataflow">
<img src="./figures/core_nn_dataflow.svg"
alt="Supervised learning data flow. The dataset {(x_i, y_i)} \in D is used to train the model f \in \mathcal{F} to minimize an objective function with two terms, a data dependant loss L, and a regularization R measuring the system complexity." />
<figcaption>Figure 6: Supervised learning data flow. The dataset <span
class="math inline">\({(x_i, y_i)} \in D\)</span> is used to train the
model <span class="math inline">\(f \in \mathcal{F}\)</span> to minimize
an objective function with two terms, a data dependant loss <span
class="math inline">\(L\)</span>, and a regularization <span
class="math inline">\(R\)</span> measuring the system
complexity.</figcaption>
</figure>
<p>In the following, we investigate two examples where supervised
learning is first applied to a Neural Network (NN) regression problem,
and then a NN classification problem. The examples highlight the
objective functions composed by the loss and the regularization term for
regression and classification respectively.</p>
<p><strong>Regression Problem:</strong> Let us consider the distribution
<span class="math inline">\(D\)</span> represented by the <span
class="math inline">\(sin\)</span> function in the <span
class="math inline">\([-3 \pi; 3 \pi]\)</span> range (see <a
href="#fig:regression">Fig 7</a>). We sample <span
class="math inline">\(50\)</span> pairs <span
class="math inline">\((x_i, y_i)\)</span> with <span
class="math inline">\(X \in [-3 \pi; 3 \pi]\)</span> and <span
class="math inline">\(Y \in [-1; 1]\)</span>. Our objective is to learn
a regressor <span class="math inline">\(f_\theta\)</span>, a three
layers NN parametrized by its weights <span class="math inline">\(\{w_0,
W_1, w_2\} = \theta\)</span>. <span class="math inline">\(w_0\)</span>
contains <span class="math inline">\((1 \times 16) + 1\)</span> weights,
<span class="math inline">\(W_1\)</span>, <span
class="math inline">\((16 \times 16) + 1\)</span>, and <span
class="math inline">\(w_2\)</span>, <span class="math inline">\((16
\times 1) + 1\)</span>. In this case, the function space is limited to
the three layers NN family with <span class="math inline">\(291\)</span>
parameters <span class="math inline">\(\mathcal{F}\)</span>.</p>
<figure id="fig:regression">
<img src="./figures/core_nn_regression.svg"
alt="Neural Network (NN) regression example. The model f_\theta is fit on the training set (X, Y) \in D representing the sin function in the range [-3 \pi; 3 \pi]." />
<figcaption>Figure 7: Neural Network (NN) regression example. The model
<span class="math inline">\(f_\theta\)</span> is fit on the training set
<span class="math inline">\((X, Y) \in D\)</span> representing the <span
class="math inline">\(sin\)</span> function in the range <span
class="math inline">\([-3 \pi; 3 \pi]\)</span>.</figcaption>
</figure>
<p>To achieve this goal using supervised learning, we can optimize the
following objective function (see <a
href="#eq:reg_sin_objective">Eq 4</a>):</p>
<p><span id="eq:reg_sin_objective"><span class="math display">\[
f^* = arg \; \underset{\theta}{min} \; \frac{1}{n} \sum_{i=1}^{n}
(f_\theta(x_i) - y_i)^2 + \lambda ||\theta||_2^2
\qquad{(4)}\]</span></span></p>
<p>where the loss is the Mean Squared Error (MSE) <span
class="math inline">\(||.||_2^2\)</span> between the ground-truth <span
class="math inline">\(y_i\)</span> and the prediction <span
class="math inline">\(\hat{y_i} = f_\theta(x_i)\)</span>, and the
weighted regularization term <span class="math inline">\(\lambda
||\theta||_2^2\)</span> to penalize the model for having large weights
and converge to a simpler solution. A python code snippet for the
objective function and the model is provided below (see
Lst <strong>¿lst:regression?</strong>):</p>
<div class="sourceCode" id="lst:regression"><pre
class="sourceCode python"><code class="sourceCode python"><span id="lst:regression-1"><a href="#lst:regression-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.nn <span class="im">import</span> (Linear, Sequential, Tanh)</span>
<span id="lst:regression-2"><a href="#lst:regression-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="lst:regression-3"><a href="#lst:regression-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Loss and Regularization</span></span>
<span id="lst:regression-4"><a href="#lst:regression-4" aria-hidden="true" tabindex="-1"></a>L <span class="op">=</span> <span class="kw">lambda</span> y_, y <span class="op">=</span> (y_ <span class="op">-</span> y).<span class="bu">pow</span>(<span class="dv">2</span>)</span>
<span id="lst:regression-5"><a href="#lst:regression-5" aria-hidden="true" tabindex="-1"></a>R <span class="op">=</span> <span class="kw">lambda</span> f: <span class="bu">sum</span>(w.<span class="bu">pow</span>(<span class="dv">2</span>).<span class="bu">sum</span>() <span class="cf">for</span> w <span class="kw">in</span> f.parameters())</span>
<span id="lst:regression-6"><a href="#lst:regression-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="lst:regression-7"><a href="#lst:regression-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Neural Network model</span></span>
<span id="lst:regression-8"><a href="#lst:regression-8" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> Sequential(</span>
<span id="lst:regression-9"><a href="#lst:regression-9" aria-hidden="true" tabindex="-1"></a>    Linear(<span class="dv">1</span>, <span class="dv">16</span>), Tanh(),</span>
<span id="lst:regression-10"><a href="#lst:regression-10" aria-hidden="true" tabindex="-1"></a>    Linear(<span class="dv">16</span>, <span class="dv">16</span>), Tanh(),</span>
<span id="lst:regression-11"><a href="#lst:regression-11" aria-hidden="true" tabindex="-1"></a>    Linear(<span class="dv">16</span>, <span class="dv">1</span>),</span>
<span id="lst:regression-12"><a href="#lst:regression-12" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="lst:regression-13"><a href="#lst:regression-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="lst:regression-14"><a href="#lst:regression-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Objective function</span></span>
<span id="lst:regression-15"><a href="#lst:regression-15" aria-hidden="true" tabindex="-1"></a>C <span class="op">=</span> (<span class="dv">1</span> <span class="op">/</span> n) <span class="op">*</span> L(f(X), Y).<span class="bu">sum</span>() <span class="op">+</span> lam <span class="op">*</span>  R(f)</span></code></pre></div>
<p><strong>Classification Problem:</strong> Let us consider the
distribution <span class="math inline">\(D\)</span> representing the 2d
positions of two clusters <span class="math inline">\({0, 1} \in
K\)</span> of moons (see <a href="#fig:classification">Fig 8</a>). We
sample <span class="math inline">\(250\)</span> moon <span
class="math inline">\((x_i, y_i)\)</span> with <span
class="math inline">\(X \in [-1; 1]\)</span> and <span
class="math inline">\(Y \in [-1; 1]\)</span>. Our objective is to learn
a classifier <span class="math inline">\(f_\theta\)</span>, a three
layers NN parametrized by its weights <span class="math inline">\(\{w_0,
W_1, w_2\} = \theta\)</span>. <span class="math inline">\(w_0\)</span>
contains <span class="math inline">\((1 \times 32) + 1\)</span> weights,
<span class="math inline">\(W_1\)</span>, <span
class="math inline">\((32 \times 32) + 1\)</span>, and <span
class="math inline">\(w_2\)</span>, <span class="math inline">\((32
\times 1) + 1\)</span>. In this case, the function space is limited to
the three layers NN family with <span
class="math inline">\(1,091\)</span> parameters <span
class="math inline">\(\mathcal{F}\)</span>.</p>
<figure id="fig:classification">
<img src="./figures/core_nn_classification.svg"
alt="Neural Network (NN) classification example. The model f_\theta is trained to classify moons based on their positions. The decision boundary is shown." />
<figcaption>Figure 8: Neural Network (NN) classification example. The
model <span class="math inline">\(f_\theta\)</span> is trained to
classify moons based on their positions. The decision boundary is
shown.</figcaption>
</figure>
<p>To achieve this goal using supervised learning, we can optimize an
objective function similar to the regression problem (see <a
href="#eq:reg_sin_objective">Eq 4</a>) using the cross-entropy as the
loss function (see <a href="#eq:cross_entropy">Eq 5</a>), measuring the
classification discordance.</p>
<p><span id="eq:cross_entropy"><span class="math display">\[
\mathcal{L} (\hat{y}, y) = \sum_{k=1}^{K} y_k \; log \; \hat{y}_k
\qquad{(5)}\]</span></span></p>
<p>A python code snippet for the loss function and the model is provided
below (see Lst <strong>¿lst:classification?</strong>):</p>
<div class="sourceCode" id="lst:classification"><pre
class="sourceCode python"><code class="sourceCode python"><span id="lst:classification-1"><a href="#lst:classification-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.nn <span class="im">import</span> (Linear, Sequential, Tanh)</span>
<span id="lst:classification-2"><a href="#lst:classification-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.nn.functional <span class="im">import</span> cross_entropy</span>
<span id="lst:classification-3"><a href="#lst:classification-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="lst:classification-4"><a href="#lst:classification-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Loss</span></span>
<span id="lst:classification-5"><a href="#lst:classification-5" aria-hidden="true" tabindex="-1"></a>L <span class="op">=</span> <span class="kw">lambda</span> y_, y <span class="op">=</span> cross_entropy(y_, y, <span class="bu">reduce</span><span class="op">=</span><span class="va">False</span>)</span>
<span id="lst:classification-6"><a href="#lst:classification-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="lst:classification-7"><a href="#lst:classification-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Neural Network model</span></span>
<span id="lst:classification-8"><a href="#lst:classification-8" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> Sequential(</span>
<span id="lst:classification-9"><a href="#lst:classification-9" aria-hidden="true" tabindex="-1"></a>    Linear(<span class="dv">1</span>, <span class="dv">32</span>), Tanh(),</span>
<span id="lst:classification-10"><a href="#lst:classification-10" aria-hidden="true" tabindex="-1"></a>    Linear(<span class="dv">32</span>, <span class="dv">32</span>), Tanh(),</span>
<span id="lst:classification-11"><a href="#lst:classification-11" aria-hidden="true" tabindex="-1"></a>    Linear(<span class="dv">32</span>, <span class="dv">1</span>),</span>
<span id="lst:classification-12"><a href="#lst:classification-12" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<h4 id="sec:optimization">Optimization</h4>
<p>In ML, supervised problems can be reduced to an optimization problem
where the computer has to find a set of parameters, weights <span
class="math inline">\(\theta\)</span>, for a given function class <span
class="math inline">\(\mathcal{F}\)</span> by optimizing an objective
function <span class="math inline">\(\theta^* = arg \; min_\theta
\mathcal{C(\theta)}\)</span> made out of two components, a
data-dependant loss <span class="math inline">\(L\)</span> and a
regularization <span class="math inline">\(R\)</span>.</p>
<p><strong>Random Search:</strong> One way to find such a function <span
class="math inline">\(f_\theta\)</span> that satisfies this objective is
to estimate the objective function for a set of random parameter
initializations and take the one that minimizes <span
class="math inline">\(C\)</span> the most. This <span
class="math inline">\(\theta\)</span> setting can then be refined by
applying random perturbations to the parameters and repeating the
operation (see Lst <strong>¿lst:random_search?</strong>). This is
possible due to the fact that we can computer <span
class="math inline">\(C(\theta)\)</span> for any value of <span
class="math inline">\(\theta\)</span> taking the average loss for a
given dataset. However, such an approach to optimization is unpractical.
NN often comes with millions or billions of parameters <span
class="math inline">\(\theta\)</span> making random-search
intractable.</p>
<div class="sourceCode" id="lst:random_search"><pre
class="sourceCode python"><code class="sourceCode python"><span id="lst:random_search-1"><a href="#lst:random_search-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> copy</span>
<span id="lst:random_search-2"><a href="#lst:random_search-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="lst:random_search-3"><a href="#lst:random_search-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="lst:random_search-4"><a href="#lst:random_search-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="lst:random_search-5"><a href="#lst:random_search-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> step <span class="kw">in</span> <span class="bu">range</span>(steps):</span>
<span id="lst:random_search-6"><a href="#lst:random_search-6" aria-hidden="true" tabindex="-1"></a>    fs, os <span class="op">=</span> [f] <span class="op">+</span> [copy.deepcopy(f) <span class="cf">for</span> f <span class="kw">in</span> <span class="bu">range</span>(n_copy)], []</span>
<span id="lst:random_search-7"><a href="#lst:random_search-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> f_ <span class="kw">in</span> fs:</span>
<span id="lst:random_search-8"><a href="#lst:random_search-8" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Apply weight perturbation</span></span>
<span id="lst:random_search-9"><a href="#lst:random_search-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> w <span class="kw">in</span> f_.parameters():</span>
<span id="lst:random_search-10"><a href="#lst:random_search-10" aria-hidden="true" tabindex="-1"></a>            w.normal_(<span class="fl">0.0</span>, <span class="fl">1.0</span> <span class="op">/</span> step)</span>
<span id="lst:random_search-11"><a href="#lst:random_search-11" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Estimate the objective function</span></span>
<span id="lst:random_search-12"><a href="#lst:random_search-12" aria-hidden="true" tabindex="-1"></a>        os.append(C(f_(X), Y))</span>
<span id="lst:random_search-13"><a href="#lst:random_search-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="lst:random_search-14"><a href="#lst:random_search-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Retrieve the winner</span></span>
<span id="lst:random_search-15"><a href="#lst:random_search-15" aria-hidden="true" tabindex="-1"></a>    f <span class="op">=</span> fs[np.argmax(os)]</span></code></pre></div>
<p><strong>First Order Derivation:</strong> A more efficient approach is
to make the objective function <span class="math inline">\(C\)</span>
and the model <span class="math inline">\(f_\theta\)</span>
differentiable. This constraint allows us to compute the gradient of the
cost <span class="math inline">\(C\)</span> with respect to the model’s
parameters <span class="math inline">\(\theta\)</span>. The value <span
class="math inline">\(\nabla_\theta C\)</span> can be obtained using
backpropagation (discussed in the next sub-section <a
href="#sec:backpropagation">Sec 2.2.2.3</a>). This vector of first order
derivatives indicates the direction from which we need to move the
weights <span class="math inline">\(\theta\)</span> away. By taking
small iterative steps toward the negative direction of the gradients, we
can improve <span class="math inline">\(\theta\)</span>. This algorithm
is called GD. In practice, due to the very large size of the datasets
(<span class="math inline">\(14,197,122\)</span> images for ImageNet
<span class="citation" data-cites="deng_2009">[<a href="#ref-deng_2009"
role="doc-biblioref">8</a>]</span>), the objective gradient is
approximated using a small subset of the training data for each step
referred to as a minibatch. This approximation of the GD is called
Stochastic Gradient Descent (SGD) (see
Lst <strong>¿lst:sgd?</strong>).</p>
<div class="sourceCode" id="lst:sgd"><pre
class="sourceCode python"><code class="sourceCode python"><span id="lst:sgd-1"><a href="#lst:sgd-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> step <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1_000</span>):</span>
<span id="lst:sgd-2"><a href="#lst:sgd-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Retrieve the next minibatch</span></span>
<span id="lst:sgd-3"><a href="#lst:sgd-3" aria-hidden="true" tabindex="-1"></a>    x, y <span class="op">=</span> next_minibatch(X, Y)</span>
<span id="lst:sgd-4"><a href="#lst:sgd-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="lst:sgd-5"><a href="#lst:sgd-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute the objective function and the gradients</span></span>
<span id="lst:sgd-6"><a href="#lst:sgd-6" aria-hidden="true" tabindex="-1"></a>    C <span class="op">=</span> L(f(x), y) <span class="op">+</span> lam <span class="op">*</span> R(f)</span>
<span id="lst:sgd-7"><a href="#lst:sgd-7" aria-hidden="true" tabindex="-1"></a>    C.backward()</span>
<span id="lst:sgd-8"><a href="#lst:sgd-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="lst:sgd-9"><a href="#lst:sgd-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Update the weights and reset the gradients</span></span>
<span id="lst:sgd-10"><a href="#lst:sgd-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> w <span class="kw">in</span> f.parameters():</span>
<span id="lst:sgd-11"><a href="#lst:sgd-11" aria-hidden="true" tabindex="-1"></a>        w <span class="op">-=</span> eps <span class="op">*</span> w.grad</span>
<span id="lst:sgd-12"><a href="#lst:sgd-12" aria-hidden="true" tabindex="-1"></a>    f.zero_grad(set_to_none<span class="op">=</span><span class="va">True</span>)</span></code></pre></div>
<p>One critical aspect of the SGD algorithm is the hyperparameter <span
class="math inline">\(\epsilon\)</span>, the learning rate. It controls
the size of the step we take toward the negative gradients. If it is too
height or too low, the optimization may not converge toward an
acceptable local minimum. A toy example is provided in <a
href="#fig:toysgd">Fig 9</a> where different learning rates are used to
find the minimum of the square function <span class="math inline">\(y =
x^2\)</span>.</p>
<figure id="fig:toysgd">
<img src="./figures/core_nn_sgd.svg"
alt="Toy example where different learning rates \epsilon are used to find the minimum of the square function y = x^2 using the Gradient Descent (GD) algorithm starting from x = -1. Some learning rate setup result in situations where the optimization does not converge to the solution. A learning rate \epsilon = 2 diverges toward infinity, \epsilon = 1 is stuck and bounces between two positions -1 and 1. However, a small learning rate \epsilon = 0.1 &lt; 1 converges towards the minimum y = 0. This example illustrates the impact of the hyperparameter \epsilon on GD." />
<figcaption>Figure 9: Toy example where different learning rates <span
class="math inline">\(\epsilon\)</span> are used to find the minimum of
the square function <span class="math inline">\(y = x^2\)</span> using
the Gradient Descent (GD) algorithm starting from <span
class="math inline">\(x = -1\)</span>. Some learning rate setup result
in situations where the optimization does not converge to the solution.
A learning rate <span class="math inline">\(\epsilon = 2\)</span>
diverges toward infinity, <span class="math inline">\(\epsilon =
1\)</span> is stuck and bounces between two positions <span
class="math inline">\(-1\)</span> and <span
class="math inline">\(1\)</span>. However, a small learning rate <span
class="math inline">\(\epsilon = 0.1 &lt; 1\)</span> converges towards
the minimum <span class="math inline">\(y = 0\)</span>. This example
illustrates the impact of the hyperparameter <span
class="math inline">\(\epsilon\)</span> on GD.</figcaption>
</figure>
<p><strong>First Order Derivation with Momentum:</strong> The DL
literature contains abundant work on first order optimizer variants
aiming for faster convergence such as SGD with Momentum <span
class="citation" data-cites="qian_1999">[<a href="#ref-qian_1999"
role="doc-biblioref">47</a>]</span>, Adagrad <span class="citation"
data-cites="duchi_2011">[<a href="#ref-duchi_2011"
role="doc-biblioref">9</a>]</span>, RMSProp <span class="citation"
data-cites="hinton_lecture6a">[<a href="#ref-hinton_lecture6a"
role="doc-biblioref">19</a>]</span>, Adam <span class="citation"
data-cites="kingma_2014">[<a href="#ref-kingma_2014"
role="doc-biblioref">28</a>]</span>, and its correction AdamW <span
class="citation" data-cites="loshchilov_2017">[<a
href="#ref-loshchilov_2017" role="doc-biblioref">37</a>]</span>. A toy
example is shown <a href="#fig:sgd_moments">Fig 10</a>.</p>
<p>The Momentum update <span class="citation" data-cites="qian_1999">[<a
href="#ref-qian_1999" role="doc-biblioref">47</a>]</span> introduces the
use of a momentum inspired by physics’ first principles to favor small
and consistent gradient directions. In this particular case, the
momentum is represented by a variable <span
class="math inline">\(v\)</span> updated to store an exponential
decaying sum of the previous gradients <span class="math inline">\(v :=
\alpha v + \nabla_\theta C(\theta)\)</span>. The weights are then
updated using negative <span class="math inline">\(v\)</span> as the
gradient direction instead of <span class="math inline">\(\nabla_\theta
C(\theta)\)</span>.</p>
<p>Other optimizers also make use of the second moment of the gradients.
Adagrad <span class="citation" data-cites="duchi_2011">[<a
href="#ref-duchi_2011" role="doc-biblioref">9</a>]</span> uses another
variable <span class="math inline">\(r\)</span> to store the second
moment <span class="math inline">\(r := r + \nabla_\theta C(\theta)
\odot \nabla_\theta C(\theta)\)</span> and modulate the update rule
toward the negative direction <span
class="math inline">\(\frac{1}{\delta + \sqrt{r}} \odot \nabla_\theta
C(\theta)\)</span> where <span class="math inline">\(\delta\)</span> is
a small value to avoid division by zero. Similarly, RMSProp <span
class="citation" data-cites="hinton_lecture6a">[<a
href="#ref-hinton_lecture6a" role="doc-biblioref">19</a>]</span>
maintains a running mean of the second moment <span
class="math inline">\(r := \rho r + (1 - \rho) \nabla_\theta C(\theta)
\odot \nabla_\theta C(\theta)\)</span>.</p>
<p>Finally Adam <span class="citation" data-cites="kingma_2014">[<a
href="#ref-kingma_2014" role="doc-biblioref">28</a>]</span>, and its
correction AdamW <span class="citation" data-cites="loshchilov_2017">[<a
href="#ref-loshchilov_2017" role="doc-biblioref">37</a>]</span>, are
applying both Momentum and RMSProp estimating the first and second
moment to make parameters with large gradients take small steps and
parameters with low gradients take larger ones. This has the advantage
to allow for bigger learning rates and faster convergence at the cost of
triple the amount of parameters to store during training. A simple
implementation of Adam is shown below (see
Lst <strong>¿lst:adam?</strong>):</p>
<!-- - Adagrad, RMSProp, AdamW
- Adam: Big Gradient = Small Steps, Small Gradient == Big Steps -->
<div class="sourceCode" id="lst:adam"><pre
class="sourceCode python"><code class="sourceCode python"><span id="lst:adam-1"><a href="#lst:adam-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Adam state (parameters, gradients first and second moments)</span></span>
<span id="lst:adam-2"><a href="#lst:adam-2" aria-hidden="true" tabindex="-1"></a>params <span class="op">=</span> <span class="bu">list</span>(f.parameters())</span>
<span id="lst:adam-3"><a href="#lst:adam-3" aria-hidden="true" tabindex="-1"></a>d_means <span class="op">=</span> [w.clone().zeros_() <span class="cf">for</span> w <span class="kw">in</span> params]</span>
<span id="lst:adam-4"><a href="#lst:adam-4" aria-hidden="true" tabindex="-1"></a>d_vars  <span class="op">=</span> [w.clone().zeros_() <span class="cf">for</span> w <span class="kw">in</span> params]</span>
<span id="lst:adam-5"><a href="#lst:adam-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="lst:adam-6"><a href="#lst:adam-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> step <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1_000</span>):</span>
<span id="lst:adam-7"><a href="#lst:adam-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Retrieve the next minibatch</span></span>
<span id="lst:adam-8"><a href="#lst:adam-8" aria-hidden="true" tabindex="-1"></a>    x, y <span class="op">=</span> next_minibatch(X, Y)</span>
<span id="lst:adam-9"><a href="#lst:adam-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="lst:adam-10"><a href="#lst:adam-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute the objective function and the gradients</span></span>
<span id="lst:adam-11"><a href="#lst:adam-11" aria-hidden="true" tabindex="-1"></a>    C <span class="op">=</span> L(f(x), y) <span class="op">+</span> lam <span class="op">*</span> R(f)</span>
<span id="lst:adam-12"><a href="#lst:adam-12" aria-hidden="true" tabindex="-1"></a>    C.backward()</span>
<span id="lst:adam-13"><a href="#lst:adam-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="lst:adam-14"><a href="#lst:adam-14" aria-hidden="true" tabindex="-1"></a>    data <span class="op">=</span> <span class="bu">zip</span>(params, d_means, d_vars)</span>
<span id="lst:adam-15"><a href="#lst:adam-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> w_idx, (w, d_m, d_v) <span class="kw">in</span> <span class="bu">enumerate</span>(data):</span>
<span id="lst:adam-16"><a href="#lst:adam-16" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Update the moments (mean and uncentered variance)</span></span>
<span id="lst:adam-17"><a href="#lst:adam-17" aria-hidden="true" tabindex="-1"></a>        d_m <span class="op">=</span> beta1 <span class="op">*</span> d_m <span class="op">+</span> (<span class="dv">1</span> <span class="op">-</span> beta1) <span class="op">*</span> w.grad</span>
<span id="lst:adam-18"><a href="#lst:adam-18" aria-hidden="true" tabindex="-1"></a>        d_v <span class="op">=</span> beta2 <span class="op">*</span> d_v <span class="op">+</span> (<span class="dv">1</span> <span class="op">-</span> beta2) <span class="op">*</span> (w.grad <span class="op">**</span> <span class="dv">2</span>)</span>
<span id="lst:adam-19"><a href="#lst:adam-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="lst:adam-20"><a href="#lst:adam-20" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Compute bias correction</span></span>
<span id="lst:adam-21"><a href="#lst:adam-21" aria-hidden="true" tabindex="-1"></a>        corr_m <span class="op">=</span> d_m <span class="op">/</span> (<span class="fl">1.0</span> <span class="op">-</span> beta1 <span class="op">**</span> step)</span>
<span id="lst:adam-22"><a href="#lst:adam-22" aria-hidden="true" tabindex="-1"></a>        corr_v <span class="op">=</span> d_v <span class="op">/</span> (<span class="fl">1.0</span> <span class="op">-</span> beta2 <span class="op">**</span> step)</span>
<span id="lst:adam-23"><a href="#lst:adam-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="lst:adam-24"><a href="#lst:adam-24" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Update weight and reset the gradient</span></span>
<span id="lst:adam-25"><a href="#lst:adam-25" aria-hidden="true" tabindex="-1"></a>        w <span class="op">-=</span> eps <span class="op">*</span> (corr_m <span class="op">/</span> (corr_v.sqrt() <span class="op">+</span> <span class="fl">1e-8</span>))</span>
<span id="lst:adam-26"><a href="#lst:adam-26" aria-hidden="true" tabindex="-1"></a>        w.grad <span class="op">=</span> <span class="va">None</span></span></code></pre></div>
<figure id="fig:sgd_moments">
<img src="./figures/core_nn_sgd_moments.svg"
alt="This toy example illustrates the impact of the optimizer choice during objective minimization with first order methods. SGD, Momentum, Adagrad, RMSProp and Adam are tasked to find the minimum of a 1-dimensional mixture of Gaussians given the same starting point x = 1 and the same learning rate \epsilon = 0.5. In this particular setup, Moments and Adagrad find the solution, RMSProp explodes, and SGD and Adam are stuck into a local minimum." />
<figcaption>Figure 10: This toy example illustrates the impact of the
optimizer choice during objective minimization with first order methods.
SGD, Momentum, Adagrad, RMSProp and Adam are tasked to find the minimum
of a 1-dimensional mixture of Gaussians given the same starting point
<span class="math inline">\(x = 1\)</span> and the same learning rate
<span class="math inline">\(\epsilon = 0.5\)</span>. In this particular
setup, Moments and Adagrad find the solution, RMSProp explodes, and SGD
and Adam are stuck into a local minimum.</figcaption>
</figure>
<p><strong>Cross-Validation and HyperParameter Search:</strong> As
illustrated by the toy examples (see Figs <a href="#fig:toysgd">9</a>,
<a href="#fig:sgd_moments">10</a>), the training of NN using SGD is
highly dependent on the initial setting of hyperparameters. One could
ask if there is a rule for choosing such parameters. Unfortunately, this
is not the case. The field is highly empirical and driven by exploration
using the scientific method.</p>
<p>One common approach is to set up metrics to evaluate the performance
of the model during the optimization process. It is a good practice to
divide the dataset into validation folds that are different from the
training data to evaluate the generalization capabilities of the model.
This practice is referred to as <span
class="math inline">\(k\)</span>-fold cross-validation and is most of
the time in DL, because of the large datasets, reduced to a single fold,
called the validation set. By defining such a process, NN can be
compared in a controlled manner and the hyperparameter space can be
searched. Hyperparameter search is so important that it is a subfield of
its own. The broad DL literature however contains many examples of
initial parameters and architectures that can be used to bootstrap this
search.</p>
<h4 id="sec:backpropagation">Backpropagation</h4>
<p>In the previous sub-section (see <a
href="#sec:optimization">Sec 2.2.2.2</a>), we saw how to learn
parametrized functions <span class="math inline">\(f_\theta\)</span>
given a training dataset. By evaluating the gradients of the objective
function with respect to the model’s parameters, it is possible to
obtain a good enough mapping <span class="math inline">\(f_\theta: X
\rightarrow Y\)</span>. In this sub-section, we discuss backpropagation,
the recursive algorithm used to efficiently compute those gradients
exploiting the chain rule <span class="math inline">\(\frac{\partial
z}{\partial x} = \frac{\partial z}{\partial y} \cdot \frac{\partial
y}{\partial x}\)</span> with <span class="math inline">\(z\)</span>
dependant on <span class="math inline">\(y\)</span> and <span
class="math inline">\(y\)</span> on <span
class="math inline">\(x\)</span>.</p>
<figure id="fig:dag">
<img src="./figures/core_nn_dag.svg"
alt="Illustration of reverse mode Automatic Differentiation (AD). This Directed Acyclic Graph (DAG) shows the forward pass in green and backward in red. The gradient of an activation is computed by multiplying the local gradient of a node by its output gradient computed in the previous step when following backward differentiation \frac{\partial C}{\partial x} = \frac{\partial z}{\partial x} \cdot \frac{\partial C}{\partial z} where \frac{\partial z}{\partial x} is the location derivative and \frac{\partial C}{\partial z} the output one." />
<figcaption>Figure 11: Illustration of reverse mode Automatic
Differentiation (AD). This Directed Acyclic Graph (DAG) shows the
forward pass in green and backward in red. The gradient of an activation
is computed by multiplying the local gradient of a node by its output
gradient computed in the previous step when following backward
differentiation <span class="math inline">\(\frac{\partial C}{\partial
x} = \frac{\partial z}{\partial x} \cdot \frac{\partial C}{\partial
z}\)</span> where <span class="math inline">\(\frac{\partial z}{\partial
x}\)</span> is the location derivative and <span
class="math inline">\(\frac{\partial C}{\partial z}\)</span> the output
one.</figcaption>
</figure>
<p><strong>Automatic Differentiation:</strong> In mathematics, AD
describes the set of techniques used to evaluate the derivative of a
function and exploits the fact that any complex computation can be
transformed into a sequence of elementary operations and functions with
known symbolic derivatives. By applying the chain rule recursively to
this sequence of operations, one can automatically compute the
derivatives with precision at the cost of storage.</p>
<p>We distinguish two modes of operation for AD, forward mode
differentiation, and reverse mode differentiation. In forward mode, the
derivatives are computed after applying each elementary operation and
function in order using the chain rule. It requires storing the
gradients along the way and carrying them until the last computation.
This mode is preferred when the size of the outputs exceeds the size of
the inputs. This is generally not the case for NN where the input, an
image for example, is larger than the output, a scalar for the objective
function. On the opposite, reverse mode differentiation traverses the
sequence of operations from end to start using the chain rule and
requires storing the output of the operations instead. This method is
preferred when the size of the inputs exceeds the outputs. This mode
thus has to happen in two passes, a forward pass where one computes the
output of every operation in the order, and a backward pass, where the
sequence of operations is traversed in backward order to compute the
derivatives.</p>
<p><strong>Computation Graph:</strong> A NN can be defined as a
succession of linear transformations followed by non-linear activations
(discussed in the next section <a href="#sec:nn">Sec 2.2.3</a>). Those
elementary operations are differentiable and when thinking of the data
flow can be viewed as a computation DAG to which backpropagation,
reverse mode differentiation, can be applied.</p>
<p>In modern DL frameworks <span class="citation"
data-cites="pytorch tensorflow">[<a href="#ref-tensorflow"
role="doc-biblioref">1</a>, <a href="#ref-pytorch"
role="doc-biblioref">44</a>]</span>, the AD is centered on the
implementation of a Graph object with Nodes. Both entities possess a
<code>forward()</code> and a <code>backward()</code> function. The
forward pass calls the <code>forward()</code> function of each node of
the graph by traversing it in order while saving the node output for
differentiation. The backward pass traverses the graph recursively in
backward order calling the <code>backward()</code> function responsible
for computing the local gradient of the node operation and multiplying
it by its output gradient following the chain rule. Nodes are in most
frameworks referred to as Layers, the elementary building block of the
NN operation chain.</p>
<p><strong>Toy Implementation:</strong> Here is a simple implementation
of such a computation graph for backpropagation and AD engines adapted
from Micrograd by Andrej Karpathy <span class="citation"
data-cites="karpathy_micrograd">[<a href="#ref-karpathy_micrograd"
role="doc-biblioref">26</a>]</span>. The Node class is responsible for
storing the value, the chained gradient, and additional information to
trace the graph for the backward pass.</p>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dataclasses <span class="im">import</span> dataclass</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="at">@dataclass</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Node:</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>    value: <span class="bu">float</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>    grad: <span class="bu">float</span> <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>    _backward <span class="op">=</span> <span class="kw">lambda</span>: <span class="va">None</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>    _children: <span class="bu">set</span>[Node] <span class="op">=</span> {}</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>    _op <span class="op">=</span> <span class="st">&quot;&quot;</span></span></code></pre></div>
<p>The Node can then be populated with elementary operations
(<code>__add__</code>, <code>__mul__</code>) and functions
(<code>tanh</code>).</p>
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Node:</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>    ...</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__add__</span>(<span class="va">self</span>, other: Node) <span class="op">-&gt;</span> Node:</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> Node(<span class="va">self</span>.value <span class="op">+</span> other.value, {<span class="va">self</span>, other}, <span class="st">&quot;+&quot;</span>)</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>        <span class="kw">def</span> _backward() <span class="op">-&gt;</span> <span class="va">None</span>:</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.grad <span class="op">+=</span> out.grad</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>            other.grad <span class="op">+=</span> out.grad</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>        out._backward <span class="op">=</span> _backward</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> out</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__mul__</span>(<span class="va">self</span>, other: Node) <span class="op">-&gt;</span> Node:</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> Node(<span class="va">self</span>.value <span class="op">*</span> other.value, {<span class="va">self</span>, other}, <span class="st">&quot;*&quot;</span>)</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>        <span class="kw">def</span> _backward() <span class="op">-&gt;</span> <span class="va">None</span>:</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.grad <span class="op">+=</span> other.value <span class="op">*</span> out.grad</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>            other.grad <span class="op">+=</span> <span class="va">self</span>.value <span class="op">*</span> out.grad</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>        out._backward <span class="op">=</span> _backward</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> out</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> tanh(<span class="va">self</span>) <span class="op">-&gt;</span> Node:</span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a>        act <span class="op">=</span> np.tanh(<span class="va">self</span>.value)</span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> Node(act, {<span class="va">self</span>}, <span class="st">&quot;tanh&quot;</span>)</span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a>        <span class="kw">def</span> _backward() <span class="op">-&gt;</span> <span class="va">None</span>:</span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.grad <span class="op">+=</span> (<span class="fl">1.0</span> <span class="op">-</span> act <span class="op">**</span> <span class="dv">2</span>) <span class="op">*</span> out.grad</span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a>        out._backward <span class="op">=</span> _backward</span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> out</span></code></pre></div>
<p>Every elementary transformation needs to be differentiable and
implements its own backward function using the chain rule. The chained
gradient stored in the node is the multiplication of the local gradient
with its output gradient computed when the parent node is encountered
during the backward pass. The Node object needs to be extended with
support for other elementary operations (e.g. <code>__pow__</code>,
<code>__neg__</code>) and functions (e.g. <code>sigmoid</code>,
<code>relu</code>) to be useful for DL.</p>
<p>We add the ability for a Node to compute its backward pass by first
tracing all the current DAG operations recursively. The gradients can
then be computed by initializing the first node (the last in the graph)
gradient to <span class="math inline">\(1\)</span>. The backward call on
the graph iteratively traverses the graph from end to start and applies
the inner backward functions to compute the chain gradients along the
way while storing them in their respective Node object.</p>
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Node:</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>    ...</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> backward(<span class="va">self</span>) <span class="op">-&gt;</span> <span class="va">None</span>:</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>        trace, visited <span class="op">=</span> [], {}</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>        <span class="kw">def</span> trace_graph(node: Node) <span class="op">-&gt;</span> <span class="va">None</span>:</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> node <span class="kw">not</span> <span class="kw">in</span> visited:</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>                visited.add(node)</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>                <span class="cf">for</span> child <span class="kw">in</span> node._children:</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>                    trace_graph(child)</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>                trace.append(node)</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>        trace_graph(<span class="va">self</span>)</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.grad <span class="op">=</span> <span class="fl">1.0</span></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> node <span class="kw">in</span> trace[::<span class="op">-</span><span class="dv">1</span>]:</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>            node._backward()</span></code></pre></div>
<p>The simple Automatic Differentiation (AD) engine is now ready to
perform forward and backward passes. The gradients stored in the node
can then be used for Stochastic Gradient Descent (SGD) to update the
weights of a Neural Network (NN) for example.</p>
<div class="sourceCode" id="cb4"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>w1, w2 <span class="op">=</span> Node(<span class="fl">0.1</span>), Node(<span class="fl">0.2</span>)  <span class="co"># Weights</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>a,  b  <span class="op">=</span> Node(<span class="fl">1.0</span>), Node(<span class="fl">0.0</span>)  <span class="co"># Inputs</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>z <span class="op">=</span> (w1 <span class="op">*</span> a <span class="op">+</span> w2 <span class="op">*</span> b).tanh()   <span class="co"># Eager forward pass</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>z.backward()                   <span class="co"># Backward pass</span></span></code></pre></div>
<p>Fortunatly open-source implementations of such engines are already
available and extensively used by the DL community. They have the
adantage to work at the Tensor level, not at the Scalar level like
Micrograd, and offer support for accelerated hardware such as Graphical
Processing Units (GPU), Tensor Processing Units (TPU), and Neural
Processing Units (NPU). In this dissertation, most examples are using
the PyTorch <span class="citation" data-cites="pytorch">[<a
href="#ref-pytorch" role="doc-biblioref">44</a>]</span> framework, a
Python Tensor library written in C++ and equipped with a powerful eager
mode reverse AD engine.</p>
<p><strong>Eager or Graph Execution:</strong> Modern DL frameworks such
as PyTorch <span class="citation" data-cites="pytorch">[<a
href="#ref-pytorch" role="doc-biblioref">44</a>]</span> and Tensorflow
<span class="citation" data-cites="tensorflow">[<a
href="#ref-tensorflow" role="doc-biblioref">1</a>]</span> now propose
two execution modes. An eager mode, where the graph is built dynamically
and operations are applied immediately, and a graph mode where the
computational graph has to be defined beforehand. Both modes come with
advantages and inconveniences. Eager mode is useful for iterative
development and provides an intuitive interface similar to imperative
programming, it is easier to debug and offers natural control flows as
well as hardware acceleration support. On the other side, graph mode
allows for more efficient execution. The graph can be optimized by
applying operations similar to the ones used in programming language
Abstract Syntax Trees (AST). Graph edges can be merged into a single
fused operation, and execution can be optimized for parallelization. It
is often the preferred way for deployment where the execution time and
memory are at stake.</p>
<h3 id="sec:nn">Neural Networks</h3>
<p>In the previous section, we described the general setup for ML, where
one has to fit a model from a given function family <span
class="math inline">\(f \in \mathcal{F}\)</span> on a given dataset
<span class="math inline">\((X, Y) \in D\)</span> optimized using +sdg
and backpropagation. This section begins discussing a particular class
of parameterized function <span class="math inline">\(f_\theta\)</span>
called Neural Networks (NN).</p>
<h4 id="sec:perceptron">Perceptron</h4>
<p>The Perceptron, introduced by Frank Rosenblatt in 1958 <span
class="citation" data-cites="rosenblatt_1958">[<a
href="#ref-rosenblatt_1958" role="doc-biblioref">49</a>]</span>, is the
building block of Neural Networks (NN). It was introduced as a
simplified model of the human neuron, containing three parts: dendrites
handling incoming signals from other neurons, a soma with a nucleus
responsible for signal aggregation, and an axone responsible for the
transmission of the processed signal to other neurons. When the signal
aggregation in the soma reaches a predefined threshold, the neuron
activates. This phenomenon is called an action potential. Although this
is not an accurate representation of the modern neuroscience state of
knowledge, this simplified model was believed to be accurate at the
time.</p>
<figure id="fig:perceptron">
<img src="./figures/core_nn_perceptron.svg"
alt="Diagram of a Perceptron with three inputs \{x_1; x_2; x_3\}. The perceptron computes an activated weighted sum of its inputs y = \sigma(\sum_{i=1}^{3} w_i \cdot x_i) where \sigma, the activation function is a threshold function." />
<figcaption>Figure 12: Diagram of a Perceptron with three inputs <span
class="math inline">\(\{x_1; x_2; x_3\}\)</span>. The perceptron
computes an activated weighted sum of its inputs <span
class="math inline">\(y = \sigma(\sum_{i=1}^{3} w_i \cdot x_i)\)</span>
where <span class="math inline">\(\sigma\)</span>, the activation
function is a threshold function.</figcaption>
</figure>
<p>Similarly, the Perceptron computes a weighted sum of its inputs and
activates if a certain threshold is reached (see <a
href="#fig:perceptron">Fig 12</a>). The Perceptron is parametrized by
the weights representing the importance attributed to the incoming
inputs and are part of the parameters <span
class="math inline">\(\theta\)</span> that are trained on a given
dataset. It can be viewed as a learned linear regressor followed by a
non-linear activation, historically a threshold function, a function
<span class="math inline">\(\sigma\)</span> that activates <span
class="math inline">\(\sigma(x) = 1\)</span> when <span
class="math inline">\(x &gt; 0.5\)</span> and <span
class="math inline">\(\sigma(x) = 0\)</span> otherwise (see
Lst <strong>¿lst:perceptron?</strong>).</p>
<div class="sourceCode" id="lst:perceptron"><pre
class="sourceCode python"><code class="sourceCode python"><span id="lst:perceptron-1"><a href="#lst:perceptron-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> perceptron(<span class="va">self</span>, x: Tensor, W: Tensor) <span class="op">-&gt;</span> Tensor:</span>
<span id="lst:perceptron-2"><a href="#lst:perceptron-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (x <span class="op">*</span> <span class="va">self</span>.W.T) <span class="op">&gt;</span> <span class="fl">0.5</span></span></code></pre></div>
<p>The objective of a perceptron is to learn a hyperplane, a plane with
<span class="math inline">\(n - 1\)</span> dimensions where <span
class="math inline">\(n\)</span> is the number of inputs, that can
perform binary classification, separate two classes. However, as
mentioned by Marvin L. Minsky and al. in their controversial book
Perceptrons <span class="citation" data-cites="minsky_1969">[<a
href="#ref-minsky_1969" role="doc-biblioref">40</a>]</span>, a
hyperplane regressor cannot solve a simple XOR problem (see <a
href="#fig:xor">Fig 13</a>).</p>
<figure id="fig:xor">
<img src="./figures/core_nn_xor.svg"
alt="Illustration of the Perceptron’s decision hyperplane when trained to solve the AND problem on the left, the OR problem in the middle, and the XOR problem on the right. The first two problems are linearly sperable, thus adapted for a Perceptron. However, a single perceptron cannot solve the XOR problem as it is not linearly separable." />
<figcaption>Figure 13: Illustration of the Perceptron’s decision
hyperplane when trained to solve the AND problem on the left, the OR
problem in the middle, and the XOR problem on the right. The first two
problems are linearly sperable, thus adapted for a Perceptron. However,
a single perceptron cannot solve the XOR problem as it is not linearly
separable.</figcaption>
</figure>
<h4 id="sec:mlp">Multi-Layer Perceptron</h4>
<p>The real value of the Perceptron comes when assembled into a
hierarchical and layer-wise architecture, a Neural Network (NN). By
repeating matrix multiplications (linear transformations) and
non-linearities the network is able to handle non-linear problems and
act as a universal function approximator <span class="citation"
data-cites="hornik_1989">[<a href="#ref-hornik_1989"
role="doc-biblioref">22</a>]</span>. This arrangement of layered
perceptrons is called a Multi-Layer Perceptron (MLP) (see <a
href="#fig:mlp">Fig 14</a>).</p>
<figure id="fig:mlp" width="90%">
<img src="./figures/core_nn_mlp.svg" style="width:90.0%"
alt="Diagram of a 3-layer Multi-Layer Perceptron (MLP). When using the matrix formulation, this arrangement of neurons can be summarized into a single expression y = \sigma(\sigma(x \cdot W_1^T) \cdot W_2^T) \cdot W_3^T." />
<figcaption>Figure 14: Diagram of a 3-layer Multi-Layer Perceptron
(MLP). When using the matrix formulation, this arrangement of neurons
can be summarized into a single expression <span class="math inline">\(y
= \sigma(\sigma(x \cdot W_1^T) \cdot W_2^T) \cdot
W_3^T\)</span>.</figcaption>
</figure>
<p>A MLP with Identity as its activation function is useless as its
chain of linear transformations can be collapsed into a single one.
Since the advent of the Perceptron, the literature has moved away from
using threshold functions as activations. Common activation functions
are the sigmoid <span class="math inline">\(\sigma(x) = \frac{1}{1 +
e^{-x}}\)</span>, tanh <span class="math inline">\(tanh(x) = \frac{e^{z}
- e^{-z}}{e^{z} + e^{-z}}\)</span>, Rectified Linear Unit (ReLU) <span
class="math inline">\(ReLU(x) = max(x, 0)\)</span> functions and
variants presenting additional properties such as infinite continuity,
gradient smoothness, and more (see <a
href="#fig:activations">Fig 15</a>).</p>
<figure id="fig:activations">
<img src="./figures/core_nn_activations.svg"
alt="Activation functions. Sigmoid \sigma(x) = \frac{1}{1 + e^{-x}} acts as a filter y \in [0; 1], tanh tanh(x) = \frac{e^{z} - e^{-z}}{e^{z} + e^{-z}} acts as a normalization compressor y \in [-1; 1], ReLU ReLU(x) = max(x, 0) folds all negatives down to zero y \in [0; +\infty]." />
<figcaption>Figure 15: Activation functions. Sigmoid <span
class="math inline">\(\sigma(x) = \frac{1}{1 + e^{-x}}\)</span> acts as
a filter <span class="math inline">\(y \in [0; 1]\)</span>, tanh <span
class="math inline">\(tanh(x) = \frac{e^{z} - e^{-z}}{e^{z} +
e^{-z}}\)</span> acts as a normalization compressor <span
class="math inline">\(y \in [-1; 1]\)</span>, ReLU <span
class="math inline">\(ReLU(x) = max(x, 0)\)</span> folds all negatives
down to zero <span class="math inline">\(y \in [0;
+\infty]\)</span>.</figcaption>
</figure>
<p><strong>MNIST Classifier:</strong> A classic toy example showing the
capabilities of MLPs is the handwritten digit classification challenge
on the Modified National Institute of Standards and Technology (MNIST)
dataset <span class="citation" data-cites="mnist">[<a href="#ref-mnist"
role="doc-biblioref">56</a>]</span>. MNIST contains <span
class="math inline">\(60,000\)</span> training and <span
class="math inline">\(10,000\)</span> test examples. It has been written
by high school students and gather <span class="math inline">\(28 \times
28\)</span> centered black and white handwritten digits from <span
class="math inline">\(0\)</span> to <span
class="math inline">\(9\)</span> (see <a
href="#fig:mnist">Fig 16</a>).</p>
<figure id="fig:mnist">
<img src="./figures/core_nn_mnist.svg"
alt="First 27 handwritten digits from the Modified National Institute of Standards and Technology (MNIST) dataset. The digits are stored as 28 \times 28 centered black and white images." />
<figcaption>Figure 16: First <span class="math inline">\(27\)</span>
handwritten digits from the Modified National Institute of Standards and
Technology (MNIST) dataset. The digits are stored as <span
class="math inline">\(28 \times 28\)</span> centered black and white
images.</figcaption>
</figure>
<p>Training a MLP on such a challenge is simple and effective. With
little training, parameters (according to the DL standards), and no
hyperparameter tweaking, a vanilla 3-layer NN with ReLU activations can
achieve <span class="math inline">\(97.5%\)</span> accuracy on the test
set. The inputs however need to be transformed before ingestion by the
model as MLPs are constrained to <span
class="math inline">\(1\)</span>-dimensional input vectors. The
following demonstrates how to implement such a model and train it on
MNIST.</p>
<div class="sourceCode" id="cb5"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> (Subset, DataLoader)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision.datasets.mnist <span class="im">import</span> MNIST</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision.transforms.functional <span class="im">import</span> to_tensor</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Load MNIST images as Tensors and Normalize [0; 1]</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>T <span class="op">=</span> <span class="kw">lambda</span> x: to_tensor(x).<span class="bu">float</span>().flatten()</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>dataset <span class="op">=</span> MNIST(<span class="st">&quot;dataset&quot;</span>, train<span class="op">=</span><span class="va">True</span>,  transform<span class="op">=</span>T.ToTensor())</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>testset <span class="op">=</span> MNIST(<span class="st">&quot;dataset&quot;</span>, train<span class="op">=</span><span class="va">False</span>, transform<span class="op">=</span>T.ToTensor())</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Split dataset in Train and Validation Splits</span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>n, split <span class="op">=</span> <span class="bu">len</span>(dataset), <span class="bu">int</span>(np.floor(<span class="fl">0.8</span> <span class="op">*</span> <span class="bu">len</span>(dataset)))</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>train_idxs <span class="op">=</span> np.random.choice(<span class="bu">range</span>(n), size<span class="op">=</span>split, replace<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>valid_idxs <span class="op">=</span> [idx <span class="cf">for</span> idx <span class="kw">in</span> <span class="bu">range</span>(n) <span class="cf">if</span> idx <span class="kw">not</span> <span class="kw">in</span> train_idxs]</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>trainset <span class="op">=</span> Subset(dataset, indices<span class="op">=</span>train_idxs)</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>validset <span class="op">=</span> Subset(dataset, indices<span class="op">=</span>valid_idxs)</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Mini Batch Loaders (Shuffle Order for Training)</span></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>trainloader <span class="op">=</span> DataLoader(trainset, batch_size<span class="op">=</span><span class="dv">1_024</span>, shuffle<span class="op">=</span><span class="va">True</span> )</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>validloader <span class="op">=</span> DataLoader(validset, batch_size<span class="op">=</span><span class="dv">1_024</span>, shuffle<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>testloader  <span class="op">=</span> DataLoader(testset,  batch_size<span class="op">=</span><span class="dv">1_024</span>, shuffle<span class="op">=</span><span class="va">False</span>)</span></code></pre></div>
<p>The first step consists in loading the MNIST dataset and applying
preprocessing to the data for preparing the ingestion by the model. The
images need to be transformed into a normalized tensor and flatten to
form a <span class="math inline">\(1\)</span>-dimensional vector. The
datasets are split into a training set, a validation set, and a test
set. A mini-batch loader is then used to wrap the dataset and load
multiple input and output pairs at the same time.</p>
<div class="sourceCode" id="cb6"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.nn <span class="im">import</span> (Linear, Module, ReLU, Sequential)</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.optim <span class="im">import</span> (AdamW, Optimizer)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Model and Optimizer</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Sequential(</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>    Linear(<span class="dv">28</span> <span class="op">*</span> <span class="dv">28</span>, <span class="dv">128</span>), ReLU(),</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>    Linear(    <span class="dv">128</span>, <span class="dv">128</span>), ReLU(),</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>    Linear(    <span class="dv">128</span>,  <span class="dv">10</span>),</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>optim <span class="op">=</span> AdamW(model.parameters(), lr<span class="op">=</span><span class="fl">1e-2</span>)</span></code></pre></div>
<p>Then, the model is defined as a sequence of three linear layers
(linear transformations with a bias for the intercept) and ReLU
activations except for the last one responsible for outputting the
logits, used for computing the loss, here the cross entropy for
multi-class classification. The enhanced SGD optimizer, Adam, is then
initialized with the model’s weight and a learning rate <span
class="math inline">\(\epsilon\)</span>. AdamW is a variant of Adam with
a corrected weight decay term for regularization.</p>
<div class="sourceCode" id="cb7"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch <span class="im">import</span> Tensor</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.nn.functional <span class="im">import</span> cross_entropy</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Perform one Step and estimate Metrics</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> step(</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>    model: Module,</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>    optim: Optimizer,</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>    imgs: Tensor,</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>    labels: Tensor,</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>    split: <span class="bu">str</span>,</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>) <span class="op">-&gt;</span> Tuple[<span class="bu">float</span>, <span class="bu">float</span>]:</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>    logits <span class="op">=</span> model(imgs)                  <span class="co"># Prediction</span></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> cross_entropy(logits, labels)  <span class="co"># Mean Loss</span></span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>    n_correct <span class="op">=</span> logits.argmax(dim<span class="op">=-</span><span class="dv">1</span>)     <span class="co"># Correct Predictions</span></span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Train if split is &quot;train&quot;</span></span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> split <span class="op">==</span> <span class="st">&quot;train&quot;</span>:</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>        loss.backward()</span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>        optim.step()</span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>        optim.zero_grad(set_to_none<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> loss.item(), n_correct.item()</span></code></pre></div>
<p>The <code>step</code> function is responsible for performing one
training step when the given split is set to <code>"train"</code> and
computes the metrics used for monitoring. In our case, we monitor the
average loss and the accuracy of the model. For a more complete
evaluation, other metrics such as the F-<span
class="math inline">\(1\)</span> score, the perplexity, the recall, and
a confusion matrix can be evaluated. They are here omitted for the sake
of illustration and simplicity.</p>
<div class="sourceCode" id="cb8"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Train for 10 epochs</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10</span>):</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Training</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>    model.train()</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>    loss, acc <span class="op">=</span> <span class="dv">0</span>, <span class="dv">0</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> imgs, labels <span class="kw">in</span> trainloader:</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>        metrics <span class="op">=</span> step(model, optim, imgs, label, <span class="st">&quot;train&quot;</span>)</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">+=</span> metrics[<span class="dv">0</span>] <span class="op">/</span> <span class="bu">len</span>(trainloader)</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>        acc  <span class="op">+=</span> metrics[<span class="dv">1</span>] <span class="op">/</span> <span class="bu">len</span>(trainloader.dataset)</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&quot;[Train] Epoch </span><span class="sc">{</span>epoch<span class="sc">}</span><span class="ss">, loss: </span><span class="sc">{</span>loss<span class="sc">:.2e}</span><span class="ss">, acc: </span><span class="sc">{</span>acc <span class="op">*</span> <span class="dv">100</span><span class="sc">:.2f}</span><span class="ss">%&quot;</span>)</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Validation</span></span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">eval</span>()</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.inference_mode():</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>        loss, acc <span class="op">=</span> <span class="dv">0</span>, <span class="dv">0</span></span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> imgs, labels <span class="kw">in</span> validloader:</span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>            metrics <span class="op">=</span> step(model, optim, imgs, label, <span class="st">&quot;valid&quot;</span>)</span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">+=</span> metrics[<span class="dv">0</span>] <span class="op">/</span> <span class="bu">len</span>(validloader)</span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>            acc  <span class="op">+=</span> metrics[<span class="dv">1</span>] <span class="op">/</span> <span class="bu">len</span>(validloader.dataset)</span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&quot;[Valid] Epoch </span><span class="sc">{</span>epoch<span class="sc">}</span><span class="ss">, loss: </span><span class="sc">{</span>loss<span class="sc">:.2e}</span><span class="ss">, acc: </span><span class="sc">{</span>acc <span class="op">*</span> <span class="dv">100</span><span class="sc">:.2f}</span><span class="ss">%&quot;</span>)</span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Test</span></span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">eval</span>()</span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.inference_mode():</span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a>    loss, acc <span class="op">=</span> <span class="dv">0</span>, <span class="dv">0</span></span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> imgs, labels <span class="kw">in</span> testloader:</span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a>        metrics <span class="op">=</span> step(model, optim, imgs, label, <span class="st">&quot;test&quot;</span>)</span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">+=</span> metrics[<span class="dv">0</span>] <span class="op">/</span> <span class="bu">len</span>(testloader)</span>
<span id="cb8-29"><a href="#cb8-29" aria-hidden="true" tabindex="-1"></a>        acc  <span class="op">+=</span> metrics[<span class="dv">1</span>] <span class="op">/</span> <span class="bu">len</span>(testloader.dataset)</span>
<span id="cb8-30"><a href="#cb8-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;[Test] loss: </span><span class="sc">{</span>loss<span class="sc">:.2e}</span><span class="ss">, acc: </span><span class="sc">{</span>acc <span class="op">*</span> <span class="dv">100</span><span class="sc">:.2f}</span><span class="ss">%&quot;</span>)</span></code></pre></div>
<p>Finally, the model is trained for <span
class="math inline">\(10\)</span> epochs, the number of times the entire
dataset is looped through. This number was arbitrarily chosen to
correspond with the loss saturation when the model does not improve
much. A training loop is divided into a few steps, a training phase
where one continuously performs a training step followed by a validation
step to monitor generalization, and when stopped, a test phase to
monitor model generalization without bias. This last step prevents
trying to overfit the validation set specifically and should be
performed at the very end. An example of training history is shown in <a
href="#fig:mnist_history">Fig 17</a>. In this example, the model reaches
<span class="math inline">\(97.5%\)</span> accuracy. By spending time
tweaking the hyperparameters (the model’s weights, the learning rate,
the number of epochs, …), the model can be improved further.</p>
<figure id="fig:mnist_history">
<img src="./figures/core_nn_mnist_history.svg"
alt="Training history of a 3-layer Multi-Layer Perceptron (MLP) with 128 neurons in every layer on the MNIST dataset. The average loss (cross-entropy) on the left, and the accuracy on the right are displayed for the training, validation, and test splits." />
<figcaption>Figure 17: Training history of a 3-layer Multi-Layer
Perceptron (MLP) with <span class="math inline">\(128\)</span> neurons
in every layer on the MNIST dataset. The average loss (cross-entropy) on
the left, and the accuracy on the right are displayed for the training,
validation, and test splits.</figcaption>
</figure>
<h4 id="sec:cnn">Convolutional Neural Network</h4>
<p>While MLPs can be viewed as universal function approximators, they
scale poorly with respect to high dimensional inputs such as images,
videos, sound representations such as a spectrogram, volumetric data,
and long sequences. For example, if we consider a small RGB image of
size <span class="math inline">\(256 \times 256 \times 3\)</span>, the
input of a MLP would be a 1-dimensional vector of size <span
class="math inline">\(196,608\)</span>. The input layer of a MLP with
<span class="math inline">\(64\)</span> neurons would already mean that
the network contains more than <span
class="math inline">\(12,582,912\)</span> parameters. For this reason,
researchers have created specialized NNs with biases in their
architecture inspired by cognitive and biophysical mechanisms.
Convolutional Neural Networks (CNN) (ConvNets) are such a NN specialized
in handling spatially correlated data such as images.</p>
<figure id="fig:convolution">
<img src="./figures/core_nn_convolution.svg"
alt="Illustration of a single 3 \times 3 \times 3 filter convolution in the middle applied to a 8 \times 8 \times 3 input tensor on the left. The result is a 6 \times 6 \times 1 activation map on the right. The filter receptive field is drawn in dashed lines. This convolution is applied in valid model, no passing was applied to the input resulting in a lower resolution output tensor." />
<figcaption>Figure 18: Illustration of a single <span
class="math inline">\(3 \times 3 \times 3\)</span> filter convolution in
the middle applied to a <span class="math inline">\(8 \times 8 \times
3\)</span> input tensor on the left. The result is a <span
class="math inline">\(6 \times 6 \times 1\)</span> activation map on the
right. The filter receptive field is drawn in dashed lines. This
convolution is applied in valid model, no passing was applied to the
input resulting in a lower resolution output tensor.</figcaption>
</figure>
<p><strong>Convolution:</strong> The core component of a ConvNet is the
convolution operation. A +CNN operates by convolving (rolling) a set of
parametrized filters on the input. If we reconsider our <span
class="math inline">\(W_1 \times H_1 \times D_1 = 256 \times 256 \times
3\)</span>, convolving a single filter of size <span
class="math inline">\(F_W \times F_H \times D_1 = 3 \times 3 \times
3\)</span> would require sliding the filter across the entire input
image tensor and computing the dot product of the overlapping tensor
chunk and the filter. This operation results in what is called an
activation map, or feature map. The filter can be convolved in different
configurations. The stride <span class="math inline">\(S\)</span>
defines the hop size when rolling the filter over the input, and the
padding <span class="math inline">\(P\)</span> defines the additional
border added to the input tensor in order to parkour the input border
(<span class="math inline">\(252\)</span> unique positions for the
filter in the <span class="math inline">\(256\)</span> image, <span
class="math inline">\(256\)</span> positions with a padding of <span
class="math inline">\(1\)</span> on each side of the input). A CNN
convolves multiple parametrized filters <span
class="math inline">\(K\)</span> in a single convolution operation.
Given a convolution setting, the operation requires $$ parameters and
outputs a feature map tensor of size <span class="math inline">\(W_2 =
(W_1 - F_W + 2P_W) / S + 1\)</span>, <span class="math inline">\(H_2 =
(H_1 - F_H + 2P_H) / S + 1\)</span>, and <span class="math inline">\(D_2
= K\)</span> (see <a href="#fig:convolution">Fig 18</a>). The different
filters are responsible for looking for the activation of different
patterns in the input. The Convolution layer introduces the notion of
weight sharing enabled by the sliding filter (neurons) and reduces
computation by a large margin in comparison to a standard MLP layer.</p>
<p><strong>Pooling:</strong> It is common to follow convolution layers
by pooling layers to reduce the dimensionality when growing the ConvNet
deeper. The pooling layer reduces its input by applying a reduction
operation. The reduction operation can be taking the <code>max</code>,
<code>min</code>, or <code>average</code>, of a rolling window. This
operation does not involve any additional parameter and is applied
channel-wise. If we consider a max-pooling operation with a <span
class="math inline">\(2 \times 2\)</span> kernel and a stride of <span
class="math inline">\(2\)</span>, the output becomes half the size of
the input. It also has the benefit of making the CNN more robust to
scale and translation. It is sometimes more strategic to make use of
stride instead of adding pooling layers. It has the same benefit of
reducing the feature map size while avoiding an additional
operation.</p>
<figure id="fig:convnet">
<img src="./figures/core_nn_convnet.svg"
alt="Illustration of a small Convolutional Neural Networks (CNN) containing a convolution (conv) layer, a max-pooling (maxpool), and another convolution followed by another max-pooling. The last feature map is then flattened into a 1-dimensional vector and used as the input for the Multi-Layer Perceptron (MLP) classifier." />
<figcaption>Figure 19: Illustration of a small Convolutional Neural
Networks (CNN) containing a convolution (conv) layer, a max-pooling
(maxpool), and another convolution followed by another max-pooling. The
last feature map is then flattened into a <span
class="math inline">\(1\)</span>-dimensional vector and used as the
input for the Multi-Layer Perceptron (MLP) classifier.</figcaption>
</figure>
<p><strong>ConvNet:</strong> Finally, a CNN is assembled by stacking
multiple convolution layers and pooling layers. When the feature maps
are small enough, the final feature map is flattened and passed to an
additional MLP in charge of the classification or regression. This
combination of a parametric convolutional feature extractor and a MLP is
what we call a ConvNet.</p>
<figure id="fig:vgg_activations">
<img src="./figures/core_nn_vgg_activations.svg"
alt="Visualisation of VGG16’s four first activation maps (feature maps). The input image is left and the activations are shown in order of the layers top to bottom and left to right. Credit https://images.all4ed.org/" />
<figcaption>Figure 20: Visualisation of VGG16’s four first activation
maps (feature maps). The input image is left and the activations are
shown in order of the layers top to bottom and left to right. Credit <a
href="https://images.all4ed.org/">https://images.all4ed.org/</a></figcaption>
</figure>
<p><strong>Feature Maps:</strong> The feature maps learned by a CNN are
hierarchical. In the first layers, the learned filters are focusing on
simple features such as lines, diagonals, and arcs, and act as edge
detectors. The deeper the layers are, the more complex the features are
because they are resulting from a succession of combinations from
previous activations (see <a
href="#fig:vgg_activations">Fig 20</a>).</p>
<p><strong>Finetuning:</strong> …</p>
<p><strong>MNIST Classifier:</strong> …</p>
<div class="sourceCode" id="cb9"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> OrderedDict</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.nn <span class="im">import</span> (Conv2d, Flatten, Linear, MaxPool2d, ReLU, Sequential)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision.transforms.functional <span class="im">import</span> to_tensor</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Load MNIST images as Tensors and Normalize [0; 1]</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>T <span class="op">=</span> <span class="kw">lambda</span> x: to_tensor(x).<span class="bu">float</span>()</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>...</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Model</span></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Sequential(OrderedDict(</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>    features<span class="op">=</span>Sequential(</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>        Conv2d(<span class="dv">1</span>,  <span class="dv">6</span>, <span class="dv">5</span>), ReLU(), MaxPool2d(<span class="dv">2</span>),</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>        Conv2d(<span class="dv">6</span>, <span class="dv">16</span>, <span class="dv">5</span>), ReLU(), MaxPool2d(<span class="dv">2</span>),</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>    ),</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>    flatten<span class="op">=</span>Flatten(),</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>    classifier<span class="op">=</span>Sequential(</span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>        Linear(<span class="dv">256</span>, <span class="dv">128</span>), ReLU(),</span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>        Linear(<span class="dv">128</span>,  <span class="dv">64</span>), ReLU(),</span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>        Linear( <span class="dv">64</span>,  <span class="dv">10</span>),</span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a>    ),</span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a>))</span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a>...</span></code></pre></div>
<figure id="fig:mnist_convnet_history">
<img src="./figures/core_nn_mnist_convnet_history.svg"
alt="Training history of a Convolutional Neural Network (CNN) made out of a sequence of two convolutions followed by max-pooling and a 3-layer Multi-Layer Perceptron (MLP) classifier on the MNIST dataset. The average loss (cross-entropy) on the left, and the accuracy on the right are displayed for the training, validation, and test splits." />
<figcaption>Figure 21: Training history of a Convolutional Neural
Network (CNN) made out of a sequence of two convolutions followed by
max-pooling and a 3-layer Multi-Layer Perceptron (MLP) classifier on the
MNIST dataset. The average loss (cross-entropy) on the left, and the
accuracy on the right are displayed for the training, validation, and
test splits.</figcaption>
</figure>
<h3 id="sec:generative">Generative Architectures</h3>
<h4 id="sec:ae">Autoencoders</h4>
<h4 id="sec:vae">Variational Autoencoders</h4>
<h4 id="sec:gan">Generative Adversarial Networks</h4>
<h4 id="sec:ddm">Denoising Diffusion Models</h4>
<h3 id="sec:attention">Attention Machanism</h3>
<h4 id="sec:mha">Multihead Self-Attention</h4>
<h4 id="sec:llm">Large Language Models</h4>

<h2 id="ch:methodology">Methodology</h2>
<h3 id="implementation">Implementation</h3>
<h3 id="objective-evaluation">Objective Evaluation</h3>
<h3 id="subjective-evaluation">Subjective Evaluation</h3>
<h3 id="reproducibility">Reproducibility</h3>

<h1 id="core">Core</h1>
<h2 id="ch:contrib-1">Contrib I (Find Catchy Explicit Name)</h2>
<h3 id="state-of-the-art">State of the Art</h3>
<h3 id="method">Method</h3>
<h3 id="setup">Setup</h3>
<h3 id="results">Results</h3>
<h3 id="summary">Summary</h3>

<h2 id="ch:contrib-2">Contrib II (Find Catchy Explicit Name)</h2>
<h3 id="state-of-the-art-1">State of the Art</h3>
<h3 id="method-1">Method</h3>
<h3 id="setup-1">Setup</h3>
<h3 id="results-1">Results</h3>
<h3 id="summary-1">Summary</h3>

<h2 id="ch:contrib-3">Contrib III (Find Catchy Explicit Name)</h2>
<h3 id="state-of-the-art-2">State of the Art</h3>
<h3 id="method-2">Method</h3>
<h3 id="setup-2">Setup</h3>
<h3 id="results-2">Results</h3>
<h3 id="summary-2">Summary</h3>

<h2 id="ch:contrib-4">Contrib IV (Find Catchy Explicit Name)</h2>
<h3 id="state-of-the-art-3">State of the Art</h3>
<h3 id="method-3">Method</h3>
<h3 id="setup-3">Setup</h3>
<h3 id="results-3">Results</h3>
<h3 id="summary-3">Summary</h3>

<h1 id="reflection">Reflection</h1>
<h2 id="ch:ethical-and-societal-impact">Ethical and Societal Impact</h2>

<h2 id="ch:conclusion">Conclusion</h2>

<h2 class="unnumbered" id="references">References</h2>
<div id="refs" class="references csl-bib-body" role="list">
<div id="ref-tensorflow" class="csl-entry" role="listitem">
<div class="csl-left-margin">[1] </div><div
class="csl-right-inline">Abadi, M., Barham, P., Chen, J., Chen, Z.,
Davis, A., Dean, J., Devin, M., Ghemawat, S., Irving, G., Isard, M., et
al. 2016. Tensorflow: A system for large-scale machine learning.
<em>Osdi</em> (2016), 265–283.</div>
</div>
<div id="ref-john_1992" class="csl-entry" role="listitem">
<div class="csl-left-margin">[2] </div><div
class="csl-right-inline">Anderson, J.R. 1992. Automaticity and the ACT
theory. <em>The American Journal of Psychology</em>. 105, 2 (1992),
165–180. DOI:https://doi.org/<a
href="https://doi.org/10.2307/1423026">10.2307/1423026</a>.</div>
</div>
<div id="ref-brown_2020" class="csl-entry" role="listitem">
<div class="csl-left-margin">[3] </div><div
class="csl-right-inline">Brown, T., Mann, B., Ryder, N., Subbiah, M.,
Kaplan, J.D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G.,
Askell, A., et al. 2020. Language models are few-shot learners.
<em>Advances in neural information processing systems</em>. 33, (2020),
1877–1901.</div>
</div>
<div id="ref-openai_2023" class="csl-entry" role="listitem">
<div class="csl-left-margin">[4] </div><div
class="csl-right-inline">CHATGPT: Optimizing language models for
dialogue: 2023. <a
href="https://openai.com/blog/chatgpt/"><em>https://openai.com/blog/chatgpt/</em></a>.
Accessed: 2023-01-26.</div>
</div>
<div id="ref-ci_2018" class="csl-entry" role="listitem">
<div class="csl-left-margin">[5] </div><div class="csl-right-inline">Ci,
Y., Ma, X., Wang, Z., Li, H. and Luo, Z. 2018. <a
href="https://doi.org/10.1145/3240508.3240661">User-guided deep anime
line art colorization with conditional adversarial networks</a>.
<em>Proceedings of the 26th ACM international conference on
multimedia</em> (New York, NY, USA, 2018), 1536–1544.</div>
</div>
<div id="ref-clipstudiopaint" class="csl-entry" role="listitem">
<div class="csl-left-margin">[6] </div><div
class="csl-right-inline">Clip studio PAINT: <a
href="https://www.clipstudio.net/"><em>https://www.clipstudio.net/</em></a>.
Accessed: 2023-01-26.</div>
</div>
<div id="ref-cortes_1995" class="csl-entry" role="listitem">
<div class="csl-left-margin">[7] </div><div
class="csl-right-inline">Cortes, C. and Vapnik, V. 1995. Support-vector
networks. <em>Machine Learning</em>. 20, 3 (Sep. 1995), 273–297.
DOI:https://doi.org/<a
href="https://doi.org/10.1007/BF00994018">10.1007/BF00994018</a>.</div>
</div>
<div id="ref-deng_2009" class="csl-entry" role="listitem">
<div class="csl-left-margin">[8] </div><div
class="csl-right-inline">Deng, J., Dong, W., Socher, R., Li, L.-J., Li,
K. and Fei-Fei, L. 2009. <a
href="https://doi.org/10.1109/CVPR.2009.5206848">ImageNet: A large-scale
hierarchical image database</a>. <em>2009 IEEE conference on computer
vision and pattern recognition</em> (2009), 248–255.</div>
</div>
<div id="ref-duchi_2011" class="csl-entry" role="listitem">
<div class="csl-left-margin">[9] </div><div
class="csl-right-inline">Duchi, J., Hazan, E. and Singer, Y. 2011. <a
href="http://jmlr.org/papers/v12/duchi11a.html">Adaptive subgradient
methods for online learning and stochastic optimization</a>. <em>Journal
of Machine Learning Research</em>. 12, 61 (2011), 2121–2159.</div>
</div>
<div id="ref-frans_2017" class="csl-entry" role="listitem">
<div class="csl-left-margin">[10] </div><div
class="csl-right-inline">Frans, K. 2017. <a
href="http://arxiv.org/abs/1704.08834">Outline colorization through
tandem adversarial networks</a>. <em>CoRR</em>. abs/1704.08834,
(2017).</div>
</div>
<div id="ref-fukushima_1980" class="csl-entry" role="listitem">
<div class="csl-left-margin">[11] </div><div
class="csl-right-inline">Fukushima, K. 1980. Neocognitron: A
self-organizing neural network model for a mechanism of pattern
recognition unaffected by shift in position. <em>Biological
Cybernetics</em>. 36, 4 (Apr. 1980), 193–202. DOI:https://doi.org/<a
href="https://doi.org/10.1007/BF00344251">10.1007/BF00344251</a>.</div>
</div>
<div id="ref-furusawa_2O17" class="csl-entry" role="listitem">
<div class="csl-left-margin">[12] </div><div
class="csl-right-inline">Furusawa, C., Hiroshiba, K., Ogaki, K. and
Odagiri, Y. 2017. <a
href="https://doi.org/10.1145/3145749.3149430">Comicolorization:
Semi-automatic manga colorization</a>. <em>SIGGRAPH asia 2017 technical
briefs</em> (New York, NY, USA, 2017).</div>
</div>
<div id="ref-goodfellow_2016" class="csl-entry" role="listitem">
<div class="csl-left-margin">[13] </div><div
class="csl-right-inline">Goodfellow, I.J., Bengio, Y. and Courville, A.
2016. <em>Deep learning</em>. MIT Press.</div>
</div>
<div id="ref-goodfellow_2014" class="csl-entry" role="listitem">
<div class="csl-left-margin">[14] </div><div
class="csl-right-inline">Goodfellow, I., Pouget-Abadie, J., Mirza, M.,
Xu, B., Warde-Farley, D., Ozair, S., Courville, A. and Bengio, Y. 2014.
<a
href="https://proceedings.neurips.cc/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf">Generative
adversarial nets</a>. <em>Advances in neural information processing
systems</em> (2014).</div>
</div>
<div id="ref-hati_2019" class="csl-entry" role="listitem">
<div class="csl-left-margin">[15] </div><div
class="csl-right-inline">Hati, Y., Jouet, G., Rousseaux, F. and Duhart,
C. 2019. <a href="https://doi.org/10.1145/3359998.3369401">PaintsTorch:
A user-guided anime line art colorization tool with double generator
conditional adversarial network</a>. <em>European conference on visual
media production</em> (New York, NY, USA, 2019).</div>
</div>
<div id="ref-hati_2023" class="csl-entry" role="listitem">
<div class="csl-left-margin">[16] </div><div
class="csl-right-inline">Hati, Y., Thevenin, V., Nolot, F., Rousseaux,
F. and Duhart, C. 2023. StencilTorch: An iterative and user-guided
framework for anime lineart colorization. <em>Image and vision
computing</em> (Cham, 2023), 1–17.</div>
</div>
<div id="ref-he_2016" class="csl-entry" role="listitem">
<div class="csl-left-margin">[17] </div><div
class="csl-right-inline">He, K., Zhang, X., Ren, S. and Sun, J. 2016.
Deep residual learning for image recognition. <em>Proceedings of the
IEEE conference on computer vision and pattern recognition</em> (2016),
770–778.</div>
</div>
<div id="ref-hensman_2017" class="csl-entry" role="listitem">
<div class="csl-left-margin">[18] </div><div
class="csl-right-inline">Hensman, P. and Aizawa, K. 2017. <a
href="https://doi.org/10.1109/ICDAR.2017.295">cGAN-based manga
colorization using a single training image</a>. <em>2017 14th IAPR
international conference on document analysis and recognition
(ICDAR)</em> (Los Alamitos, CA, USA, Nov. 2017), 72–77.</div>
</div>
<div id="ref-hinton_lecture6a" class="csl-entry" role="listitem">
<div class="csl-left-margin">[19] </div><div
class="csl-right-inline">Hinton, G., Srivastava, N. and Swersky, K.
Neural networks for machine learning: Overview of mini-batch gradient
descent.</div>
</div>
<div id="ref-ho_2020" class="csl-entry" role="listitem">
<div class="csl-left-margin">[20] </div><div
class="csl-right-inline">Ho, J., Jain, A. and Abbeel, P. 2020. Denoising
diffusion probabilistic models. <em>Advances in Neural Information
Processing Systems</em>. 33, (2020), 6840–6851.</div>
</div>
<div id="ref-hochreiter_1997" class="csl-entry" role="listitem">
<div class="csl-left-margin">[21] </div><div
class="csl-right-inline">Hochreiter, S. and Schmidhuber, J. 1997.
<span>Long Short-Term Memory</span>. <em>Neural Computation</em>. 9, 8
(Nov. 1997), 1735–1780. DOI:https://doi.org/<a
href="https://doi.org/10.1162/neco.1997.9.8.1735">10.1162/neco.1997.9.8.1735</a>.</div>
</div>
<div id="ref-hornik_1989" class="csl-entry" role="listitem">
<div class="csl-left-margin">[22] </div><div
class="csl-right-inline">Hornik, K., Stinchcombe, M. and White, H. 1989.
Multilayer feedforward networks are universal approximators. <em>Neural
Networks</em>. 2, 5 (1989), 359–366. DOI:https://doi.org/<a
href="https://doi.org/10.1016/0893-6080(89)90020-8">10.1016/0893-6080(89)90020-8</a>.</div>
</div>
<div id="ref-jackson_1998" class="csl-entry" role="listitem">
<div class="csl-left-margin">[23] </div><div
class="csl-right-inline">Jackson, P. 1998. <em>Introduction to expert
systems</em>. Addison-Wesley Longman Publishing Co., Inc.</div>
</div>
<div id="ref-jumper_2021" class="csl-entry" role="listitem">
<div class="csl-left-margin">[24] </div><div
class="csl-right-inline">Jumper, J. et al. 2021. Highly accurate protein
structure prediction with AlphaFold. <em>Nature</em>. 596, 7873 (Aug.
2021), 583–589. DOI:https://doi.org/<a
href="https://doi.org/10.1038/s41586-021-03819-2">10.1038/s41586-021-03819-2</a>.</div>
</div>
<div id="ref-kandinsky_1977" class="csl-entry" role="listitem">
<div class="csl-left-margin">[25] </div><div
class="csl-right-inline">Kandinsky, W. and Sadleir, M. 1977.
<em>Concerning the spiritual in art</em>. Dover Publications.</div>
</div>
<div id="ref-karpathy_micrograd" class="csl-entry" role="listitem">
<div class="csl-left-margin">[26] </div><div
class="csl-right-inline">Karpathy, A. 2020. <a
href="https://github.com/karpathy/micrograd"><span>Micrograd</span></a>.</div>
</div>
<div id="ref-kim_2019" class="csl-entry" role="listitem">
<div class="csl-left-margin">[27] </div><div
class="csl-right-inline">Kim, H., Jhoo, H.Y., Park, E. and Yoo, S. 2019.
<a href="https://doi.org/10.1109/ICCV.2019.00915">Tag2Pix: Line art
colorization using text tag with SECat and changing loss</a>. <em>2019
IEEE/CVF international conference on computer vision (ICCV)</em> (2019),
9055–9064.</div>
</div>
<div id="ref-kingma_2014" class="csl-entry" role="listitem">
<div class="csl-left-margin">[28] </div><div
class="csl-right-inline">Kingma, D.P. and Ba, J. 2014. Adam: A method
for stochastic optimization. <em>arXiv preprint arXiv:1412.6980</em>.
(2014).</div>
</div>
<div id="ref-kingma_2013" class="csl-entry" role="listitem">
<div class="csl-left-margin">[29] </div><div
class="csl-right-inline">Kingma, D.P. and Welling, M. 2013.
Auto-encoding variational bayes. <em>arXiv preprint
arXiv:1312.6114</em>. (2013).</div>
</div>
<div id="ref-krizhevsky_2012" class="csl-entry" role="listitem">
<div class="csl-left-margin">[30] </div><div
class="csl-right-inline">Krizhevsky, A., Sutskever, I. and Hinton, G.E.
2012. <a
href="https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf">ImageNet
classification with deep convolutional neural networks</a>. <em>Advances
in neural information processing systems</em> (2012).</div>
</div>
<div id="ref-larid_2019" class="csl-entry" role="listitem">
<div class="csl-left-margin">[31] </div><div
class="csl-right-inline">Laird, J.E. 2019. <em>The soar cognitive
architecture</em>. The MIT Press.</div>
</div>
<div id="ref-lecun_2019" class="csl-entry" role="listitem">
<div class="csl-left-margin">[32] </div><div class="csl-right-inline">Le
Cun, Y. 2019. <em><a
href="https://www.odilejacob.fr/catalogue/sciences-humaines/questions-de-societe/quand-la-machine-apprend_9782738149312.php">Quand
la machine apprend: La r<span>é</span>volution des neurones artificiels
et de l’apprentissage profond</a></em>. Odile Jacob.</div>
</div>
<div id="ref-lecun_1989" class="csl-entry" role="listitem">
<div class="csl-left-margin">[33] </div><div
class="csl-right-inline">LeCun, Y., Boser, B., Denker, J.S., Henderson,
D., Howard, R.E., Hubbard, W. and Jackel, L.D. 1989. <span
class="nocase">Backpropagation Applied to Handwritten Zip Code
Recognition</span>. <em>Neural Computation</em>. 1, 4 (Dec. 1989),
541–551. DOI:https://doi.org/<a
href="https://doi.org/10.1162/neco.1989.1.4.541">10.1162/neco.1989.1.4.541</a>.</div>
</div>
<div id="ref-lecun_1998" class="csl-entry" role="listitem">
<div class="csl-left-margin">[34] </div><div
class="csl-right-inline">Lecun, Y., Bottou, L., Bengio, Y. and Haffner,
P. 1998. Gradient-based learning applied to document recognition.
<em>Proceedings of the IEEE</em>. 86, 11 (1998), 2278–2324.
DOI:https://doi.org/<a
href="https://doi.org/10.1109/5.726791">10.1109/5.726791</a>.</div>
</div>
<div id="ref-lieto_2021" class="csl-entry" role="listitem">
<div class="csl-left-margin">[35] </div><div
class="csl-right-inline">Lieto, A. 2021. <em><a
href="https://doi.org/10.4324/9781315460536">Cognitive design for
artificial minds (1st ed.)</a></em>. Routledge.</div>
</div>
<div id="ref-liu_2017" class="csl-entry" role="listitem">
<div class="csl-left-margin">[36] </div><div
class="csl-right-inline">Liu, Y., Qin, Z., Wan, T. and Luo, Z. 2018.
Auto-painter: Cartoon image generation from sketch by using conditional
wasserstein generative adversarial networks. <em>Neurocomputing</em>.
311, (2018), 78–87. DOI:https://doi.org/<a
href="https://doi.org/10.1016/j.neucom.2018.05.045">10.1016/j.neucom.2018.05.045</a>.</div>
</div>
<div id="ref-loshchilov_2017" class="csl-entry" role="listitem">
<div class="csl-left-margin">[37] </div><div
class="csl-right-inline">Loshchilov, I. and Hutter, F. 2017. Decoupled
weight decay regularization. <em>arXiv preprint arXiv:1711.05101</em>.
(2017).</div>
</div>
<div id="ref-mccarthy_1978" class="csl-entry" role="listitem">
<div class="csl-left-margin">[38] </div><div
class="csl-right-inline">McCarthy, J. 1978. <a
href="https://doi.org/10.1145/800025.1198360">History of LISP</a>.
<em>History of programming languages</em>. Association for Computing
Machinery. 173–185.</div>
</div>
<div id="ref-dartmouth_2006" class="csl-entry" role="listitem">
<div class="csl-left-margin">[39] </div><div
class="csl-right-inline">McCarthy, J., Minsky, M.L., Rochester, N. and
Shannon, C.E. 2006. A proposal for the dartmouth summer research project
on artificial intelligence, august 31, 1955. <em>AI Magazine</em>. 27, 4
(2006), 12. DOI:https://doi.org/<a
href="https://doi.org/10.1609/aimag.v27i4.1904">10.1609/aimag.v27i4.1904</a>.</div>
</div>
<div id="ref-minsky_1969" class="csl-entry" role="listitem">
<div class="csl-left-margin">[40] </div><div
class="csl-right-inline">Minsky, M. and Papert, S. 1969.
<em>Perceptrons: An introduction to computational geometry</em>. MIT
Press.</div>
</div>
<div id="ref-mumford_2012" class="csl-entry" role="listitem">
<div class="csl-left-margin">[41] </div><div
class="csl-right-inline">Mumford, M., Medeiros, K. and Partlow, P. 2012.
Creative thinking: Processes, strategies, and knowledge. <em>The Journal
of Creative Behavior</em>. 46, (Mar. 2012). DOI:https://doi.org/<a
href="https://doi.org/10.1002/jocb.003">10.1002/jocb.003</a>.</div>
</div>
<div id="ref-newell_1959" class="csl-entry" role="listitem">
<div class="csl-left-margin">[42] </div><div
class="csl-right-inline">Newell, A., Shaw, J.C. and Simon, H.A. 1959.
<em><a href="https://doi.org/10.1037/13117-003">The processes of
creative thinking</a></em>. RAND Corporation.</div>
</div>
<div id="ref-paintman" class="csl-entry" role="listitem">
<div class="csl-left-margin">[43] </div><div
class="csl-right-inline">Paintman: <a
href="http://www.retasstudio.net/products/paintman/"><em>http://www.retasstudio.net/products/paintman/</em></a>.
Accessed: 2023-01-26.</div>
</div>
<div id="ref-pytorch" class="csl-entry" role="listitem">
<div class="csl-left-margin">[44] </div><div
class="csl-right-inline">Paszke, A. et al. 2019. PyTorch: An imperative
style, high-performance deep learning library. <em>Proceedings of the
33rd international conference on neural information processing
systems</em>. Curran Associates Inc.</div>
</div>
<div id="ref-paintschainer_2017" class="csl-entry" role="listitem">
<div class="csl-left-margin">[45] </div><div
class="csl-right-inline">Pelica paint: 2017. <a
href="https://petalica-paint.pixiv.dev/index_en.html"><em>https://petalica-paint.pixiv.dev/index_en.html</em></a>.
Accessed: 2023-01-26.</div>
</div>
<div id="ref-photoshop" class="csl-entry" role="listitem">
<div class="csl-left-margin">[46] </div><div
class="csl-right-inline">Photoshop: <a
href="https://www.adobe.com/products/photoshop.html"><em>https://www.adobe.com/products/photoshop.html</em></a>.
Accessed: 2023-01-26.</div>
</div>
<div id="ref-qian_1999" class="csl-entry" role="listitem">
<div class="csl-left-margin">[47] </div><div
class="csl-right-inline">Qian, N. 1999. On the momentum term in gradient
descent learning algorithms. <em>Neural Networks</em>. 12, 1 (1999),
145–151. DOI:https://doi.org/<a
href="https://doi.org/10.1016/S0893-6080(98)00116-6">10.1016/S0893-6080(98)00116-6</a>.</div>
</div>
<div id="ref-rombach_2021" class="csl-entry" role="listitem">
<div class="csl-left-margin">[48] </div><div
class="csl-right-inline">Rombach, R., Blattmann, A., Lorenz, D., Esser,
P. and Ommer, B. 2021. <a
href="https://arxiv.org/abs/2112.10752">High-resolution image synthesis
with latent diffusion models</a>.</div>
</div>
<div id="ref-rosenblatt_1958" class="csl-entry" role="listitem">
<div class="csl-left-margin">[49] </div><div
class="csl-right-inline">Rosenblatt, F. 1958. <span class="nocase">The
perceptron: A probabilistic model for information storage and
organization in the brain.</span> <em>Psychological Review</em>. 65, 6
(1958), 386–408. DOI:https://doi.org/<a
href="https://doi.org/10.1037/h0042519">10.1037/h0042519</a>.</div>
</div>
<div id="ref-rumelhart_1986" class="csl-entry" role="listitem">
<div class="csl-left-margin">[50] </div><div
class="csl-right-inline">Rumelhart, D.E., Hinton, G.E. and Williams,
R.J. 1986. Learning representations by back-propagating errors.
<em>Nature</em>. 323, 6088 (Oct. 1986), 533–536. DOI:https://doi.org/<a
href="https://doi.org/10.1038/323533a0">10.1038/323533a0</a>.</div>
</div>
<div id="ref-russell_2016" class="csl-entry" role="listitem">
<div class="csl-left-margin">[51] </div><div
class="csl-right-inline">Russell, S.J. and Norvig, P. 2009.
<em>Artificial intelligence: A modern approach</em>. Pearson.</div>
</div>
<div id="ref-saito_2015" class="csl-entry" role="listitem">
<div class="csl-left-margin">[52] </div><div
class="csl-right-inline">Saito, M. and Matsui, Y. 2015. <a
href="https://doi.org/10.1145/2820903.2820907">Illustration2Vec: A
semantic vector representation of illustrations</a>. <em>SIGGRAPH asia
2015 technical briefs</em> (New York, NY, USA, 2015), 5:1–5:4.</div>
</div>
<div id="ref-sangkloy_2016" class="csl-entry" role="listitem">
<div class="csl-left-margin">[53] </div><div
class="csl-right-inline">Sangkloy, P., Lu, J., Fang, C., Yu, F. and
Hays, J. 2017. <a
href="https://doi.org/10.1109/CVPR.2017.723">Scribbler: Controlling deep
image synthesis with sketch and color</a>. <em>2017 <span>IEEE</span>
conference on computer vision and pattern recognition, <span>CVPR</span>
2017, honolulu, HI, USA, july 21-26, 2017</em> (2017), 6836–6845.</div>
</div>
<div id="ref-senior_2020" class="csl-entry" role="listitem">
<div class="csl-left-margin">[54] </div><div
class="csl-right-inline">Senior, A.W. et al. 2020. Improved protein
structure prediction using potentials from deep learning.
<em>Nature</em>. 577, 7792 (Jan. 2020), 706–710. DOI:https://doi.org/<a
href="https://doi.org/10.1038/s41586-019-1923-7">10.1038/s41586-019-1923-7</a>.</div>
</div>
<div id="ref-silver_2016" class="csl-entry" role="listitem">
<div class="csl-left-margin">[55] </div><div
class="csl-right-inline">Silver, D. et al. 2016. Mastering the game of
go with deep neural networks and tree search. <em>Nature</em>. 529, 7587
(Jan. 2016), 484–489. DOI:https://doi.org/<a
href="https://doi.org/10.1038/nature16961">10.1038/nature16961</a>.</div>
</div>
<div id="ref-mnist" class="csl-entry" role="listitem">
<div class="csl-left-margin">[56] </div><div
class="csl-right-inline">The MNIST database: <a
href="http://yann.lecun.com/exdb/mnist/"><em>http://yann.lecun.com/exdb/mnist/</em></a>.
Accessed: 2023-02-07.</div>
</div>
<div id="ref-vaswani_2017" class="csl-entry" role="listitem">
<div class="csl-left-margin">[57] </div><div
class="csl-right-inline">Vaswani, A., Shazeer, N., Parmar, N.,
Uszkoreit, J., Jones, L., Gomez, A.N., Kaiser, Ł. and Polosukhin, I.
2017. Attention is all you need. <em>Advances in neural information
processing systems</em>. 30, (2017).</div>
</div>
<div id="ref-vinyals_2019" class="csl-entry" role="listitem">
<div class="csl-left-margin">[58] </div><div
class="csl-right-inline">Vinyals, O. et al. 2019. Grandmaster level in
StarCraft II using multi-agent reinforcement learning. <em>Nature</em>.
575, 7782 (Nov. 2019), 350–354. DOI:https://doi.org/<a
href="https://doi.org/10.1038/s41586-019-1724-z">10.1038/s41586-019-1724-z</a>.</div>
</div>
<div id="ref-wolf_2017" class="csl-entry" role="listitem">
<div class="csl-left-margin">[59] </div><div
class="csl-right-inline">Wolf, M.J., Miller, K. and Grodzinsky, F.S.
2017. Why we should have seen that coming: Comments on microsoft’s tay
"experiment," and wider implications. <em>SIGCAS Comput. Soc.</em> 47, 3
(Sep. 2017), 54–64. DOI:https://doi.org/<a
href="https://doi.org/10.1145/3144592.3144598">10.1145/3144592.3144598</a>.</div>
</div>
<div id="ref-aston_zhang_2021" class="csl-entry" role="listitem">
<div class="csl-left-margin">[60] </div><div
class="csl-right-inline">Zhang, A., Lipton, Z.C., Li, M. and Smola, A.J.
2021. Dive into deep learning. <em>arXiv preprint arXiv:2106.11342</em>.
(2021).</div>
</div>
<div id="ref-zhang_ji_2017" class="csl-entry" role="listitem">
<div class="csl-left-margin">[61] </div><div
class="csl-right-inline">Zhang, L., Ji, Y., Lin, X. and Liu, C. 2017. <a
href="https://doi.org/10.1109/ACPR.2017.61">Style transfer for anime
sketches with enhanced residual u-net and auxiliary classifier GAN</a>.
<em>2017 4th IAPR asian conference on pattern recognition (ACPR)</em>
(2017), 506–511.</div>
</div>
<div id="ref-zhang_richard_2017" class="csl-entry" role="listitem">
<div class="csl-left-margin">[62] </div><div
class="csl-right-inline">Zhang, R., Zhu, J.-Y., Isola, P., Geng, X.,
Lin, A.S., Yu, T. and Efros, A.A. 2017. Real-time user-guided image
colorization with learned deep priors. <em>ACM Trans. Graph.</em> 36, 4
(Jul. 2017). DOI:https://doi.org/<a
href="https://doi.org/10.1145/3072959.3073703">10.1145/3072959.3073703</a>.</div>
</div>
</div>
</body>
</html>
